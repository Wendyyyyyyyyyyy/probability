# Mean Function {#mean-function}

In the next few lessons, we discuss three functions that are 
commonly used to summarize random processes: the mean function, 
the variance function, and the autocovariance function.

## Theory {-}

```{definition mean-function, name="Mean Function"}
The **mean function** $\mu(t)$ of a random process $\{ X(t) \}$ 
  is a function that specifies the expected value at each time $t$. 
That is,
\[ \mu(t) \overset{\text{def}}{=} E[X(t)]. \]

For a discrete-time process, we notate the mean function as 
\[ \mu[n] \overset{\text{def}}{=} E[X[n]]. \]
```

The following video explains how to think about a mean function intuitively.

<iframe width="560" height="315" src="https://www.youtube.com/embed/R_zn7d47VUQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

Let's calculate the mean function of some random processes.

```{example random-amplitude-mean, name="Random Amplitude Process"}
Consider the random amplitude process 
\begin{equation}
X(t) = A\cos(2\pi  f t)
(\#eq:random-amplitude)
\end{equation}
introduced in Example \@ref(exm:random-amplitude). 

To be concrete, suppose $A$ is a $\text{Binomial}(n=5, p=0.5)$ random variable 
and $f = 1$. To calculate the mean function, observe that the only thing that is 
random in \@ref(eq:random-amplitude) is $A$. Everything else is a constant, 
so they can be pulled outside the expectation.
\begin{align*}
\mu(t) = E[X(t)] &= E[A\cos(2\pi ft)] \\
&= E[A] \cos(2\pi ft) \\
&= 2.5 \cos(2\pi ft),
\end{align*}
where in the last step, we used the formula for the expected value of a binomial random variable, 
$E[A] = np = 5 \cdot 0.5 = 2.5$.
```

Shown below (in blue) are 30 realizations of this process, along with the mean function (in red). Notice 
how the mean function passes through the heart of the realizations.
```{r, echo=FALSE, fig.show = "hold", fig.align = "default"}
plot(NA, NA,
     xaxt="n", yaxt="n", bty="n",
     xlim=c(-2, 3), ylim=c(-5.1, 5.1),
     xlab="Time (t)", ylab="X(t)")
axis(1, pos=0)
axis(2, pos=0)
set.seed(1)
ts <- seq(-2, 3, by=0.01)
a <- rbinom(30, 5, 0.5)
for(i in 1:30) {
  lines(ts, a[i] * cos(2 * pi * ts), col=rgb(0, 0, 1, 0.2))
}
lines(ts, 2.5 * cos(2 * pi * ts), col="red", lty=2, lwd=2)
```

```{example poisson-process-mean, name="Poisson Process"}
Consider the Poisson process 
$\{ N(t); t \geq 0 \}$ of rate $\lambda$, 
defined in Example \@ref(exm:poisson-process-as-process).

Recall that $N(t)$ represents the number of arrivals on the 
interval $(0, t)$, which we know (by properties of the Poisson process) 
follows a $\text{Poisson}(\mu=\lambda t)$ distribution. Since the 
expected value of a $\text{Poisson}(\mu)$ random variable is $\mu$, we 
must have
\[ \mu(t) = E[N(t)] = \lambda t \]
```

Shown below (in blue) are 30 realizations of the Poisson process, with  
the mean function superimposed (in red). 

```{r, echo=FALSE, fig.show = "hold", fig.align = "default"}
plot(NA, NA,
     xaxt="n", yaxt="n", bty="n",
     xlim=c(0, 5), ylim=c(0, 8.5),
     xlab="Time (t)", ylab="Number of arrivals N(t)")
axis(1, pos=0, at=0:5)
axis(2, pos=0)
set.seed(1)
for(i in 1:30) {
  arrivals <- cumsum(rexp(10, 0.8))
  ts <- seq(0, 6, by=.01)
  N <- c()
  for(t in ts) {
    N <- c(N, sum(arrivals < t))
  }
  lines(ts, N, col=rgb(0, 0, 1, 0.2))
}
abline(a=0, b=0.8, col="red", lty=2, lwd=2)
```

```{example white-noise-mean, name="White Noise"}
Consider the white noise process $\{ Z[n] \}$ defined in \@ref(exm:white-noise), 
which consists of i.i.d. random variables. Suppose the expected value of these 
random variables is $\mu \overset{\text{def}}{=} E[Z[n]]$. Then, the mean function 
is constant, equal to this expected value.
\[ \mu[n] = E[Z[n]] \equiv \mu. \]
```

Shown below (in blue) are 30 realizations of a white noise process consisting of i.i.d. 
standard normal random variables, along with the mean function (in red), which in this case is 
$\mu[n] \equiv 0$.

```{r, echo=FALSE, fig.show = "hold", fig.align = "default"}
plot(NA, NA,
     xaxt="n", yaxt="n", bty="n",
     xlim=c(-2, 3), ylim=c(-3, 3),
     xlab="Time Sample (n)", ylab="Z[n]")
axis(1, pos=0, at=-2:3)
axis(2, pos=0)
set.seed(1)
for(i in 1:30) {
  ts <- -3:4
  Z <- rnorm(8)
  points(ts, Z, pch=19, col=rgb(0, 0, 1, 0.2))
  lines(ts, Z, col=rgb(0, 0, 1, 0.2))
}
points(-2:3, rep(0, 6), col="red", pch=19)
abline(h=0, col="red", lty=2, lwd=2)
```

```{example random-walk-mean, name="Random Walk"}
Consider the random walk process $\{ X[n]; n\geq 0 \}$ of 
Example \@ref(exm:random-walk-process). 
Since 
\[ X[n] = Z[1] + Z[2] + \ldots + Z[n], \]
the mean function is 
\begin{align*} 
\mu[n] = E[X[n]] &= E[Z[1]] + E[Z[2]] + \ldots + E[Z[n]] \\
&= n E[Z[1]].
\end{align*}
```

Shown below (in blue) are 30 realizations of the random walk process where the steps $Z[n]$ are 
i.i.d. standard normal, so the mean function (shown in red) is $\mu[n] = n \cdot 0 \equiv 0$.

```{r, echo=FALSE, fig.show = "hold", fig.align = "default"}
plot(NA, NA,
     xaxt="n", yaxt="n", bty="n",
     xlim=c(0, 5), ylim=c(-5.1, 5.1),
     xlab="Time Sample (n)", ylab="X[n]")
axis(1, pos=0)
axis(2, pos=0)
set.seed(1)
for(i in 1:30) {
  ts <- 0:5
  X <- c(0, cumsum(rnorm(5)))
  points(ts, X, pch=19, col=rgb(0, 0, 1, 0.2))
  lines(ts, X, col=rgb(0, 0, 1, 0.2))
}
points(0:5, rep(0, 6), col="red", pch=19)
abline(h=0, col="red", lty=2, lwd=2)
```

## Essential Practice {-}

1. Consider a grain of pollen suspended in water, whose horizontal position can be modeled by 
Brownian motion $\{B(t)\}$ with parameter $\alpha=4 \text{mm}^2/\text{s}$, as in Example \@ref(exm:pollen).
Calculate the mean function of $\{ B(t) \}$.

2. Radioactive particles hit a Geiger counter according to a Poisson process 
at a rate of $\lambda=0.8$ particles per second. Let $\{ N(t); t \geq 0 \}$ represent this Poisson process.

    Define the new process $\{ D(t); t \geq 3 \}$ by 
    \[ D(t) = N(t) - N(t - 3). \]
    This process represents the number of particles that hit the Geiger counter in the last 3 seconds. 
    Calculate the mean function of $\{ D(t); t \geq 3 \}$.
 
3. Consider the moving average process $\{ X[n] \}$ of Example \@ref(exm:ma1), defined by 
\[ X[n] = 0.5 Z[n] + 0.5 Z[n-1], \]
where $\{ Z[n] \}$ is a sequence of i.i.d. standard normal random variables. 
Calculate the mean function of $\{ X[n] \}$.
    
4. Let $\Theta$ be a $\text{Uniform}(a=-\pi, b=\pi)$ random variable, and let $f$ be a constant. 
Define the random phase process $\{ X(t) \}$ by
\[ X(t) = \cos(2\pi f t + \Theta). \]
Calculate the mean function of $\{ X(t) \}$. (Hint: LOTUS)
