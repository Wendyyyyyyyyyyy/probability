# Negative Binomial Distribution {#negative-binomial}

## Motivating Example {-}

On the American roulette wheel, there are $38$ spaces: $18$ black, $18$ red, and $2$ green. 
You've been playing roulette at the casino for a while now and decide to keep placing bets on red until you have won $3$ bets.
What is the probability that you leave the casino after placing exactly 5 bets? 

## Theory {-}

To answer the question posed at the beginning of the lesson, we need a distribution like the 
geometric, except that it stops after $3$ $\fbox{1}$s have been drawn 
(instead of after the first $\fbox{1}$). The negative binomial distribution is exactly what we need.

```{theorem negbinom, name="Negative Binomial Distribution"}
If a random variable can be described as the number of draws, _with replacement_, 
from the box 
\[ \overbrace{\underbrace{\fbox{0}\ \ldots \fbox{0}}_{N_0}\ \underbrace{\fbox{1}\ \ldots \fbox{1}}_{N_1}}^N \]
_until_ $r$ $\fbox{1}$s have been drawn, then its p.m.f. is given by 
\begin{equation}
f(x) = \dfrac{\binom{x-1}{r-1} N_0^{x-r} \cdot N_1^r}{N^x}, x=r, r+1, r+2, \ldots
(\#eq:negbinom1)
\end{equation}
where $N = N_1 + N_0$ is the number of tickets in the box.

We say that the random variable has a $\text{NegativeBinomial}(r, N_1, N_0)$ distribution, and $r$, $N_1$, 
$N_0$ are called **parameters** of the distribution.

Equivalently, \@ref(eq:negbinom1) can be written as 
\begin{equation}
f(x) = \binom{x-1}{r-1} (1-p)^{x-r} p^r, x=r, r+1, r+2, \ldots,
(\#eq:negbinom2)
\end{equation}
where $p = N_1 / N$ is the proportion of $\fbox{1}$s in the box. So we can also say that 
the random variable has a $\text{NegativeBinomial}(r, p)$ distribution, where $r$ and $p$ are the parameters.
```

Like the geometric distribution, there is no upper bound on the possible values of a negative binomial random variable. 
We might have to wait arbitrarily long to collect $r$ $\fbox{1}$s. Also, notice that the minimum possible value of a
negative binomial random variable is $r$. This is intutive because you need to have drawn at least $r$ times before you 
can have $r$ $\fbox{1}$s.

We will derive the formulas \@ref(eq:negbinom1) and \@ref(eq:negbinom2) later in this lesson. 
For now, let's see how these formulas can be used to solve problems.

```{example name="Three Wins in Roulette"}
There are 38 equally likely spaces on a roulette wheel, 18 of which are red. So we set up a box model where the 
$\fbox{1}$s represent the red spaces:
  
  \[ \overbrace{\underbrace{\fbox{1}\ \ldots \fbox{1}}_{N_1=18}\ \underbrace{\fbox{0}\ \ldots \fbox{0}}_{N_0=20}}^{N=38} \]

The number of draws until we get $r=3$ $\fbox{1}$s corresponds to the number of bets we make until we have won 3 times.
So the number of bets follows a $\text{NegativeBinomial}(r=3, N_1=18, N_0=20)$ distribution.

Therefore, we can write down its p.m.f. using \@ref(eq:negbinom2):
  \[ f(x) = \binom{x-1}{3-1} \left( \frac{20}{38} \right)^{x-3} \left( \frac{18}{38} \right)^3. \]

To calculate the probability that we leave the casino after exactly 5 bets, we plug in $5$ for $x$:
\[ f(5) = \binom{4}{2} \left( \frac{20}{38} \right)^2 \left( \frac{18}{38} \right)^3 \approx .1766. \]
```

**TODO: Derivation**

### Visualizing the Distribution {-}

Let's graph the negative binomial distribution for different values of $n$, $N_1$, and $N_0$.

First, we fix the number of $\fbox{1}$s at $r=5$ and vary the composition of the box. 

```{r negbinom-pmf-1, echo=FALSE, fig.show = "hold", fig.align = "default", fig.asp=0.5}
library(latex2exp)

xs <- 0:30
r <- 5

par(mfrow=c(1, 3))
N1 <- 5
N0 <- 15
p <- N1 / (N0 + N1)
plot(xs + r, dnbinom(xs, r, p), pch=19, xlab="x", ylab="f(x)", ylim=c(0, 0.5),
     main=TeX(paste("NegBinom$(n=", n, ", N_1=", N1, ", N_0=", N0, ")$")))
for(x in xs) {
  lines(c(x+r, x+r), c(0, dnbinom(x, r, p)), lwd=2)
} 

N1 <- 10
N0 <- 10
p <- N1 / (N0 + N1)
plot(xs + r, dnbinom(xs, r, p), pch=19, xlab="x", ylab="f(x)", ylim=c(0, 0.5),
     main=TeX(paste("NegBinom$(n=", n, ", N_1=", N1, ", N_0=", N0, ")$")))
for(x in xs) {
  lines(c(x+r, x+r), c(0, dnbinom(x, r, p)), lwd=2)
} 

N1 <- 15
N0 <- 5
p <- N1 / (N0 + N1)
plot(xs + r, dnbinom(xs, r, p), pch=19, xlab="x", ylab="f(x)", ylim=c(0, 0.5),
     main=TeX(paste("NegBinom$(n=", n, ", N_1=", N1, ", N_0=", N0, ")$")))
for(x in xs) {
  lines(c(x+r, x+r), c(0, dnbinom(x, r, p)), lwd=2)
} 
```

Not surprisingly, as we increase the number of $\fbox{1}$s in the box, the fifth 
$\fbox{1}$ is drawn sooner, so the probability mass shifts to the left.

**TODO: Other Graph**

```{r negbinom-pmf-2, echo=FALSE, fig.show = "hold", fig.align = "default", fig.asp=0.5}
library(latex2exp)

xs <- 0:30
r <- 5

par(mfrow=c(1, 3))
N1 <- 5
N0 <- 15
p <- N1 / (N0 + N1)
plot(xs + r, dnbinom(xs, r, p), pch=19, xlab="x", ylab="f(x)", ylim=c(0, 0.5),
     main=TeX(paste("NegBinom$(n=", n, ", N_1=", N1, ", N_0=", N0, ")$")))
for(x in xs) {
  lines(c(x+r, x+r), c(0, dnbinom(x, r, p)), lwd=2)
} 

N1 <- 10
N0 <- 10
p <- N1 / (N0 + N1)
plot(xs + r, dnbinom(xs, r, p), pch=19, xlab="x", ylab="f(x)", ylim=c(0, 0.5),
     main=TeX(paste("NegBinom$(n=", n, ", N_1=", N1, ", N_0=", N0, ")$")))
for(x in xs) {
  lines(c(x+r, x+r), c(0, dnbinom(x, r, p)), lwd=2)
} 

N1 <- 15
N0 <- 5
p <- N1 / (N0 + N1)
plot(xs + r, dnbinom(xs, r, p), pch=19, xlab="x", ylab="f(x)", ylim=c(0, 0.5),
     main=TeX(paste("NegBinom$(n=", n, ", N_1=", N1, ", N_0=", N0, ")$")))
for(x in xs) {
  lines(c(x+r, x+r), c(0, dnbinom(x, r, p)), lwd=2)
} 
```


### Calculating Binomial Probabilities on the Computer {-}

Calculating binomial probabilities by hand can be unwieldy when $n$ is large. 
Fortunately, the binomial distribution is built into many software packages.

For example, suppose we want to solve the following problem.
```{example, name="Telemarketing"}
Suppose a telemarketer has a 15% chance of making a sale on any given phone call. 
He is required to make 10 successful sales before leaving for the day. 
What is the probability that he needs to make more than 40 calls?
```

```{solution}
First, we will set up a box model for _the number of calls_. We have a box with 

- $N_0 = 85$ tickets labeled $\fbox{0}$
- $N_1 = 15$ tickets labeled $\fbox{1}$
  
to represent the 15% chance of making a sale. We will draw from this box until we have 
drawn 10 $\fbox{1}$s, representing the 10 successful calls. We will assume that his success on one 
call is independent of his success on any other, so we draw _with replacement_. 

Therefore, we know that the number of calls, which we will call $X$, 
follows a $\text{NegativeBinomial}(r=51, N_1=15, N_0=85)$ distribution.

The probability that he has to make more than 40 calls is $P(X > 40)$. To calculate 
this directly, we would have to evaluate an infinite sum:
\[ P(X > 40) = f(41) + f(42) + f(43) + \ldots. \]
The complement rule makes this slightly more palatable:
\[ P(X > 40) = 1 - P(X \leq 40) = 1 - f(40) - f(39) - \ldots - f(10), \]
but this is still a calculation we do not want to do by hand.
```


Here's how we would calculate the probability using the Python library [Symbulate](http://dlsun.github.io/symbulate). 
We first specify the parameters of the negative binomial distribution. Note that Symbulate requires that the parameters 
be $r$ and $p$, so we have to convert $N_1=15, N_0=85$ into $p = 0.15$. 

Calculating the probability directly involves evaluating the p.m.f. at infinitely many values, so we look at the 
complement. We can evaluate the p.m.f. at all of these values using the `.pmf()` metho and add the probabilities 
using `sum()`.
```{python}
from symbulate import *
probs = NegativeBinomial(r=10, p=0.15).pmf(range(10, 41)) # note that range(..., 41) does not include 41
1 - sum(probs)
```

Alternatively, we could also calculate this using the c.d.f. and the complement rule:
```{python}
1 - NegativeBinomial(r=10, p=0.15).cdf(40)
```

You can play around with the Python code in [this Colab notebook](https://colab.research.google.com/github/dlsun/probability/blob/master/colabs/py/Calculating_NegBinom_Probabilities.ipynb). 

It is also possible to do this calculation in R, a statistical programming language. 
Note that R uses the names `size=` and `prob=` for $r$ and $p$, respectively. R also uses a different 
convention for defining the negative binomial distribution; it considers the number of 
$\fbox{0}$s that were drawn, rather than the total number of draws. So we have to subtract the $r=10$ $\fbox{1}$s from the 
number of draws before passing in values to R.
```{r}
probs <- dnbinom((10:40) - 10 , size=10, prob=0.15)
1 - sum(probs)
```

We can also use the c.d.f. function:
```{r}
1 - pnbinom((10:40) - 10 , size=10, prob=0.15)
```

You can play around with the R code in [this Colab notebook](https://colab.research.google.com/github/dlsun/probability/blob/master/colabs/r/Calculating_NegBinom_Probabilities.ipynb). 


## Essential Practice {-}

1. Complete the blank: The geometric distribution is a special case of the negative binomial distribution where $r = $ _____.
2. Calculate the following probabilities. Which is larger?

    (A) You toss a coin 4 times. The probability that you get (exactly) 2 heads.
    
    (B) You toss a coin until you get 2 heads. The probability that it takes (exactly) 4 tosses.
    
    Explain intuitively why the answer makes sense.
3. In Major League Baseball's Home Run Derby, each contestant is allowed to keep swinging the bat until they have made 10 outs. (An out is 
defined to be anything that is not a home run.) If Barry Bonds has a 70% chance of hitting a home run on any given swing, what is the 
probability that he hits at least 10 home runs before his turn is up?

## Additional Exercises {-}

1. Your coach tells you that you cannot leave basketball practice until you have made at least $20$ free throws. If you free throw probability is $80\%$, find the probability that you are out of practice after taking an even amount of free throws.
2. A medical researcher is recruiting 20 subjects for a study on an experimental drug for COVID-19. Each person that she interviews 
has a 60% chance of being eligible to participate in the study. What is the probability that she will have to interview more than 
40 people?
2. You have two coins. One coin is a fair coin with a $.5$ probability of landing on heads. The other coin is a biased coin with a $.25$ probability of landing on heads. You pick one of these two coins at random, and begin flipping until you get $5$ heads. It takes you $12$ flips in order to get your $5$ heads. What is the probability that the coin you picked was the fair coin? What is the probability you picked the biased coin?
