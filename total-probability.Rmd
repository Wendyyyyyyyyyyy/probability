# Law of Total Probability {#ltp}

## Motivating Example {-}

Anny is an incredibly superstitious person and a huge fan of chess competitor Hikaru Nakamura, and tomorrow is the World Chess Championship. Her big superstition is that if it rains on a tournament day for Hikaru he will have a $70\%$ chance of winning the whole thing, and it does not rain then he will have a $15\%$ chance of winning the whole thing. Anny checks the weather at the night and it says the chance it rains tomorrow is $30\%$. What is the probability that Hikaru wins the World Chess Championship? Let's do a simulation

```{r}
N <- 100000
outcomes <- rep(0, N)

for (i in 1:N){
  weather <- sample(c("Rainy", "Not Rainy"), 1, prob = c(.3, .7))
  if (weather == "Rainy"){
    outcome <- sample(c("Win", "Loss"), 1, prob = c(.7, .3))
  }
  else{
    outcome <- sample(c("Win", "Loss"), 1, prob = c(.15, .85))
  }
  outcomes[i] <- outcome
}
results <- table(outcomes)
results

```

The simulated probability of Hikaru winning is 
$`r results["Win"]` / `r length(outcomes)` \approx `r round(results["Win"] / length(outcomes), 3)`$.

## Theory {-}

Previously we have encountered problems before that give us the direct probabilities of an event A of occuring and an event B happening. Suppose now we don't know the probability of event A happening but we know a few other things. 

```{r, echo=FALSE, engine='tikz', out.width='90%', fig.ext='pdf', fig.cap='Probability Space of $X$'}
\begin{tikzpicture}[fill=gray]
% left hand
\scope
\clip (-2,-2) rectangle (2,2)
      (1,0) circle (1);
       (0,0) circle (1);
\endscope
\draw (0,0)  node[align=center,minimum size=3cm,draw,circle] {$A$}
      (-2,-2) rectangle (3,2);
\draw (2,1.5) node[align = center] {$B$};
\draw (-1.5,1.5) node[align = center] {$B^c$};
\draw (0.5,-2) -- (0.5,2);
\end{tikzpicture}
```

We can see from the diagram that $P(X = B \cap A)$ makes up the right part of $A$'s circle and $P(X = B^c \cap A)$ makes up the left part of $A$'s circle. So it is clear that probability of event $A$ is just the sum of $P(X = B \cap A)$ and $P(X = B^c \cap A)$. 

Another way of writing this using the conditional probability version of the "and" formula  is simply

$$P(A) = \sum_x P(X=x) P(A | X=x). $$

Let's plug in the information from the Hikaru Nakamura example

\begin{alignat*}{2}
x_1 &+{}& 4x_2 &= -2 \\
x_1 &+{}& 2x_2 &= 6 \\
2x_1&+{}& 3x_2 &= 1 
\end{alignat*}


\begin{align*}
P(\text{Hikaru Wins}) &= P(X = \text{ Rain})P(\text{Hikaru Wins}|X = \text{ Rain}) +\\
&\phantom{aaa} P(X = \text{ No Rain})P(\text{Hikaru Wins}|X = \text{ No Rain})\\
&= 0.3 \cdot 0.7 + 0.7 \cdot 0.15 \\
&= 0.315
\end{align*}

Which is quite close to our simulated value!

## Worked Examples {-}

1. 
The ELISA test is used to screen blood for HIV. 

- When the blood contains HIV, it gives a positive result 99\% of the time. 
- When the blood does not contain HIV, it gives a negative result 94\% of the time. 

If the prevalence of HIV is 0.7\% in the adult male population, what is the probability that a randomly selected adult male will test positive?

Suppose an adult male patient has just tested positive and wants to know the probability that he has HIV. What would you tell him?

2. You draw two cards from a well-shuffled deck of cards. What is the probability that the 2nd card is a heart?

3. Let $X \sim \text{Binomial}(n, p)$ and $Y \sim \text{Binomial}(m, p)$. What is the distribution of $S = X + Y$?

## Exercises {-}
