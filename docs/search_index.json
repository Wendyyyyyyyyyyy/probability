[
["index.html", "Introduction to Probability Preface", " Introduction to Probability Dennis Sun 2020-06-30 Preface "],
["counting.html", "Lesson 1 Probability and Counting Motivating Example Theory Examples Additional Exercises", " Lesson 1 Probability and Counting Motivating Example In 1620, the Grand Duke of Tuscany asked the astronomer and mathematician Galileo to determine whether the numbers on three fair dice are more likely to add up to 9 or 10. Theory Definition 1.1 (Definition of Probability) If all possible outcomes are equally likely, then the probability of an event \\(A\\) is \\[ P(A) = \\frac{\\text{number of outcomes where $A$ occurs}}{\\text{number of possible outcomes}}. \\] For example, suppose we want to know the probability of getting an even number when we roll a fair die. There are \\(6\\) equally likely possible outcomes, ⚀ ⚁ ⚂ ⚃ ⚄ ⚅, of which 3 are even. Therefore, the probability of rolling an even number is \\[ P(\\text{even number}) = \\frac{\\text{number of outcomes that are even}}{\\text{number of possible outcomes}} = \\frac{3}{6}. \\] Next, suppose we want to know the probability of rolling a 7 when we roll two fair dice. There are 36 equally likely outcomes, ⚀⚀ ⚁⚀ ⚂⚀ ⚃⚀ ⚄⚀ ⚅⚀ ⚀⚁ ⚁⚁ ⚂⚁ ⚃⚁ ⚄⚁ ⚅⚁ ⚀⚂ ⚁⚂ ⚂⚂ ⚃⚂ ⚄⚂ ⚅⚂ ⚀⚃ ⚁⚃ ⚂⚃ ⚃⚃ ⚄⚃ ⚅⚃ ⚀⚄ ⚁⚄ ⚂⚄ ⚃⚄ ⚄⚄ ⚅⚄ ⚀⚅ ⚁⚅ ⚂⚅ ⚃⚅ ⚄⚅ ⚅⚅ of which 6 outcomes add up to 7. (Check this for yourself!) Therefore, the probability of rolling a 7 is \\[ P(\\text{sum is 7}) = \\frac{\\text{number of outcomes where the sum is 7}}{\\text{number of possible outcomes}} = \\frac{6}{36}. \\] Galileo needed to consider the possible outcomes when three dice are rolled. At this point, listing all of the possible outcomes is impractical. We need to find a way to count the number of outcomes without listing all of them. Here is a way to see that there are 36 ways to roll two dice, without listing them out. There are 6 possible outcomes for the first die, and each of these 6 outcomes can be paired with 6 possible outcomes for the second die. Therefore, there must be \\(6 \\cdot 6 = 36\\) ways to roll two dice. The following theorem generalizes this principle. Theorem 1.1 (Multiplication Principle of Counting) If a task can be performed in \\(n_1\\) ways, and for each of these ways, a second task can be performed in \\(n_2\\) ways, then the two tasks can be performed together in a total of \\(n_1 \\cdot n_2\\) ways. Proof. List the outcomes in a table, with \\(n_1\\) columns and \\(n_2\\) rows (like we did above for the possible outcomes of two dice, where \\(n_1 = n_2 = 6\\)). Each column corresponds to one of the \\(n_1\\) possible outcomes of the first task, each row to one of the \\(n_2\\) possible outcomes of the second. There are \\(n_1 \\cdot n_2\\) cells in the table. Using the multiplication principle, we can count the total number of ways of rolling three dice. We already know that there are 36 ways that the first two dice can come out. Each of these 36 ways can be matched with each of the 6 ways that the third dice can come out. Therefore, by Theorem @ref{thm:multiplication-principle}, there are \\[ 36 \\cdot 6 = 216 \\] ways the three dice could come out. Using the multiplication principle, we can calculate the probability that no sixes are rolled among the three dice. In order for there to be no sixes, each of the three dice must have shown one of the other 5 numbers. The number of ways for this to happen is \\[ 5 \\cdot 5 \\cdot 5 = 125, \\] so the probability is \\[ P(\\text{no sixes}) = \\frac{125}{216} \\approx 57.8\\%. \\] Now, Galileo was interested in the event that the numbers add up to 9, which is much trickier to count. We will come back to his question in a future lesson, once we have more counting tools under our belt. Examples In the casino game craps, two dice are rolled by a player, called the “shooter”. The first roll is called the “come-out roll”. The shooter wins on the come-out roll if they roll a 7 or a 11. On the other hand, they lose if the come-out roll is a 2, 3, or 12. Otherwise, the game continues. What is the probability that the shooter wins on the come-out roll? What is the probability that the shooter loses on the come-out roll? What is the probability that the game continues? If you add up the three probabilities you just calculated, what do you get? Why does this make sense? Many examples in this book will be based on a standard deck of 52 playing cards, consisting of 13 cards of each suit. Familiarize yourself with the terminology. Suppose you draw one card from a shuffled deck of cards. What is the probability that the card is a heart? What is the probability that the card is an ace? What is the probability that the card is a face card (also known as a “court card”)? Many examples in this book will be based on the casino game roulette. Familiarize yourself with the roulette wheel. (Click the wheel to spin it.) You win if the ball lands in a pocket that matches your bet. What is the probability that you win if you bet on red? What is the probability that you win if you bet on the number 10? What is the probability that you win if you bet on odd (i.e., that the number is odd)? In standard poker, each player is dealt 5 cards off the top of a (shuffled) deck of cards. The hand is called a “flush” if all 5 cards are the same suit. What is the probability that you get a flush of hearts (i.e., all 5 cards are hearts)? Additional Exercises "],
["factorial.html", "Lesson 2 The Factorial Motivating Example Theory Examples Additional Exercises", " Lesson 2 The Factorial Motivating Example How many ways are there to arrange a deck of 52 cards? Theory We can use the multiplication rule to determine the number of ways to arrange the deck. The first card can be any one of 52 cards. No matter which one it is, the second card can be any one of the remaining 51 cards. So there are \\(52 \\cdot 51\\) ways to choose the first 2 cards. For every one of these \\(52 \\cdot 51\\) ways, there are \\(50\\) remaining cards to choose as the third card, which makes \\(52 \\cdot 51 \\cdot 50\\) ways to choose the first 3 cards. And so on. By the time we get to the last card in the deck, there is only \\(1\\) card left. So there are \\[ 52 \\cdot 51 \\cdot 50 \\cdot \\ldots \\cdot 2 \\cdot 1 \\] ways to arrange the 52 cards in a deck. This is such an important quantity in probability and counting that it has been given a special name. Definition 2.1 (Factorial) The quantity \\(n!\\) (pronounced: “n factorial”) is defined as \\[ n! = n \\cdot (n-1) \\cdot \\ldots \\cdot 1. \\] It represents the number of ways to arrange \\(n\\) objects. So the number of ways to arrange a deck of cards can be expressed as \\(52!\\). Using Wolfram Alpha, we can calculate this to be about \\(8 \\times 10^{67}\\), an astronomical number. In particular, it is greater than: the number of seconds since the universe began. the number of atoms on Earth. So the next time you hold a shuffled deck of cards in your hands, spend a moment appreciating the fact that you are holding an arrangement that has likely never before existed in the history of the universe. Examples Each year, as part of a “Secret Santa” tradition, a group of 4 friends write their names on slips of papers and place the slips into a hat. Each member of the group draws a name at random from the hat and must by a gift for that person. Of course, it is possible that they draw their own name, in which case they buy a gift for themselves. What is the probability that everyone in the group ends up buying a gift for themselves? (Note that the names are not placed back in the hat once they are drawn, so each person receives exactly one gift.) A deck of 52 cards is shuffled thoroughly. What is the probability that the four aces are all next to each other? (Hint: First, count the number of positions that the block of four aces can go, then multiply this by the number of ways of ordering the four aces.) If a five-letter word is formed at random (meaning that all sequences of five letters are equally likely), what is the probability that no letter occurs more than once? The “bootstrap” is a statistical method for generating a new data set that is like an existing one. Suppose we have a data set consisting of \\(6\\) observations: \\(x_1, x_2, x_3, x_4, x_5, x_6\\). To generate a “bootstrap” data set, we sample from the original data set with replacement, meaning that it is possible for each observation to be sampled more than once. Examples of bootstrap data sets include: \\[\\begin{align*} x_4, x_2, x_4, x_3, x_2, x_4 \\\\ x_3, x_1, x_6, x_1, x_1, x_2 \\\\ x_2, x_1, x_4, x_3, x_6, x_5 \\end{align*}\\] Notice that in the last example, each observation appears exactly once. What is the probability that the bootstrap data set contains each observation exactly once? Additional Exercises "],
["box-models.html", "Lesson 3 Box Models and Combinations Motivating Example Theory Examples", " Lesson 3 Box Models and Combinations Motivating Example One of the most coveted hands in poker is a four-of-a-kind, which is when the hand contains all four cards of a particular rank. For example, the hand below is an example of a four-of-a-kind, since it contains all four 7s in the deck. (The last card, called the “kicker”, can be any other card.) In this lesson, we will calculate the probability of a four-of-a-kind in two ways: (1) using methods that we have already learned and (2) using combinations, which is a new method that will be introduced in this lesson. Theory Many counting and probability problems can be reduced to a box model. In a box model, there are \\(N\\) tickets in a box, and we draw \\(n\\) tickets from the box. For example, three rolls of a fair die can be modeled as \\(n=3\\) draws from the box \\[ \\fbox{$\\fbox{1}\\ \\fbox{2}\\ \\fbox{3}\\ \\fbox{4}\\ \\fbox{5}\\ \\fbox{6}$}. \\] In order to accurately model how dice behave (i.e., the outcome of one die roll does not affect the outcome of another), we have to place the ticket back in the box after each draw. In other words, the \\(n=3\\) draws are made with replacement. In other situations, the draws are made without replacement. For example, consider four friends who draw names from a hat to determine whom each person’s Secret Santa is. If we call the four friends “1”, “2”, “3”, and “4” (their actual names are unimportant, as far as probability is concerned), then we can model the Secret Santa game as \\(n=4\\) draws from the box \\[ \\fbox{$\\fbox{1}\\ \\fbox{2}\\ \\fbox{3}\\ \\fbox{4}$}. \\] Since every person has exactly one Secret Santa, the draws must be made without replacement. Once a Secret Santa has been chosen for person 3, we remove \\(\\fbox{3}\\) from the box so that they do not end up with two Secret Santas. Using the multiplication principle (Theorem 1.1), we can count the number of ways to draw \\(n\\) tickets from the box \\[ \\fbox{$\\fbox{1}\\ \\fbox{2}\\ \\ldots\\ \\fbox{\\(N\\)}$}. \\] If drawing with replacement, the number of possible ways is \\[ \\underbrace{N \\cdot N \\cdot N \\cdot \\ldots \\cdot N}_{\\text{$n$ terms}} = N^n, \\] since we have \\(N\\) tickets to choose from on each draw. If drawing without replacement, the number of possible ways is \\[ \\underbrace{N \\cdot (N-1) \\cdot (N-2) \\cdot \\ldots \\cdot (N-n+1)}_{\\text{$n$ terms}} = \\frac{N!}{(N-n)!}, \\] since the number of tickets remaining in the box decreases by 1 on each draw. For example, if we assign a number 1 to 52 to each card in a standard playing deck, then a poker hand can be modeled as \\(n=5\\) draws, without replacement, from the box \\[ \\fbox{$\\fbox{1}\\ \\fbox{2}\\ \\ldots\\ \\fbox{52}$}. \\] The number of possible poker hands is \\[ \\frac{52!}{(52-5)!} = 52 \\cdot 51 \\cdot 50 \\cdot 49 \\cdot 48 = 311,875,200. \\] How many of these possible outcomes result in a four-of-a-kind? Here is the reasoning: Let’s start by assuming that the first four cards in the hand are the four-of-a-kind and the last card is the kicker. The first card can be any one of the 52 cards. Once we have chosen the first card, the rank of the four-of-a-kind is determined. The second card must be one of the 3 remaining cards of the same rank. The third card must be one of the 2 remaining cards of that rank. The fourth card must be the 1 remaining card of that rank. The last card, the kicker, is one of the other 48 cards in the deck. We assumed that the kicker was the last card in the hand. But the kicker could just as well have been the first card in the hand. In fact, the kicker could have been in any one of 5 positions. So we need to multiply everything by 5 in the end. So the probability of a four-of-a-kind is \\[ \\frac{(52 \\cdot 3 \\cdot 2 \\cdot 1 \\cdot 48) \\cdot 5}{52 \\cdot 51 \\cdot 50 \\cdot 49 \\cdot 48} \\approx .00024. \\] This calculation was complicated because we had to consider the different orders in which the cards might be drawn. It is often easier to ignore the order when counting outcomes. That is, we treat \\(\\fbox{1}\\ \\fbox{3}\\ \\fbox{4}\\ \\fbox{5}\\ \\fbox{8}\\) as the same outcome as \\(\\fbox{3}\\ \\fbox{5}\\ \\fbox{4}\\ \\fbox{1}\\ \\fbox{8}\\); we do not double count different reorderings of the same draws. Fortunately, when the draws are made without replacement, the unordered outcomes are also equally likely, so it is equally valid to count unordered outcomes as ordered ones for the purposes of calculating probabilities. If we ignore order when counting, we say that “order doesn’t matter”. Theorem 3.1 (Combinations) The number of ways to draw \\(n\\) tickets from the box \\[ \\fbox{$\\fbox{1}\\ \\fbox{2}\\ \\ldots\\ \\fbox{\\(N\\)}$}, \\] when order doesn’t matter, is symbolized \\(\\binom{N}{n}\\) (pronounced: “\\(N\\) choose \\(n\\)”) and is equal to \\[ \\binom{N}{n} = \\frac{N!}{n! (N-n)!}. \\] Proof. We know that any set of \\(n\\) distinct objects can be reordered in \\(n!\\) ways. So when we count different reorderings of the same set of \\(n\\) tickets, we end up counting each set of distinct tickets \\(n!\\) times. By the multiplication principle (Theorem 1.1): \\[\\begin{align*} \\left(\\text{# ways when order matters}\\right) &amp;= \\left(\\text{# ways when order doesn&#39;t matter}\\right) \\cdot n!. \\end{align*}\\] But we already know the left-hand side of this equation, the number of ways to draw \\(n\\) tickets without replacement when order matters: it is \\(\\frac{N!}{(N-n)!}\\). Solving for the unknown in this equation, we end up with: \\[\\begin{align*} \\binom{N}{n} \\overset{\\text{def}}{=} \\left(\\text{# ways when order doesn&#39;t matter}\\right) &amp;= \\frac{\\left(\\text{# ways when order matters}\\right)}{n!} \\\\ &amp;= \\frac{N!}{n! (N-n)!} \\end{align*}\\] Now, let’s revisit the probability of a four-of-a-kind using combinations. If we ignore the order of the cards in the hand, there are \\[ \\binom{52}{5} = 2,598,960. \\] possible poker hands. (Binomial coefficients can be calculated using Wolfram Alpha.) Notice how much smaller this number is than the 300+ million ordered poker hands. That is because when order matters, each distinct (unordered) poker hand gets counted \\(5! = 120\\) times, once for each possible way of reordering the 5 cards in the hand. How many “unordered” four-of-a-kind hands are there? Here is how to count them: There are 13 ranks (Ace through King). Any one of these ranks could be the rank for the four-of-a-kind. Once we have chosen the rank, that completely determines 4 of the 5 cards in the four-of-a-kind hand. There is only one way to include all 4 cards of a given rank, since we are no longer concerned with the order in which they are drawn or their position in the hand. So all that’s left is to choose the kicker, which can be any one of the remaining 48 cards. So when we ignore order, there are \\[ 13 \\cdot 48 = 624 \\] ways to get a four-of-a-kind. The probability is therefore \\[ \\frac{13 \\times 48}{\\binom{52}{5}} = \\frac{624}{2,598,960} \\approx .00024, \\] which matches the answer from before. Notice how much simpler \\(13 \\cdot 48\\) is, compared with the mental gymnastics needed to account for the order. Examples In Lesson 1, you calculated the probability of a “flush of hearts” in poker by counting the possible hands. There, you took order into account. Repeat the calculation by counting the possible hands where order does not matter. How many different 8-letter “words” can be formed by rearranging the letters in LALALAAA? (Hint: Model this situation using \\(n=3\\) draws from the box \\(\\fbox{\\(\\fbox{1}\\ \\fbox{2}\\ \\ldots\\ \\fbox{8}\\)}\\). The tickets that you draw correspond to the positions of the three Ls. So, for example, drawing \\(\\fbox{3}, \\fbox{1}, \\fbox{5}\\) corresponds to the word LALALAAA. You still need to figure out whether the draws should be made with replacement and whether you should count different orderings of the same 3 tickets.) You toss a coin 60 times. Each toss results in two equally likely outcomes, heads or tails. What is the probability that you get exactly 30 heads in the 60 tosses? (Hint: To count the number of ways of getting exactly 30 heads, you need to count the number of ways of arranging 30 H and 30 Ts. The general strategy from the previous question may be helpful here.) "],
["replacement.html", "Lesson 4 Sampling With Replacement Motivating Example Discussion Examples Bonus Material", " Lesson 4 Sampling With Replacement Motivating Example Recall Galileo’s problem from Lesson 1. He wanted to know whether a sum of 9 or a sum of 10 was more likely when 3 dice are rolled. In fact, Galileo’s peers reasoned that the two events should be equally likely, since there are six ways to get a sum of 9 \\[\\begin{align*} 3 + 3 + 3 &amp; &amp; 2 + 3 + 4 &amp; &amp; 2 + 2 + 5 &amp; &amp; 1 + 4 + 4 &amp; &amp; 1 + 3 + 5 &amp; &amp; 1 + 2 + 6 \\end{align*}\\] and also six ways to get a sum of 10: \\[\\begin{align*} 3 + 3 + 4 &amp; &amp; 2 + 4 + 4 &amp; &amp; 2 + 3 + 5 &amp; &amp; 2 + 2 + 6 &amp; &amp; 1 + 4 + 5 &amp; &amp; 1 + 3 + 6 \\end{align*}\\] But gamblers of the day knew better. From experience, they knew that a sum of 10 was more likely than a sum of 9. But where did Galileo’s peers go wrong in their reasoning? Discussion Recall from Lesson 3 that the three rolls of a die can be modeled as \\(n=3\\) draws with replacement from the box \\[ \\fbox{$\\fbox{1}\\ \\fbox{2}\\ \\fbox{3}\\ \\fbox{4}\\ \\fbox{5}\\ \\fbox{6}$}. \\] Galileo’s peers showed that there are 6 ways to get a sum of 9 if you ignore the order in which the tickets were drawn. (Notice that they included 2 + 3 + 5, but not 3 + 5 + 2 and other orderings of the same three rolls.) They also showed that there are 6 ways to get a sum of 10. Why does this not guarantee the probabilities of the two events are the same? Notice that this case (draws with replacement, order doesn’t matter) is one that we have not studied yet. with replacement without replacement order matters \\(N^n\\) \\(\\frac{N!}{(N-n)!}\\) order doesn’t matter ??? \\(\\binom{N}{n} = \\frac{N!}{n!(N-n)!}\\) To settle the question, let’s go back to counting ordered outcomes. The outcome \\(2 + 3 + 4\\) corresponds to \\(3! = 6\\) outcomes, when you account for the possible orderings: \\(2 + 3 + 4\\) \\(2 + 4 + 3\\) \\(3 + 2 + 4\\) \\(3 + 4 + 2\\) \\(4 + 2 + 3\\) \\(4 + 3 + 2\\) On the other hand, the outcome \\(2 + 2 + 5\\) can only be reordered \\(3\\) different ways: \\(2 + 2 + 5\\) \\(2 + 5 + 2\\) \\(5 + 2 + 2\\) And the outcome \\(3 + 3 + 3\\) only has one possible ordering. In other words, when we draw with replacement, the same ticket can be drawn more than once, and repetitions reduce the number of ways that tickets can be reordered. The problem with simply counting the number of outcomes is that the 6 outcomes \\[\\begin{align*} 3 + 3 + 3 &amp; &amp; 2 + 3 + 4 &amp; &amp; 2 + 2 + 5 &amp; &amp; 1 + 4 + 4 &amp; &amp; 1 + 3 + 5 &amp; &amp; 1 + 2 + 6 \\end{align*}\\] are not all equally likely. \\(2 + 3 + 4\\) is twice as likely as \\(2 + 2 + 5\\) and six times as likely as \\(3 + 3 + 3\\). When draws are made with replacement, only ordered outcomes are equally likely. This was Galileo’s insight. When he took into account the number of possible orderings associated with each unordered outcome: \\[\\begin{array}{rr} \\hline \\text{Unordered Outcome} &amp; \\text{Possible Orderings} \\\\ \\hline 3 + 3 + 3 &amp; \\text{1 way}\\ \\\\ 2 + 3 + 4 &amp; \\text{6 ways} \\\\ 2 + 2 + 5 &amp; \\text{3 ways} \\\\ 1 + 4 + 4 &amp; \\text{3 ways} \\\\ 1 + 3 + 5 &amp; \\text{6 ways} \\\\ 1 + 2 + 6 &amp; + \\text{6 ways} \\\\ \\hline &amp; \\text{25 ways} \\end{array}\\] he found that the probability of a 9 was actually \\[ \\frac{25}{216}. \\] (Remember that there are \\(6^3 = 216\\) equally likely outcomes when order matters.) Repeating the calculation for the probability of a 10, Galileo showed that the two probabilities were indeed different. Examples Here’s a different illustration of the fact that not all unordered outcomes are equally likely when draws are made with replacement. In the Pick 3 Lotto, a winning number is chosen between 000 to 999. Contestants win if the digits in their chosen number matches the winning number, in any order. What is your chance of winning if you bet on 053? What is your chance of winning if you bet on 055? What is your chance of winning if you bet on 555? Complete the solution to Galileo’s problem. What is the probability that the sum is 10 when 3 fair dice are rolled? How does this compare with the probability that the sum is 9? Bonus Material You will rarely need to count the unordered ways that \\(n\\) tickets can be drawn with replacement, since the unordered outcomes are not equally likely. However, in case you are curious how this can be calculated, the following video explains how. This video is completely optional! "],
["double-counting.html", "Lesson 5 Double Counting Motivating Example Theory Examples", " Lesson 5 Double Counting Motivating Example The French nobleman (and avid gambler) Chevalier de Méré knew that betting on at least one six (⚅) in 4 rolls of a die was a favorable bet for him. Once other gamblers caught on, he devised a new bet: at least one double-six (⚅⚅) in 24 rolls of two dice. Although he did not know how to calculate the probabilities, he reasoned that the two bets should be equivalent, since double-sixes are \\(1/6\\) as likely as a single six, but there are \\(6\\) times as many rolls to compensate Are the two bets equivalent? Theory Here is a common (but wrong) way of calculating the probability of getting at least one six in 4 rolls of a die. \\[\\begin{align*} P(\\text{at least one ⚅}) &amp;= P(\\text{⚅ on 1st roll, or ⚅ on 2nd roll, or ⚅ on 3rd roll or ⚅ on 4th roll}) \\\\ &amp;= P(\\text{⚅ on 1st roll}) + P(\\text{⚅ on 2nd roll}) + P(\\text{⚅ on 3nd roll}) + P(\\text{⚅ on 4th roll}) \\\\ &amp;= \\frac{1}{6} + \\frac{1}{6} + \\frac{1}{6} + \\frac{1}{6} \\\\ &amp;= \\frac{4}{6} ? \\end{align*}\\] What’s wrong with the above reasoning? The problem is that \\[ P(A \\text{ or } B) \\neq P(A) + P(B) \\] in general. The reason is that \\(P(A) + P(B)\\) double counts outcomes where \\(A\\) and \\(B\\) both happen. For example, suppose \\(A\\) is “⚅ on 1st roll” and \\(B\\) is “⚅ on 2nd roll”. Then, it is not hard to see that the event \\(A \\text{ or } B\\) happens on 11 out of 36 outcomes, so \\[ P(A \\text{ or } B) = \\frac{11}{36} \\neq \\frac{12}{36} = \\frac{1}{6} + \\frac{1}{6} = P(A) + P(B). \\] \\(P(A) + P(B)\\) double counts the outcome where both rolls were ⚅s. Figure 5.1: Double Counting Dice Rolls One way to avoid double counting is to subtract the cases that are double counted. Theorem 5.1 (Inclusion-Exclusion Principle) \\[ P(A \\text{ or } B) = P(A) + P(B) - P(A \\text{ and } B) \\] Figure 5.2: Intuition for the Inclusion-Exclusion Principle So, for example: \\[\\begin{align*} P(\\text{at least one ⚅ in 2 rolls}) &amp;= P(\\text{⚅ on 1st roll}) + P(\\text{⚅ on 2nd roll}) - P(\\text{⚅ on both rolls}) \\\\ &amp;= \\frac{1}{6} + \\frac{1}{6} - \\frac{1}{36} \\\\ &amp;= \\frac{11}{36} \\end{align*}\\] However, this approach does not scale well to calculating the probability of at least one ⚅ in 4 rolls. In many situations, it is easier to calculate the probability that an event does not happen, also known as the complement of the event. Because the total probability has to be 1, the two probabilities are related by the following formula. Theorem 5.2 (Complement Rule) \\[ P(\\text{not } A) = 1 - P(A). \\] Let’s apply the Complement Rule to the Chevalier de Méré’s problem. To calculate the probability of getting at least one ⚅ in 4 rolls, we can calculate the probability of the complement. If we did not get at least one ⚅, that must mean that we got no ⚅s. This means that every roll was one of the other 5 outcomes. This probability is much easier to calculate using the counting tricks we have learned. \\[\\begin{align*} P(\\text{at least one ⚅}) &amp;= 1 - P(\\text{no ⚅s}) \\\\ &amp;= 1 - \\frac{5^4}{6^4} \\\\ &amp;\\approx 0.5177. \\end{align*}\\] Examples In poker, a “two pair” hand has 2 cards of one rank, 2 cards of another rank, and 1 card of a third rank. For example, the hand 2, 2, Q, Q, J is a “two pair”. Your friend calculates the probability of “two pair” as follows: There are \\(\\binom{52}{5}\\) equally likely hands (where order does not matter). We count the number of ways to choose the first pair. There are \\(13\\) choices for the rank and \\(\\binom{4}{2}\\) choices for the two cards within the rank, so there are \\(13 \\times \\binom{4}{2}\\) ways. Next, we count the ways to choose the second pair. Since one rank has already been chosen, there are \\(12 \\times \\binom{4}{2}\\) ways to do this. Finally, we choose the remaining card. There are \\(11 \\times \\binom{4}{1} = 44\\) ways to do this. Your friend calculates the probability as \\[ \\frac{13 \\times \\binom{4}{2} \\times 12 \\times \\binom{4}{2} \\times 44}{\\binom{52}{5}} \\approx .095, \\] but then finds online that the actual probability of “two pair” is only \\(.0475\\). This number is exactly half the probability that your friend got, so he suspects that he double-counted. But where? Complete the calculation for the Chevalier de Méré. Calculate the probability of getting at least one ⚅⚅ in 24 rolls of two dice. "],
["conditional.html", "Lesson 6 Conditional Probability Motivating Example Theory Examples Additional Exercises", " Lesson 6 Conditional Probability Motivating Example You know that your coworker has two children. Absent any other information, the probability that both are boys is \\(P(\\text{both boys}) = \\frac{1}{4}\\). One day, she mentions to you, “I need to stop by St. Joseph’s after work for a PTA meeting.” St. Joseph’s is a local all-boys school. So now you know that at least one of her children is a boy. What is the probability now that both her children are boys? Most people assume that the answer is \\(\\frac{1}{2}\\), since the other child is equally likely to be a boy or a girl, and the gender of one child does not affect the gender of another. The actual answer may surprise you…. Theory To quantify how probabilities change in light of new information, we calculate the conditional probability. \\[ P(\\text{both boys}\\ |\\ \\text{at least one boy}) \\] The \\(|\\) symbol is read “given” and the event after the \\(|\\) symbol represents information that we know. In general, to calculate a conditional probability, we use the following formula. Definition 6.1 (Conditional Probability) \\[ P(B | A) = \\frac{P(A \\textbf{ and } B)}{P(A)}. \\] The probability \\(P(A \\textbf{ and } B)\\) is called the joint probability of the two events \\(A\\) and \\(B\\). So the conditional probability above is \\[\\begin{align*} P(\\text{both boys}\\ |\\ \\text{at least one boy}) &amp;= \\frac{P(\\text{both boys} \\textbf{ and } \\text{at least one boy})}{P(\\text{at least one boy})} \\\\ &amp;= \\frac{P(\\text{both boys})}{P(\\text{at least one boy})} \\\\ &amp;= \\frac{1/4}{3/4} \\\\ &amp;= \\frac{1}{3}. \\end{align*}\\] In the above example, the joint probability \\(P(\\text{both boys} \\textbf{ and } \\text{at least one boy})\\) is easy to calculate because the two events are redundant. If we know that both are boys, then we automatically know that at least one is a boy. The information that at least one of her children attends St. Joseph’s (and, thus, is a boy) increases the probability that she has two boys from \\(1/4\\) to \\(1/3\\). If this result was counterintuitive to you, the video below gives some intuition. We can rearrange the conditional probability formula to get a formula that is useful for calculating the joint probability when the conditional probability is known. Theorem 6.1 (Multiplication Rule) \\[ P(A \\textbf{ and } B) = P(A) \\cdot P(B | A). \\] Example 6.1 Two cards are dealt off the top of a shuffled deck of cards. What is the probability that both are queens? Solution. In this case, we want to calculate the joint probability \\[ P(\\text{1st card is Q} \\textbf{ and } \\text{2nd card is Q}), \\] and the conditional probability \\[ P(\\text{2nd card is Q} | \\text{1st card is Q}) \\] is simple. If it is known that the 1st card was a queen, then there are only 51 cards remaining in the deck, of which 3 are queens, so \\[ P(\\text{2nd card is Q} | \\text{1st card is Q}) = \\frac{3}{51}. \\] By the Multiplication Rule (6.1), \\[\\begin{align*} P(\\text{1st card is Q} \\textbf{ and } \\text{2nd card is Q}) &amp;= P(\\text{1st card is Q}) \\cdot P(\\text{2nd card is Q} | \\text{1st card is Q}) \\\\ &amp;= \\frac{4}{52} \\cdot \\frac{3}{51} \\end{align*}\\] Let’s compare this with a solution based on counting the outcomes directly. There are \\(52 \\cdot 51\\) equally likely (ordered) outcomes, of which \\(4 \\cdot 3\\) are both queens. Therefore, the probability is \\[ P(\\text{1st card is queen} \\textbf{ and } \\text{2nd card is queen}) = \\frac{4 \\cdot 3}{52 \\cdot 51}. \\] We get the same answer; the only thing that changes is the order of operations: In counting, we first multiply to get the number of outcomes, then divide to get probabilities. In the multiplication rule, we first divide to get probabilities, then multiply the probabilities. Examples You and your friend Amy are each dealt two cards: hers face up and yours face down. In which of the following scenarios are you more likely to have a pair: when she has a pair of queens when she has a queen and a 5? Dr. No has captured James Bond and forces him to play a game of Russian roulette. (Note: Russian roulette is very different from the casino game roulette!) Dr. No shows him an revolver with 6 chambers, all initially empty. He places 2 bullets into adjacent chambers. He makes Bond spin the cylinder, place the muzzle against his head, and pull the trigger. He survives! Luckily for Bond, the cylinder stopped on one of the empty chambers. Now Dr. No gives Bond two options: he can re-spin the cylinder before firing again or he can fire with the gun in its current state. (Keep in mind that the cylinder rotates to the next chamber each time the gun is fired.) What option should Bond choose to maximize his chance of surviving? Clearly write out the conditional probability of interest using \\(P(B|A)\\) notation. Find the probability. (Hint: You should not need to do any calculations. You should be able to find the probability just by thinking carefully about the information you have. Make sure you explain your reasoning carefully.) Additional Exercises "],
["independence.html", "Lesson 7 Independence Motivating Example Theory Examples Additional Exercises", " Lesson 7 Independence Motivating Example Many gamblers believe that after a string of losses, they are “due” for a win. Consider a gambler who repeatedly bets on reds in roulette, an event with probability \\(18 / 38 \\approx 0.474\\). The ball has not landed in a red pocket on any of the last 4 spins of the wheel. Does this make it more likely that he will win on the next spin? This is really a conditional probability question in disguise. We want to know the probability that the ball will land in a red pocket on the 5th spin, given that it did not land in a red pocket on any of the first 4 spins: \\[ P(\\text{red on 5th spin}\\ |\\ \\text{not red on first 4 spins}). \\] Theory To verify that the two probabilities are exactly the same, we do the calculation: \\[\\begin{align*} P(\\text{red on 5th spin}\\ |\\ \\text{not red on first 4 spins}) &amp;= \\frac{P(\\text{not red on first 4 spins} \\textbf{ and } \\text{red on 5th spin}) }{P(\\text{not red on first 4 spins})} \\\\ &amp;= \\frac{ 20^4 \\cdot 18 \\big/ 38^5 }{20^4 \\big/ 38^4} \\\\ &amp;= \\frac{18}{38}. \\end{align*}\\] We see that the conditional probability is \\(18 / 38\\), which is the same as the probability that the 5th spin is red if we did not know the outcome of the first 4 spins. In mathematical notation, \\[\\begin{align*} P(\\text{red on 5th spin}\\ |\\ \\text{not red on first 4 spins}) &amp;= P(\\text{red on 5th spin}) \\end{align*}\\] When conditioning on one event (e.g., “not red on first 4 spins”) does not change the probability of another event (e.g., “red on 5th spin”), we say that the two events are independent. In this case, whether the gambler wins on the 5th spin is independent of the fact that he has lost each of the last 4 spins. The folk belief that one is “due” for a win after a series of losses is plain wrong and is known as the gambler’s fallacy. Definition 7.1 (Independence) Two events \\(A\\) and \\(B\\) are said to be independent if the \\[\\begin{equation} P(B | A) = P(B). \\tag{7.1} \\end{equation}\\] The next result follows by applying the Multiplication Rule (6.1) to the definition of independence. Theorem 7.1 Two events \\(A\\) and \\(B\\) are independent if and only if their probabilities multiply: \\[\\begin{equation} P(A \\textbf{ and } B) = P(A) P(B). \\tag{7.2} \\end{equation}\\] Proof. First, we assume (7.1) and show that (7.2) holds: \\[\\begin{align*} P(A \\textbf{ and } B) &amp;= P(A) P(B | A) &amp; \\text{by the Multiplication Rule} \\\\ &amp;= P(A) P(B) &amp; \\text{by assumption}. \\end{align*}\\] Conversely, we assume (7.2) and show that (7.1) holds: \\[\\begin{align*} P(B | A) &amp;= \\frac{P(A \\textbf{ and } B)}{P(A)} &amp; \\text{by the definition of conditional probability} \\\\ &amp;= \\frac{P(A) P(B)}{P(A)} &amp; \\text{by assumption} \\\\ &amp;= P(B). \\end{align*}\\] Here is an example that combines several concepts from the past few lessons. Example 7.1 You and a fellow castaway are stranded on a desert island, playing dice for the last banana. Two dice will be rolled. If the biggest number is 1, 2, 3, or 4, then Player 1 wins. If the biggest number is 5 or 6, then Player 2 wins. Would you rather be Player 1 or Player 2? Solution. Player 2 has a \\(20/36 = 0.5556\\) chance of winning. Here’s why: \\[\\begin{align*} P(\\text{biggest number is 5, 6}) &amp;= 1 - P(\\text{biggest number is 1, 2, 3, 4}) \\\\ &amp;= 1 - P(\\text{1st die is 1, 2, 3, 4} \\textbf{ and } \\text{2nd die is 1, 2, 3, 4}) \\\\ &amp;= 1 - \\frac{4}{6} \\cdot \\frac{4}{6}\\ \\ \\text{(by independence)} \\\\ &amp;= 1 - \\frac{16}{36} \\\\ &amp;= \\frac{20}{36} \\end{align*}\\] Examples One card is dealt off the top of a well-shuffled deck of cards. Is the event that the card is a heart independent of the event that the card is an ace? Two cards are dealt off the top of a well-shuffled deck of cards. Is the event that the first card is a heart independent of the event that the second card is a heart? In the dice game Yahtzee, five dice are rolled. The outcomes of the five dice are independent. What is the probability of rolling a “Yahtzee” (i.e., when all five dice show the same number)? Additional Exercises "],
["ltp.html", "Lesson 8 Law of Total Probability Motivating Example Theory Examples", " Lesson 8 Law of Total Probability Motivating Example You watch a magician place 4 ordinary quarters and 1 double-headed quarter into a box. If you select a coin from the box at random and toss it, what is the probability that it lands heads? Theory In some situations, calculating the probability of an event is easy, once you condition on the right information. For example, in the example above, if we knew that the coin we chose was ordinary, then: \\[ P(\\text{heads} | \\text{ordinary}) = \\frac{1}{2}. \\] On the other hand, if the coin we chose was double-headed, then \\[ P(\\text{heads} | \\text{double-headed}) = 1. \\] How do we combine these conditional probabilities to come up with \\(P(\\text{heads})\\), the overall probability that the coin lands heads? Theorem 8.1 (Law of Total Probability) Let \\(A_1, ..., A_n\\) be a partition of the possible outcomes. Then: \\[ P(B) = \\sum_{i=1}^n P(A_i) P(B | A_i). \\] A partition is a collection of non-overlapping events that cover all the possible outcomes. For example, in the example above, \\(A_1 = \\{ \\text{ordinary}\\}\\) and \\(A_2 = \\{ \\text{double-headed} \\}\\) is a partition, since the coin that we selected has to be one of the two and cannot be both. Applying the Law of Total Probability to this problem, we have \\[\\begin{align*} P(\\text{heads}) &amp;= P(\\text{ordinary}) P(\\text{heads} | \\text{ordinary}) + P(\\text{double-headed}) P(\\text{heads} | \\text{double-headed}) \\\\ &amp;= 0.8 \\cdot \\frac{1}{2} + 0.2 \\cdot 1 \\\\ &amp;= 0.6 \\end{align*}\\] So the overall probability \\(P(B)\\) is just a weighted average of the conditional probabilities \\(P(B | A_i)\\), where the “weights” are \\(P(A_i)\\). (Note that these “weights” have to add up to 1, since \\(A_1, ..., A_n\\) are a partition of all the possible outcomes, whose total probability is \\(1.0\\).) This means that the overall probability \\(P(B)\\) will always lie somewhere between the conditional probabilities \\(P(B | A_i)\\), with more weight given to the more probable scenarios. For example, we could have predicted that \\(P(\\text{heads})\\) would lie somewhere between \\(\\frac{1}{2}\\) and \\(1\\); the fact that it is much closer to the former is because choosing the ordinary coin was more probable. Examples Here are some things we already know about a deck of cards: The top card in a shuffled deck of cards has a \\(13/52\\) chance of being a diamond. If the top card is a diamond, then the second card has a \\(12/51\\) chance of being a diamond. If the top card is not a diamond, then the second card has a \\(13/51\\) chance of being a diamond. Now, suppose we “burn” (i.e., discard) the top card without looking at it. What is the probability that the second card is a diamond? Use the Law of Total Probability, conditioning on the top card. Does burning cards affect probabilities? Anny is a fan of chess competitor Hikaru Nakamura, and tomorrow is the World Chess Championship. She is superstitious and believes that the weather influences how he will perform. Hikaru has a 60% chance of winning if it rains, a 25% chance if it is cloudy, and a 10% chance if it is sunny. Anny checks the weather the night before, and the forecast says that the chance of rain tomorrow is 40%; otherwise, it is equally likely to be cloudy as sunny. What is the probability that Hikaru wins the World Chess Championship? "],
["bayes.html", "Lesson 9 Bayes’ Theorem 9.1 Motivating Example 9.2 Theory 9.3 Examples", " Lesson 9 Bayes’ Theorem 9.1 Motivating Example The ELISA test is used to screen blood for HIV. When the blood contains HIV, it gives a positive result 98% of the time. When the blood does not contain HIV, it gives a negative result 94% of the time. The prevalence of HIV is about 1% in the adult male population. A patient has just tested positive and wants to know the probability that he has HIV. What would you tell him? The solution to this problem involves an important theorem in probability and statistics called Bayes’ Theorem. This video covers some of the intuition and the history behind Bayes’ Theorem. Don’t worry about the details for now. This video is meant to be more inspiring than informative. 9.2 Theory The conditional probabilities \\(P(A | B)\\) and \\(P(B | A)\\) are not the same. For example, let \\(A\\) be “currently a Cal Poly student” and \\(B\\) be “went to high school in California”. \\(P(B | A)\\) is very high, about \\(0.85\\), since most Cal Poly students are in-state. \\(P(A | B)\\) is very low, as only a very small fraction of people who went to high school in CA are currently in college, much less at Cal Poly. Bayes’ Theorem is a way to convert probabilities of the form \\(P(B | A)\\) into probabilities of the form \\(P(A | B)\\). This switcheroo is surprisingly common in probability and statistics. For example, Doctors know the probability that a patient tests positive (\\(B\\)) given that they have the disease (\\(A\\)), but a patient is more interested in the probability that he has the disease (\\(A\\)) given that he tested positive (\\(B\\)). E-mail providers can collect data on the probability that an e-mail contains a certain word (\\(B\\)) given that it is spam (\\(A\\)), but a spam filter needs the probability that the e-mail is spam (\\(A\\)) given that it contains the word (\\(B\\)). Don’t be deceived by its simplicity; Bayes’ Theorem is one of the most important and powerful results in all of probability and statistics. Theorem 9.1 (Bayes’ Theorem) \\[ P(A | B) = \\frac{P(A) P(B | A)}{P(B)}. \\] Proof. By the definition of conditional probability (6.1) and the multiplication rule (6.1): \\[\\begin{equation} P(A | B) = \\frac{P(A \\textbf{ and } B)}{P(B)} = \\frac{P(A) P(B | A)}{P(B)}. \\end{equation}\\] The next video provides intuition about this proof, connecting it with concepts from the past few lessons, including conditional probability and independence. To solve most problems, you will need to combine Bayes’ Theorem with the Law of Total Probability (8.1). The solution to the HIV testing example from above demonstrates some of the common tricks. Solution. Let’s represent HIV positive by \\(H\\) and a positive ELISA test by \\(T\\). The problem statement tells us that \\[\\begin{align*} P(H) &amp;= 0.01 &amp; P(T | H) &amp;= 0.98 &amp; P(\\textbf{not } T | \\textbf{not } H) &amp;= 0.94. \\end{align*}\\] By the Complement Rule, we can infer that \\[\\begin{align*} P(\\textbf{not } H) &amp;= 0.99 &amp; P(\\textbf{not } T | H) &amp;= 0.02 &amp; P(T | \\textbf{not } H) &amp;= 0.06. \\end{align*}\\] Since we already have \\(P(T | H)\\) and we want to know \\(P(H | T)\\), this is a job for Bayes’ Rule: \\[ P(H | T) = \\frac{P(H) P(T | H)}{P(T)} = \\frac{0.01 \\cdot 0.98}{P(T)}. \\] Unfortunately, we do not know \\(P(T)\\), the probability of testing positive overall. However, we do know its probability, conditional on HIV status. So we apply the Law of Total Probability, partitioning by HIV status: \\[ P(T) = P(H) P(T | H) + P(\\textbf{not } H) P(T | \\textbf{not } H) = 0.01 \\cdot 0.98 + 0.99 \\cdot 0.06. \\] Finally, we plug this result into Bayes’ Rule: \\[ P(H | T) = \\frac{0.01 \\cdot 0.98}{0.01 \\cdot 0.98 + 0.99 \\cdot 0.06} = .142. \\] So even though the patient tested positive for HIV, he only has a 14.2% chance of actually having HIV! The low probability is surprising at first. But it makes sense if we think about the problem geometrically. The figure below partitions adult males based on their HIV status and test status. The shaded area represents all people who tested positive. The people who actually have HIV make up only a tiny fraction of all the people who tested positive because there are so many more people who do not have the disease, that the false positives overwhelm the true positives. Figure 9.1: Intuition for Bayes’ Rule The next video will give you deep insights about Bayes’ rule. You should be able to follow most of it, but you may want to come back to this video after trying some of the examples below. 9.3 Examples The rare mineral unobtanium is present in only 1% of rocks in a mine. You have an unobtanium detector, which never fails to detect unobtanium when it is present. Otherwise, it is still reliable, returning accurate readings 90% of the time when unobtanium is not present. What is \\(P(\\text{unobtanium detected} | \\text{unobtanium present})\\)? What is \\(P(\\text{unobtanium present} | \\text{unobtanium detected})\\)? (Hint: One of these probabilities can be read off directly from the question prompt. The other needs to be calculated using Bayes’ Rule.) One application where Bayes’ Theorem has been extremely successful is spam filtering. From historical data, 80% of all e-mail is spam, and the phrase “free money” is used in 10% of spam e-mails. That is, \\(P(\\text{&quot;free money&quot;} | \\text{spam}) = 0.1\\). The phrase is also used in 1% of non-spam e-mails. A new e-mail has just arrived which contains the phrase “free money”. Given this information, what is the probability that it is spam, \\(P(\\text{spam} | \\text{&quot;free money&quot;})\\)? A certain disease afflicts 10% of the population. A test for the disease is 90% accurate for patients with the disease and 80% accurate for patients without the disease. Suppose you test positive for the disease. What is the probability that you actually have the disease? "],
["rv.html", "Lesson 10 Random Variables Motivating Example Theory Examples", " Lesson 10 Random Variables Motivating Example Texas hold ’em is a popular variant of poker. In Texas hold’em, each player starts with 2 cards (called “hole cards”) that are only known to them. In addition, there are 5 cards in the center (called “community cards”) that are shared by all the players. The player that wins is the one with the best five-card poker hand among the 7 cards (i.e., the 2 hole cards unique to them, plus the 5 community cards). Alice and Bob are playing Texas hold’em using a single deck of cards. The 5 community cards have not been revealed yet. Alice is looking at her 2 hole cards, which are Because she already has two diamonds, she wonders how many more diamonds there are in the community cards. If there are 3 or more, then she has a flush. Bob, on the other hand, has the following hole cards Because he has two jacks of different suits, he is less interested in the suit than in the number of jacks among the community cards. If there are 2, then he has a four-of-a-kind. If there are 0, then he just has a lowly pair. Both Alice and Bob are interested in the same random phenomenon: the 5 community cards with their \\(\\binom{48}{5} \\approx 1,712,304\\) possible outcomes. However, their attention is drawn to different quantities: Alice to the number of diamonds Bob to the number of jacks The number of diamonds and the number of jacks are two examples of random variables associated with this phenomenon. A random variable is simply a way of assigning a number to every possible outcome in a probability experiment. As we have seen, depending on the quantity of interest, there may be many random variables associated with the same probability experiment. To appreciate that Alice and Bob are interested in different random variables, suppose the 5 community cards are revealed to be Alice’s random variable (the number of diamonds) is 2, while Bob’s (the number of jacks) is 1. To help them decide how much to bet, Alice and Bob need to know the probabilities, such as the probability that the number of diamonds is at least 3. the probability that the number of jacks equals 2. Theory We describe random variables (such as the number of diamonds or the number of jacks) by the probabilities of their possible values. This is summarized by a function called the probability mass function. Definition 10.1 (Probability Mass Function) The probability mass function (p.m.f.) of a random variable \\(X\\) is a function that specifies the probability of different outcomes: \\[ f(x) = P(X = x). \\] Informally, the information contained in the p.m.f. is called the distribution of the random variable. Example 10.1 (Calculating the P.M.F.) Let’s calculate the p.m.f. of the number of diamonds, \\(X\\), among the community cards. We deal 5 cards from a deck of cards that has had 4 cards removed (because they have already been dealt to Alice and Bob). Furthermore, we know that 2 of these cards were diamonds. So the deck has 48 cards left, of which 11 are diamonds. First, we calculate \\(f(0)\\), the probability that \\(X = 0\\). In order for there to be no diamonds, all 5 cards must be selected from the \\(48 - 11 = 37\\) non-diamonds. So the probabiilty is \\[ f(0) = P(X = 0) = \\frac{\\binom{37}{5}}{\\binom{48}{5}} = .2546. \\] Next, we calculate \\(f(1)\\), the probability that \\(X = 1\\). We can choose any one of the 11 diamonds and pair it with any of the \\(\\binom{37}{4}\\) ways to choose 4 cards from the non-diamonds. \\[ f(1) = P(X = 1) = \\frac{11 \\cdot \\binom{37}{4}}{\\binom{48}{5}} = .4243. \\] Now, we calculate \\(f(2)\\), the probability that \\(X = 2\\). We can match any one of the \\(\\binom{11}{2}\\) ways to choose 2 diamonds with the \\(\\binom{37}{3}\\) ways to choose 3 non-diamonds: \\[ f(2) = P(X = 2) = \\frac{\\binom{11}{2} \\cdot \\binom{37}{3}}{\\binom{48}{5}} = .2496. \\] Continuing in this way, we can calculate \\(f(3)\\), \\(f(4)\\), and \\(f(5)\\). (Try these yourself!) When the random variable only takes on a handful of possible values, we can write out the probabilities in a table. 0 1 2 3 4 5 \\(f(x)\\) .2546 .4243 .2496 .0642 .0071 .0002 For random variables that take on many possible values, it is usually more convenient to specify the p.m.f. as a formula. In this example, the formula below produces the same probabilities as the table above, when you plug in the right value of \\(x\\): \\[\\begin{align*} f(x) &amp;= \\frac{\\binom{11}{x} \\binom{37}{5-x}}{\\binom{48}{5}} &amp; x &amp;= 0, 1, 2, 3, 4, 5. \\end{align*}\\] Try plugging different values of \\(x\\) into this formula and verifying that you get the probabilities in the table above. Example 10.2 (Using the P.M.F.) In order for Alice to have a flush, there must be at least 3 diamonds among the community cards. Let’s see how she can easily calculate this probability, once she has the p.m.f. \\(f(x)\\). In terms of the random variable \\(X\\), the probability that there are at least 3 diamonds is \\(P(X \\geq 3)\\), which is \\[\\begin{align*} P(X \\geq 3) &amp;= f(3) + f(4) + f(5) \\\\ &amp;= .0642 + .0071 + .0002 \\\\ &amp;= .0715. \\end{align*}\\] The complement rule (5.2) can sometimes save time. Although it would not helped in this example, we could have also calculated the probability as follows: \\[\\begin{align*} P(X \\geq 3) &amp;= 1 - P(X &lt; 3) \\\\ &amp;= 1 - (f(0) + f(1) + f(2)) \\\\ &amp;= 1 - (.2546 + .4243 + .2496) \\\\ &amp;= .0715. \\end{align*}\\] Example 10.3 (Graphing the P.M.F.) A graph of the p.m.f. is the best way to understand the distribution of a random variable over its possible values. On the graph below, the \\(x\\)-axis represents the possible values of the random variable. Each impulse represents the probability of a possible value. From the graph, it is immediately clear that 1 diamond is most probable. Unfortunately for Alice, it does not seem promising that she will get the 3 or more diamonds she needs to secure a flush. Examples Continuing with the example from the lesson, let \\(Y\\) be the number of Jacks in the community cards. Calculate and graph the p.m.f. of \\(Y\\). Two fair, six-sided dice are rolled. Let \\(S\\) be the sum of the two numbers. Calculate and graph the p.m.f. of \\(S\\). Let \\(D\\) be the absolute difference between the two numbers. (That is, \\(D\\) is always a positive number.) Calculate and graph the p.m.f. of \\(D\\). A fair coin is tossed 5 times. Let \\(Z\\) be the number of heads. Calculate and graph the p.m.f. of \\(Z\\). Use the p.m.f. to calculate the probability of getting at least 2 heads. "],
["cdf.html", "Lesson 11 Cumulative Distribution Functions Theory Examples", " Lesson 11 Cumulative Distribution Functions Theory The p.m.f. (10.1) is one way to describe a random variable, but it is not the only way. The cumulative distribution function is a different representation that contains the same information as the p.m.f. Definition 11.1 (Cumulative Distribution Function) The cumulative distribution function (c.d.f.) is a function that returns the probability that a random variable is less than or equal to a particular value: \\[ F(x) = P(X \\leq x). \\] It is called “cumulative” because it includes all the probability up to (and including) \\(x\\). Example 11.1 (Calculating the C.D.F.) Let’s calculate the c.d.f. of \\(X\\), the number of diamonds among the community cards, using the p.m.f. that we calculated in Lesson 10. Note that \\(F(x)\\) is the sum of all the probabilities up to \\(x\\). So, for example, \\[\\begin{align*} F(2.8) = P(X \\leq 2.8) &amp;= f(0) + f(1) + f(2) \\\\ &amp;= .2546 + .4243 + .2496 \\\\ &amp;= .9284. \\end{align*}\\] There is no simple formula for \\(F(x)\\). However, we can describe it piecewise. \\[ F(x) = \\begin{cases} 0 &amp; x \\leq 0 \\\\ .2546 &amp; 0 \\leq x &lt; 1 \\\\ .6788 &amp; 1 \\leq x &lt; 2 \\\\ .9284 &amp; 2 \\leq x &lt; 3 \\\\ .9926 &amp; 3 \\leq x &lt; 4 \\\\ .9997 &amp; 4 \\leq x &lt; 5 \\\\ 1.0 &amp; x \\geq 5 \\end{cases}. \\] Note that the c.d.f. of \\(X\\) has the following properties: It is constant between integers. Because it is impossible for the random variable \\(X\\) to assume non-integer values, \\(F(1.2) = P(X \\leq 1.2)\\) and \\(F(1) = P(X \\leq 1)\\) must be the same. The value of \\(F(x)\\) increases from 0 to 1 as \\(x\\) increases. This makes sense because as \\(x\\) increases, we accumulate more and more probability. Example 11.2 (Graphing the C.D.F.) The properties of the c.d.f. become clearer on a graph, like the one below. Because the random variable \\(X\\) cannot take on decimal values, the c.d.f. of \\(X\\) does not change between integers, giving it its step-function appearance. Note that the c.d.f. \\(F(x)\\) can be evaluated at all values \\(x\\), not just at integer values. ``` Example 11.3 (Using the C.D.F.) Some probabilities are easier to calculate using the c.d.f. than using the p.m.f. For example, the probability that Alice gets a flush, \\(P(X \\geq 3)\\), can be calculated by using the complement rule (5.2) and looking up the appropriate probability directly from the c.d.f. \\(F(x)\\). \\[\\begin{align*} P(X \\geq 3) &amp;= 1 - P(X &lt; 3) \\\\ &amp;= 1 - P(X \\leq 2) \\\\ &amp;= 1 - F(2) \\\\ &amp;= 1 - .9284 \\\\ &amp;= .0716 \\end{align*}\\] Remember that the c.d.f. \\(F(x)\\) always includes the probability of \\(x\\). Since \\(P(X &lt; 3)\\) should not include the probability of \\(3\\), we use \\(F(2)\\) instead of \\(F(3)\\). At the beginning of this lesson, we mentioned that the c.d.f. contains the exact same information as the p.m.f., no more and no less. Therefore, it should be possible to recover the p.m.f. from the c.d.f. For example, how would we calculate \\(f(3) = P(X = 3)\\), if we only knew the c.d.f. \\(F(x)\\)? We could subtract \\(P(X \\leq 2)\\) from \\(P(X \\leq 3)\\) to get just the probability that it is equal to 3. \\[\\begin{align*} f(3) = P(X = 3) &amp;= P(X \\leq 3) - P(X \\leq 2) \\\\ &amp;= F(3) - F(2) \\\\ &amp;= .9926 - .9284 \\\\ &amp;= .0642, \\end{align*}\\] which agrees with the p.m.f. from Lesson 10. Examples Continuing with the example from the lesson, let \\(Y\\) be the number of Jacks among the community cards. Calculate and graph the c.d.f. of \\(Y\\). Consider a random variable \\(Z\\) with c.d.f. given by the formula \\[\\begin{align*} F(x) &amp;= \\begin{cases} 1 - 3^{-\\lfloor x \\rfloor} &amp; x \\geq 0 \\\\ 0 &amp; \\text{otherwise} \\end{cases}. \\end{align*}\\] (Note that \\(\\lfloor x \\rfloor\\) denotes the floor operator, which rounds \\(x\\) down to the nearest integer. So \\(\\lfloor 3.9 \\rfloor = 3\\) and \\(\\lfloor 7.1 \\rfloor = 7\\).) Graph the c.d.f. \\(F(x)\\). Then, use it to calculate: \\(P(Z &gt; 3)\\) \\(P(Z = 2)\\) "],
["hypergeometric.html", "Lesson 12 Hypergeometric Distribution Motivating Example Theory Essential Practice Additional Exercises", " Lesson 12 Hypergeometric Distribution Motivating Example We revisit the Texas Hold’em example from Lesson 10, when we first learned about random variables. In that example, Alice was dealt and she wanted to know the distribution of the number of diamonds among the community cards. If this random variable is at least 3, then she has a flush. In Lesson 10, we derived the p.m.f. of the number of diamonds from scratch. In this lesson, we will derive the p.m.f. by matching this random variable to a template. Theory In probability, some distributions are so common that they have been given names. The first named distribution that we will learn is the hypergeometric distribution. Theorem 12.1 (Hypergeometric Distribution) If a random variable can be described as the number of \\(\\fbox{1}\\)s in \\(n\\) random draws, without replacement, from the box \\[ \\overbrace{\\underbrace{\\fbox{0}\\ \\ldots \\fbox{0}}_{N_0}\\ \\underbrace{\\fbox{1}\\ \\ldots \\fbox{1}}_{N_1}}^N, \\] then its p.m.f. is given by \\[\\begin{equation} f(x) = \\dfrac{\\binom{N_1}{x}\\binom{N_0}{n-x}}{\\binom{N}{n}}, x=0, ..., n, \\tag{12.1} \\end{equation}\\] where \\(N = N_1 + N_0\\) is the number of tickets in the box. We say that the random variable has a \\(\\text{Hypergeometric}(n, N_1, N_0)\\) distribution, and \\(n\\), \\(N_1\\), \\(N_0\\) are called parameters of the distribution. We will derive the formula (12.1) later in this lesson. First, let’s see how this result allows us to avoid most calculations. Example 12.1 (The Number of Diamonds) In Alice’s case, the community cards are \\(5\\) cards taken at random, without replacement, from a deck of \\(48\\) cards. So we can represent it by a box model with \\(N=48\\) tickets, with \\[\\begin{align*} \\text{$N_1=11$ tickets labeled } \\fbox{1} &amp;\\text{ representing the diamond cards} \\\\ \\text{$N_0=37$ tickets labeled } \\fbox{0} &amp;\\text{ representing the non-diamond cards}. \\end{align*}\\] Now, if we draw \\(n=5\\) times from this box without replacement, then the number of \\(\\fbox{1}\\)s we get corresponds to the number of diamonds. Therefore, by Theorem 12.1, we know that the number of diamonds follows a \\(\\text{Hypergeometric}(n=5, N_1=11, N_0=37)\\) distribution. We can now write down the p.m.f. by plugging the values of the parameters \\(n\\), \\(N_1\\), \\(N_0\\) into (12.1): \\[ f(x) = \\frac{\\binom{11}{x} \\binom{37}{5-x}}{\\binom{48}{5}}, x=0, 1, \\ldots, 5. \\] Now that we have a formula for the p.m.f., we can calculate probabilities by plugging numbers into it. So, for example, the probability that Alice gets a flush is: \\[\\begin{align*} P(X \\geq 3) &amp;= f(3) + f(4) + f(5) \\\\ &amp;= \\frac{\\binom{11}{3} \\binom{37}{5-3}}{\\binom{48}{5}} + \\frac{\\binom{11}{4} \\binom{37}{5-4}}{\\binom{48}{5}} + \\frac{\\binom{11}{5} \\binom{37}{5-5}}{\\binom{48}{5}} \\\\ &amp;\\approx .0715. \\end{align*}\\] Now, let’s derive the p.m.f. of the hypergeometric distribution. Understanding this derivation will help you remember the formula! Proof. If we number each ticket \\(1, 2, \\ldots, N\\), then there are \\(\\binom{N}{n}\\) equally likely unordered outcomes. Note that in this way of counting, the \\(\\fbox{1}\\)s in the box are distinct. So drawing the first \\(\\fbox{1}\\) in the box is not the same as drawing the second \\(\\fbox{1}\\) in the box. How many of the possible outcomes have exactly \\(x\\) \\(\\fbox{1}\\)s? There are \\(\\binom{N_1}{x}\\) unordered ways to choose \\(x\\) \\(\\fbox{1}\\)s from the \\(N_1\\) \\(\\fbox{1}\\)s. There are \\(\\binom{N_0}{n-x}\\) unordered ways to choose the remaining \\(n-x\\) \\(\\fbox{0}\\)s. Since any one of the \\(\\binom{N_1}{x}\\) ways of choosing the \\(\\fbox{1}\\)s can be paired with any one of the \\(\\binom{N_0}{n-x}\\) ways of choosing the \\(\\fbox{0}\\)s, the total number of ways to choose \\(n\\) tickets, resulting in \\(x\\) \\(\\fbox{1}\\)s and \\(n-x\\) \\(\\fbox{0}\\)s, is \\[ \\binom{N_1}{x} \\cdot \\binom{N_0}{n-x}, \\] by the multiplication principle of counting (Theorem 1.1). Therefore, the probability of getting exactly \\(x\\) \\(\\fbox{1}\\)s in \\(n\\) draws is: \\[ f(x) = P(X = x) = \\dfrac{\\binom{N_1}{x}\\binom{N_0}{n-x}}{\\binom{N}{n}}. \\] Graphing Let’s graph the hypergeometric distribution for different values of \\(n\\), \\(N_1\\), and \\(N_0\\). First, we hold the number of draws constant at \\(n=5\\) and vary the composition of the box. The distribution shifts, depending on the composition of the box. The more \\(\\fbox{1}\\)s there are in the box, the more \\(\\fbox{1}\\)s in the sample. Next, we study how the distribution changes as a function of \\(n / N\\), the relative fraction of tickets removed from the box. For all of the graphs below, \\(N_1 = N_0 = N/2\\). All three plots are symmetric, which makes sense, since there are exactly as many \\(\\fbox{1}\\)s as \\(\\fbox{0}\\)s in the box. However, when the number of draws makes up a large fraction of the box, as in the leftmost plot, the distribution is very tightly concentrated around intermediate values, such as 4, 5, and 6. This makes sense because sampling without replacement is “self-balancing”. Each time we draw a \\(\\fbox{1}\\), it becomes less likely that we will draw a \\(\\fbox{1}\\) again (and more likely to draw a \\(\\fbox{0}\\)). This makes extreme outcomes, such as drawing all \\(\\fbox{1}\\)s, less likely. Calculating Hypergeometric Probabilities on the Computer Calculating hypergeometric probabilities by hand is unwieldy when \\(n\\), \\(N_1\\), and \\(N_0\\) are large. Fortunately, the hypergeometric distribution is built into many software packages. For example, suppose we want to solve the following problem. Example 12.2 (Capture-Recapture) One way to estimate the number of animals in a population is capture-recapture. For example, suppose we want to estimate the number of fish in a lake. Clearly, it is impractical to catch all of the fish. Instead, we capture \\(m\\) fish one week, tag them, and release them back into the lake. We go back the next week, after these tagged fish have had a chance to mix with the population, and catch another \\(n\\) distinct fish. Some, but not all, of these \\(n\\) fish will be tagged. The number of tagged fish in this second catch allows us to estimate the population of fish in the lake. Suppose there are actually 100 fish in the lake; we capture \\(m=20\\) fish the first week and \\(n=30\\) fish the next week. What is the probability that at least \\(7\\) of the \\(30\\) fish will be tagged? Solution. We can represent this using a box model. The fish in the lake will be represented by \\(N=100\\) tickets, with \\[\\begin{align*} \\text{$N_1=20$ tickets labeled } \\fbox{1} &amp;\\text{ representing the tagged fish} \\\\ \\text{$N_0=80$ tickets labeled } \\fbox{0} &amp;\\text{ representing the non-tagged fish}. \\end{align*}\\] Now, if we draw \\(n=30\\) times from this box without replacement, then the number of \\(\\fbox{1}\\)s we get corresponds to the number of tagged fish we get. Therefore, the number of tagged fish is a \\(\\text{Hypergeometric}(n=30, N_1=20, N_0=80)\\) random variable. However, to calculate the probability that at least \\(7\\) of the \\(30\\) fish will be tagged, we have to evaluate the p.m.f. at 7, 8, 9, etc. This is a job for a computer, not a human. In Python, we use a library called Symbulate. We first specify the parameters of the hypergeometric distribution; then we evaluate the p.m.f. using the .pmf() method. Note that .pmf() accepts either a single number or a list of numbers. If a list of numbers is passed into .pmf(), then it will evaluate the p.m.f. at each of those numbers, returning a list of probabilities. from symbulate import * probs = Hypergeometric(n=30, N1=20, N0=80).pmf(range(7, 31)) probs ## array([1.80287211e-01, 1.16176457e-01, 5.77600464e-02, 2.22376179e-02, ## 6.62820205e-03, 1.52341741e-03, 2.67853610e-04, 3.55743076e-05, ## 3.50270105e-06, 2.48771382e-07, 1.22310776e-08, 3.89715707e-10, ## 7.13438366e-12, 5.60558716e-14, 0.00000000e+00, 0.00000000e+00, ## 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ## 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]) To add these probabilities, we call sum(): sum(probs) ## 0.38492014376629696 We could have also gotten the same answer by using c.d.f.s. Note that \\(P(X \\geq 7) = 1 - F(6)\\). 1 - Hypergeometric(n=30, N1=20, N0=80).cdf(6) ## 0.384920143766305 You can play around with the Python code in this Colab notebook. It is possible to do the same calculation in R, a statistical programming language. Note that R uses different names for the parameters. Like Python, R can evaluate the p.m.f. at a single value or a vector of values. probs &lt;- dhyper(x=7:30, m=20, n=80, k=30) probs ## [1] 1.802872e-01 1.161765e-01 5.776005e-02 2.223762e-02 6.628202e-03 ## [6] 1.523417e-03 2.678536e-04 3.557431e-05 3.502701e-06 2.487714e-07 ## [11] 1.223108e-08 3.897157e-10 7.134384e-12 5.605587e-14 0.000000e+00 ## [16] 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 ## [21] 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 To add these probabilities, we call sum(): sum(probs) ## [1] 0.3849201 We could have also gotten the same answer by using c.d.f.s. Notice how R uses the prefix d for p.m.f.s and the prefix p for c.d.f.s. 1 - phyper(6, m=20, n=80, k=30) ## [1] 0.3849201 You can play around with the R code in this Colab notebook. Another Formula for the Hypergeometric Distribution (optional) There is another formula for the hypergeometric p.m.f. that looks different but is equivalent to (12.1). It is based on counting the number of ordered outcomes, instead of the number of unordered outcomes. You should verify that this formula gives the same probabilities as (12.1). Theorem 12.2 (Another Formula for the Hypergeometric) The p.m.f. of a \\(\\text{Hypergeometric}(n, N_1, N_0)\\) random variable can also be written as \\[ f(x) = \\frac{\\binom{n}{x} \\cdot \\frac{N_1!}{(N_1 - x)!} \\cdot \\frac{N_0!}{(N_0 - n + x)!}}{\\frac{N!}{(N-n)!}}. \\] Proof. There are \\(\\frac{N!}{(N-n)!}\\) ways to choose \\(n\\) tickets from \\(N\\), if we account for the order in which \\(n\\) the tickets were drawn. How many of these ordered outcomes have exactly \\(x\\) \\(\\fbox{1}\\)s and \\(n-x\\) \\(\\fbox{0}\\)s? Let’s start by counting the number of outcomes that look like \\[\\begin{equation} \\underbrace{\\fbox{1}, \\ldots, \\fbox{1}}_{x}, \\underbrace{\\fbox{0}, \\ldots, \\fbox{0}}_{n-x}, \\tag{12.2} \\end{equation}\\] in this exact order. There are \\(N_1\\) choices for the first \\(\\fbox{1}\\), \\(N_1 - 1\\) choices for the second, and so on, until we get to the last \\(\\fbox{1}\\), for which there are \\(N_1 - x + 1\\) choices. Then, there are \\(N_0\\) choices for the first \\(\\fbox{0}\\), \\(N_0 - 1\\) choices for the second, and so on. By the multiplication principle of counting (Theorem 1.1), there are \\[\\begin{equation} \\underbrace{N_1 \\cdot (N_1 - 1) \\cdot \\ldots \\cdot (N_1 - x + 1)}_{\\displaystyle\\frac{N_1!}{(N_1 - x)!}} \\cdot \\underbrace{N_0 \\cdot (N_0 - 1) \\cdot \\ldots \\cdot (N_0 - (n - x) + 1)}_{\\displaystyle\\frac{N_0!}{(N_0 - n + x)!}}. \\tag{12.3} \\end{equation}\\] ways to get an outcome like (12.2), in that exact order. However, because we are counting ordered outcomes, we need to account for the possibility that the \\(\\fbox{1}\\)s and \\(\\fbox{0}\\)s were drawn in a different order than (12.2). There are \\(\\binom{n}{x}\\) ways to reorder the \\(\\fbox{1}\\)s and \\(\\fbox{0}\\)s, each of which can be obtained in (12.3) ways. So the total number of (ordered) ways to get \\(x\\) \\(\\fbox{1}\\)s and \\(n-x\\) \\(\\fbox{0}\\)s is \\[ \\binom{n}{x} \\cdot \\frac{N_1!}{(N_1 - x)!} \\cdot \\frac{N_0!}{(N_0 - n + x)!} \\] So the p.m.f. can be written as \\[ f(x) = P(X = x) = \\frac{\\binom{n}{x} \\cdot \\frac{N_1!}{(N_1 - x)!} \\cdot \\frac{N_0!}{(N_0 - n + x)!}}{\\frac{N!}{(N-n)!}}. \\] It is easy to see that this formula is equivalent to (12.1), if you write out the binomial coefficients in (12.1) as factorials and regroup \\(\\frac{n!}{x! (n-x)!}\\) as \\(\\binom{n}{x}\\). Essential Practice Recall in the example from Lesson 10, there was another player, Bob, who had two Jacks and was looking to get a four-of-a-kind. For Bob, the random variable of interest was the number of Jacks among the community cards. Use a box model to argue that Bob’s random variable also has a hypergeometric distribution. What are its parameters? In order to ensure safety, a random sample of cars on each production line are crash-tested before being released to the public. The process of crash testing destroys the car. Suppose that a production line contains 10 defective and 190 working cars. If 4 of these cars are chosen at random for crash-testing, what is: the probability that at least 1 car will be found defective? the probability that exactly 2 cars will be found defective? The state proposes a lottery in which you select \\(6\\) numbers from \\(1\\) to \\(15\\). When it is time to draw, the lottery selects \\(8\\) different numbers, and you win if at least \\(4\\) of the \\(6\\) numbers you picked are among the \\(8\\) numbers that the lottery drew. What is the probability you win the prize? Additional Exercises You are enrolled in \\(3\\) courses this quarter, and the breakdown of majors by class is as follows: Class 1: \\(4\\) Statistics majors and \\(6\\) Computer Science majors Class 2: \\(17\\) Statistics majors and \\(13\\) Computer Science majors Class 3: \\(11\\) Statistics majors and \\(9\\) Computer Science majors If you take a simple random sample of \\(20\\%\\) of the students in Class 1, what is the probability that the number of Statistics majors in your sample is equal to the number of Computer Science majors? (Note: In a simple random sample, each student can be selected at most once.) Now, suppose you pick one of your \\(3\\) classes at random and then choose a random sample of \\(20\\%\\) of students from that class. What is the probability that the number of Statistics majors in your sample is equal to the number of Computer Science majors in your sample? In Texas Hold’em, each player has \\(2\\) cards of their own, and all players share \\(5\\) cards in the center of the table. A player has a flush when there are at least \\(5\\) cards of the same suit out of the \\(7\\) total cards. The deck is shuffled between hands, so that the probability you obtain a flush is independent from hand to hand. What is the probability that you get a flush at least once in \\(10\\) hands of Texas Hold’em? (Hint: First, calculate the probability of a flush of spades. Then, repeat for the other suits, and add the probabilities together to obtain the overall probability of a flush.) There are \\(25\\) coins in a jar. \\(15\\) are quarters, \\(7\\) are dimes, and \\(3\\) are pennies. Each time you reach in the jar, you are equally likely to pick any of the coins in the jar. The coins are not replaced in the jar after each draw. What is the minimum number of times you must reach in the jar to have at least a \\(50\\%\\) chance of getting all \\(3\\) pennies? (Hint: In this question, \\(n\\) is unknown. You will have to try a few different values of \\(n\\) to get the answer.) "],
["binomial.html", "Lesson 13 Binomial Distribution Motivating Example Theory Essential Practice Additional Exercises", " Lesson 13 Binomial Distribution Motivating Example In 1693, Samuel Pepys (who is best remembered today for his diary) wrote a letter to Isaac Newton inquiring about a wager that Pepys was planning to make. Pepys wanted to know which of the following events had the highest probability of occurring. A. 6 dice are thrown and at least 1 is a ⚅ B. 12 dice are thrown and at least 2 are ⚅s C. 18 dice are thrown and at least 3 are ⚅s Pepys thought that C had the highest probability, but Newton disagreed. The probability of A is straightforward to calculate. We use the Complement Rule (Theorem 5.2), much like we did in the Chevalier de Méré example from Lesson 5. \\[\\begin{align*} P(\\text{at least 1 ⚅ in 6 rolls}) &amp;= 1 - P(\\text{0 ⚅s in 6 rolls}) \\\\ &amp;= 1 - \\frac{5^6}{6^6} \\\\ &amp;\\approx .665 \\end{align*}\\] However, the probabilities of the other two events are trickier to calculate. For example, it is not obvious how to count the number of ways to get exactly 2 sixes in 18 dice rolls. In this lesson, we learn how this is done. Theory In this lesson, we learn another named distribution that is virtually identical to the hypergeometric distribution, except in one important detail: the draws are made with replacement instead of without replacement. Theorem 13.1 (Binomial Distribution) If a random variable can be described as the number of \\(\\fbox{1}\\)s in \\(n\\) random draws, with replacement, from the box \\[ \\overbrace{\\underbrace{\\fbox{0}\\ \\ldots \\fbox{0}}_{N_0}\\ \\underbrace{\\fbox{1}\\ \\ldots \\fbox{1}}_{N_1}}^N, \\] then its p.m.f. is given by \\[\\begin{equation} f(x) = \\dfrac{\\binom{n}{x} N_1^x N_0^{n-x}}{N^n}, x=0, ..., n, \\tag{13.1} \\end{equation}\\] where \\(N = N_1 + N_0\\) is the number of tickets in the box. We say that the random variable has a \\(\\text{Binomial}(n, N_1, N_0)\\) distribution, and \\(n\\), \\(N_1\\), \\(N_0\\) are called parameters of the distribution. Equivalently, (13.1) can be written as \\[\\begin{equation} f(x) = \\binom{n}{x} p^x (1 - p)^{n-x}, x=0, ..., n, \\tag{13.2} \\end{equation}\\] where \\(p = N_1 / N\\) is the proportion of \\(\\fbox{1}\\)s in the box. We will derive the formulas (13.1) and (13.2) later in this lesson. For now, let’s see how these formulas allow us to avoid calculations. Example 13.1 (The Newton-Pepys Problem) Let’s model each die roll as a draw from a box. Each die has \\(6\\) equally likely outcomes, so we place \\(N=6\\) tickets into the box. Since we are only interested in the number of ⚅s, we will label only one these tickets \\(\\fbox{1}\\), corresponding to a ⚅; the other five tickets will be labeled \\(\\fbox{0}\\). \\[ \\fbox{$\\fbox{1}\\ \\fbox{0}\\ \\fbox{0}\\ \\fbox{0}\\ \\fbox{0}\\ \\fbox{0}$} \\] To model 12 rolls of the die, we draw \\(n=12\\) tickets with replacement. We draw with replacement so that the outcome of one die roll does not affect the outcome of another. In other words, we want the dice rolls to be independent, and drawing with replacement is the only way to model independence. The number of \\(\\fbox{1}\\)s in these 12 draws represents the number of ⚅s that one would get in 12 rolls of a fair die. Therefore, by Theorem 13.1, we now know that the number of ⚅s in 12 rolls follows a \\(\\text{Binomial}(n=5, N_1=1, N_0=5)\\) distribution. We can now write down the p.m.f. by plugging the values of the parameters \\(n\\), \\(N_1\\), \\(N_0\\) into (13.1): \\[ f(x) = \\frac{\\binom{12}{x} 1^x 5^{12-x}}{6^{12}}, x=0, 1, \\ldots, 12. \\] Equivalently, we have \\(p = N_1/N = 1/6\\), and plugging in the values of the parameters \\(n\\) and \\(p\\) into (13.2), we have: \\[ f(x) = \\binom{12}{x} \\left(\\frac{1}{6}\\right)^x \\left(\\frac{5}{6} \\right)^{12-x}, x=0, 1, \\ldots, 12. \\] Both formulas should produce the same probabilities. To answer Pepys’ question about the probability of getting at least 2 ⚅s in 12 rolls, we combine the binomial distribution with the complement rule, \\[\\begin{align*} P(X \\geq 2) &amp;= 1 - P(X \\leq 1) \\\\ &amp;= 1 - (f(0) + f(1)) \\\\ &amp;= 1 - \\binom{12}{0} \\left(\\frac{1}{6}\\right)^0 \\left(\\frac{5}{6} \\right)^{12} - \\binom{12}{1} \\left(\\frac{1}{6}\\right)^1 \\left(\\frac{5}{6} \\right)^{11} \\\\ &amp;= 1 - \\left(\\frac{5}{6} \\right)^{12} - 12 \\left(\\frac{1}{6}\\right) \\left(\\frac{5}{6} \\right)^{11} \\\\ &amp;\\approx .6187. \\end{align*}\\] Now, let’s derive the p.m.f. of the binomial distribution. Proof. There are \\(N^n\\) ordered ways to choose \\(n\\) tickets from \\(N\\) with replacement. Recall from Lesson 4 that when sampling with replacement, we must count ordered outcomes, since the unordered outcomes are not all equally likely. Let’s start by counting the number of outcomes that look like \\[\\begin{equation} \\underbrace{\\fbox{1}, \\ldots, \\fbox{1}}_{x}, \\underbrace{\\fbox{0}, \\ldots, \\fbox{0}}_{n-x}, \\tag{13.3} \\end{equation}\\] in this exact order. There are \\(N_1\\) choices for the first \\(\\fbox{1}\\), \\(N_1\\) choices for the second \\(\\fbox{1}\\), and in fact, \\(N_1\\) choices for all \\(x\\) \\(\\fbox{1}\\)s, since we are drawing with replacement. Likewise, there are \\(N_0\\) choices for all \\(n-x\\) \\(\\fbox{0}\\)s. By the multiplication principle of counting (Theorem 1.1), there are \\[\\begin{equation} N_1^x \\cdot N_0^{n-x}. \\tag{13.4} \\end{equation}\\] ways to get an outcome like (13.3), in that exact order. However, because we are counting ordered outcomes, we also need to account for the possibility that the \\(\\fbox{1}\\)s and \\(\\fbox{0}\\)s were drawn in a different order than (13.3). There are \\(\\binom{n}{x}\\) ways to reorder the \\(\\fbox{1}\\)s and \\(\\fbox{0}\\)s, each of which can be obtained in (13.4) ways. So the total number of (ordered) ways to get \\(x\\) \\(\\fbox{1}\\)s and \\(n-x\\) \\(\\fbox{0}\\)s is \\[ \\binom{n}{x} \\cdot N_1^x \\cdot N_0^{n-x}. \\] So the p.m.f. can be written as \\[ f(x) = P(X = x) = \\frac{\\binom{n}{x} \\cdot N_1^x \\cdot N_0^{n-x}}{N^n}. \\] To see that this formula is the same as (13.2), we write \\(N^n = N^x \\cdot N^{n-x}\\). Then, we have: \\[\\begin{align*} f(x) &amp;= \\binom{n}{x}\\frac{N_1^x \\cdot N_0^{n-x}}{N^x \\cdot N^{n-x}} \\\\ &amp;= \\binom{n}{x} \\left( \\frac{N_1}{N} \\right)^x \\left( \\frac{N_0}{N} \\right)^{n-x} \\\\ &amp;= \\binom{n}{x} p^x (1 - p)^{n-x}, \\end{align*}\\] where in the last line, we used the fact that \\(\\frac{N_0}{N} = \\frac{N - N_1}{N} = 1 - \\frac{N_1}{N} = 1 - p\\). Graphing Let’s graph the binomial distribution for different values of \\(n\\), \\(N_1\\), and \\(N_0\\). First, we hold the number of draws constant at \\(n=5\\) and vary the composition of the box. The distribution shifts, depending on the composition of the box. The more \\(\\fbox{1}\\)s there are in the box, the more \\(\\fbox{1}\\)s in the sample. Next, we study how the distribution changes as a function of \\(n / N\\), the relative fraction of draws we make from the box. For all of the graphs below, \\(N_1 = N_0 = N/2\\). In contrast to the hypergeometric distribution, the binomial distribution does not change when we vary the number of tickets in the box, as long as we keep the relative proportions of \\(\\fbox{1}\\)s and \\(\\fbox{0}\\)s the same. This makes sense because we are drawing with replacement, so it does not matter how many draws we make; the box always looks the same. The binomial distribution is indifferent to the exact number of tickets \\(N\\) in the box. For example, to model a coin toss, we could use \\[ \\displaystyle \\fbox{\\(\\fbox{1}\\ \\fbox{0}\\)} \\] or \\[ \\displaystyle \\fbox{\\(\\fbox{1}\\ \\fbox{1}\\ \\fbox{0}\\ \\fbox{0}\\)}. \\] Although the first box is more natural, the second box is equally valid. Any box with the same number of \\(\\fbox{1}\\)s as \\(\\fbox{0}\\)s can be used to model a coin toss, since they all guarantee a 50% chance of drawing a \\(\\fbox{1}\\). The fact that the binomial distribution does not depend on \\(N\\) should not be surprising not surprising, in light of @ref{eq:binomial2}, which shows that the binomial p.m.f. can be written solely in terms of \\(p = N_1 / N\\), the proportion of \\(\\fbox{1}\\)s in the box. Calculating Binomial Probabilities on the Computer Calculating binomial probabilities by hand can be unwieldy when \\(n\\) is large. Fortunately, the binomial distribution is built into many software packages. For example, suppose we want to solve the following problem. Example 13.2 (Parity Checks) Messages that are exactly 50-bits long are regularly sent over a noisy communication channel. Each bit has a 1% chance of being corrupted by the channel. That is, the receiver saw a \\(0\\) where the original message had a \\(1\\), and vice versa. Each bit is corrupted independently of any other bit. To help detect errors, a 51st bit, called a parity bit, is sent along with the message. This bit is chosen to make the sum of all 51 bits come out to an even integer. When the receiver receives the message, she can calculate the sum of all 51 bits herself. If the sum is odd, then she knows that the message has been corrupted and can ask the sender to resend the message. This is called a parity check. The parity check works if exactly one bit is corrupted. However, if exactly two bits are corrupted, then the sum of all 51 bits will be even, and hence the errors will not be detected by the receiver. In general, errors will not be detected if an even number of bits are corrupted. What is the probability that a corrupted message goes undetected? Solution. First, we will set up a box model for the number of corrupted bits. We have a box with \\(N_0 = 99\\) tickets labeled \\(\\fbox{0}\\) \\(N_1 = 1\\) tickets labeled \\(\\fbox{1}\\) to represent the 1% chance that each bit is corrupted. We will draw 51 times from this box to represent the 51 bits in the message. We draw with replacement, since the bits are corrupted independently. Then, the number of \\(\\fbox{1}\\)s corresponds to the number of corrupted bits. Therefore, we know that the number of corrupted bits, which we will call \\(X\\), follows a \\(\\text{Binomial}(n=51, N_1=1, N_0=99)\\) distribution. The probability that a corrupted message goes undetected is the probability that \\(X\\) is positive and even. (If \\(X=0\\), then the message was not corrupted in the first place. If \\(X\\) is odd, then the error will be caught by the parity check.) To calculate this probability, we sum the p.m.f. over the relevant values: \\[\\begin{align*} P(\\text{corrupted message goes undetected}) &amp;= P(\\text{$X$ is positive and even}) \\\\ &amp;= f(2) + f(4) + f(6) + \\ldots + f(50) \\end{align*}\\] This would require evaluating the p.m.f. at 25 different values! This is a job for a computer, not a human. Here’s how we would calculate the probability using the Python library Symbulate. We first specify the parameters of the binomial distribution. Note that Symbulate requires that the parameters be \\(n\\) and \\(p\\), so we have to do a bit of conversion. Then, we create a list of the positive even values and evaluate the p.m.f. at all of these values, in one fell swoop, using the .pmf() method. from symbulate import * probs = Binomial(n=51, p=0.01).pmf(range(2, 51, 2)) probs ## array([7.79174480e-02, 1.55818996e-03, 1.14573571e-05, 4.13324569e-08, ## 8.46244910e-11, 1.07274277e-13, 8.91255091e-17, 5.04689904e-20, ## 2.00253338e-23, 5.67792557e-27, 1.16616574e-30, 1.75027722e-34, ## 1.92868014e-38, 1.56177790e-42, 9.26787459e-47, 4.00356955e-51, ## 1.24511721e-55, 2.74244677e-60, 4.17928311e-65, 4.26413949e-70, ## 2.77920480e-75, 1.07909959e-80, 2.23393269e-86, 2.02064767e-92, ## 5.04900000e-99]) To add these probabilities, we call sum(): sum(probs) ## 0.07948713677652883 You can play around with the Python code in this Colab notebook. It is also possible to do this calculation in R, a statistical programming language. Note that R uses the names size= and prob= for \\(n\\) and \\(p\\), respectively. We create a list of the positive even integers from 2 to 51, and evaluate the binomial p.m.f. at these values. probs &lt;- dbinom(seq(from=2, to=51, by=2), size=51, prob=0.01) probs ## [1] 7.791745e-02 1.558190e-03 1.145736e-05 4.133246e-08 8.462449e-11 ## [6] 1.072743e-13 8.912551e-17 5.046899e-20 2.002533e-23 5.677926e-27 ## [11] 1.166166e-30 1.750277e-34 1.928680e-38 1.561778e-42 9.267875e-47 ## [16] 4.003570e-51 1.245117e-55 2.742447e-60 4.179283e-65 4.264139e-70 ## [21] 2.779205e-75 1.079100e-80 2.233933e-86 2.020648e-92 5.049000e-99 To add these probabilities, we call sum(): sum(probs) ## [1] 0.07948714 You can play around with the R code in this Colab notebook. Essential Practice Show Mr. Pepys that C (at least 3 ⚅s in 18 rolls) is actually the least likely of the three options. About 10% of passengers who are scheduled to take a particular flight fail to show up. For this reason, airlines overbook flights, selling more tickets than they have seats, with the expectation that they will have some no shows. An airline with seating for 100 passengers sells 110 tickets for the flight. What is the probability that they will have enough seats for all the passengers for all of the passengers who show up for the flight? (Assume that passengers independently show up for the flight. Can you think of a situation where this would not be a reasonable assumption?) In the World Series of baseball, two teams (call them A and B) play a sequence of games against each other, and the first team to win four games wins the series. Suppose team \\(A\\) is slightly better, with a \\(0.6\\) probability of winning each game, and assume the games are independent. What is the probability that team \\(A\\) wins the series? (Hint: After 7 games, one of the teams must have won the Series. Even though the teams only play until one team has won four games, this calculation is easiest if you assume that the teams always play 7 games.) Additional Exercises "]
]
