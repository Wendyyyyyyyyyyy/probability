[
["index.html", "Introduction to Probability Preface", " Introduction to Probability Dennis Sun 2020-08-14 Preface "],
["counting.html", "Lesson 1 Probability and Counting Motivating Example Theory Examples Additional Exercises", " Lesson 1 Probability and Counting Motivating Example In 1620, the Grand Duke of Tuscany asked the astronomer and mathematician Galileo to determine whether the numbers on three fair dice are more likely to add up to 9 or 10. Theory Definition 1.1 (Definition of Probability) If all possible outcomes are equally likely, then the probability of an event \\(A\\) is \\[ P(A) = \\frac{\\text{number of outcomes where $A$ occurs}}{\\text{number of possible outcomes}}. \\] For example, suppose we want to know the probability of getting an even number when we roll a fair die. There are \\(6\\) equally likely possible outcomes, ⚀ ⚁ ⚂ ⚃ ⚄ ⚅, of which 3 are even. Therefore, the probability of rolling an even number is \\[ P(\\text{even number}) = \\frac{\\text{number of outcomes that are even}}{\\text{number of possible outcomes}} = \\frac{3}{6}. \\] Next, suppose we want to know the probability of rolling a 7 when we roll two fair dice. There are 36 equally likely outcomes, ⚀⚀ ⚁⚀ ⚂⚀ ⚃⚀ ⚄⚀ ⚅⚀ ⚀⚁ ⚁⚁ ⚂⚁ ⚃⚁ ⚄⚁ ⚅⚁ ⚀⚂ ⚁⚂ ⚂⚂ ⚃⚂ ⚄⚂ ⚅⚂ ⚀⚃ ⚁⚃ ⚂⚃ ⚃⚃ ⚄⚃ ⚅⚃ ⚀⚄ ⚁⚄ ⚂⚄ ⚃⚄ ⚄⚄ ⚅⚄ ⚀⚅ ⚁⚅ ⚂⚅ ⚃⚅ ⚄⚅ ⚅⚅ of which 6 outcomes add up to 7. (Check this for yourself!) Therefore, the probability of rolling a 7 is \\[ P(\\text{sum is 7}) = \\frac{\\text{number of outcomes where the sum is 7}}{\\text{number of possible outcomes}} = \\frac{6}{36}. \\] Galileo needed to consider the possible outcomes when three dice are rolled. At this point, listing all of the possible outcomes is impractical. We need to find a way to count the number of outcomes without listing all of them. Here is a way to see that there are 36 ways to roll two dice, without listing them out. There are 6 possible outcomes for the first die, and each of these 6 outcomes can be paired with 6 possible outcomes for the second die. Therefore, there must be \\(6 \\cdot 6 = 36\\) ways to roll two dice. The following theorem generalizes this principle. Theorem 1.1 (Multiplication Principle of Counting) If a task can be performed in \\(n_1\\) ways, and for each of these ways, a second task can be performed in \\(n_2\\) ways, then the two tasks can be performed together in a total of \\(n_1 \\cdot n_2\\) ways. Proof. List the outcomes in a table, with \\(n_1\\) columns and \\(n_2\\) rows (like we did above for the possible outcomes of two dice, where \\(n_1 = n_2 = 6\\)). Each column corresponds to one of the \\(n_1\\) possible outcomes of the first task, each row to one of the \\(n_2\\) possible outcomes of the second. There are \\(n_1 \\cdot n_2\\) cells in the table. Using the multiplication principle, we can count the total number of ways of rolling three dice. We already know that there are 36 ways that the first two dice can come out. Each of these 36 ways can be matched with each of the 6 ways that the third dice can come out. Therefore, by Theorem @ref{thm:multiplication-principle}, there are \\[ 36 \\cdot 6 = 216 \\] ways the three dice could come out. Using the multiplication principle, we can calculate the probability that no sixes are rolled among the three dice. In order for there to be no sixes, each of the three dice must have shown one of the other 5 numbers. The number of ways for this to happen is \\[ 5 \\cdot 5 \\cdot 5 = 125, \\] so the probability is \\[ P(\\text{no sixes}) = \\frac{125}{216} \\approx 57.8\\%. \\] Now, Galileo was interested in the event that the numbers add up to 9, which is much trickier to count. We will come back to his question in a future lesson, once we have more counting tools under our belt. Examples In the casino game craps, two dice are rolled by a player, called the “shooter”. The first roll is called the “come-out roll”. The shooter wins on the come-out roll if they roll a 7 or a 11. On the other hand, they lose if the come-out roll is a 2, 3, or 12. Otherwise, the game continues. What is the probability that the shooter wins on the come-out roll? What is the probability that the shooter loses on the come-out roll? What is the probability that the game continues? If you add up the three probabilities you just calculated, what do you get? Why does this make sense? Many examples in this book will be based on a standard deck of 52 playing cards, consisting of 13 cards of each suit. Familiarize yourself with the terminology. Suppose you draw one card from a shuffled deck of cards. What is the probability that the card is a heart? What is the probability that the card is an ace? What is the probability that the card is a face card (also known as a “court card”)? Many examples in this book will be based on the casino game roulette. Familiarize yourself with the roulette wheel. (Click the wheel to spin it.) You win if the ball lands in a pocket that matches your bet. What is the probability that you win if you bet on red? What is the probability that you win if you bet on the number 10? What is the probability that you win if you bet on odd (i.e., that the number is odd)? In standard poker, each player is dealt 5 cards off the top of a (shuffled) deck of cards. The hand is called a “flush” if all 5 cards are the same suit. What is the probability that you get a flush of hearts (i.e., all 5 cards are hearts)? Additional Exercises "],
["factorial.html", "Lesson 2 The Factorial Motivating Example Theory Examples Additional Exercises", " Lesson 2 The Factorial Motivating Example How many ways are there to arrange a deck of 52 cards? Theory We can use the multiplication rule to determine the number of ways to arrange the deck. The first card can be any one of 52 cards. No matter which one it is, the second card can be any one of the remaining 51 cards. So there are \\(52 \\cdot 51\\) ways to choose the first 2 cards. For every one of these \\(52 \\cdot 51\\) ways, there are \\(50\\) remaining cards to choose as the third card, which makes \\(52 \\cdot 51 \\cdot 50\\) ways to choose the first 3 cards. And so on. By the time we get to the last card in the deck, there is only \\(1\\) card left. So there are \\[ 52 \\cdot 51 \\cdot 50 \\cdot \\ldots \\cdot 2 \\cdot 1 \\] ways to arrange the 52 cards in a deck. This is such an important quantity in probability and counting that it has been given a special name. Definition 2.1 (Factorial) The quantity \\(n!\\) (pronounced: “n factorial”) is defined as \\[ n! = n \\cdot (n-1) \\cdot \\ldots \\cdot 1. \\] It represents the number of ways to arrange \\(n\\) objects. So the number of ways to arrange a deck of cards can be expressed as \\(52!\\). Using Wolfram Alpha, we can calculate this to be about \\(8 \\times 10^{67}\\), an astronomical number. In particular, it is greater than: the number of seconds since the universe began. the number of atoms on Earth. So the next time you hold a shuffled deck of cards in your hands, spend a moment appreciating the fact that you are holding an arrangement that has likely never before existed in the history of the universe. Examples Each year, as part of a “Secret Santa” tradition, a group of 4 friends write their names on slips of papers and place the slips into a hat. Each member of the group draws a name at random from the hat and must by a gift for that person. Of course, it is possible that they draw their own name, in which case they buy a gift for themselves. What is the probability that everyone in the group ends up buying a gift for themselves? (Note that the names are not placed back in the hat once they are drawn, so each person receives exactly one gift.) A deck of 52 cards is shuffled thoroughly. What is the probability that the four aces are all next to each other? (Hint: First, count the number of positions that the block of four aces can go, then multiply this by the number of ways of ordering the four aces.) If a five-letter word is formed at random (meaning that all sequences of five letters are equally likely), what is the probability that no letter occurs more than once? The “bootstrap” is a statistical method for generating a new data set that is like an existing one. Suppose we have a data set consisting of \\(6\\) observations: \\(x_1, x_2, x_3, x_4, x_5, x_6\\). To generate a “bootstrap” data set, we sample from the original data set with replacement, meaning that it is possible for each observation to be sampled more than once. Examples of bootstrap data sets include: \\[\\begin{align*} x_4, x_2, x_4, x_3, x_2, x_4 \\\\ x_3, x_1, x_6, x_1, x_1, x_2 \\\\ x_2, x_1, x_4, x_3, x_6, x_5 \\end{align*}\\] Notice that in the last example, each observation appears exactly once. What is the probability that the bootstrap data set contains each observation exactly once? Additional Exercises "],
["box-models.html", "Lesson 3 Box Models and Combinations Motivating Example Theory Essential Practice Additional Practice", " Lesson 3 Box Models and Combinations Motivating Example One of the most coveted hands in poker is a four-of-a-kind, which is when the hand contains all four cards of a particular rank. For example, the hand below is an example of a four-of-a-kind, since it contains all four 7s in the deck. (The last card, called the “kicker”, can be any other card.) In this lesson, we will calculate the probability of a four-of-a-kind in two ways: (1) using methods that we have already learned and (2) using combinations, which is a new method that will be introduced in this lesson. Theory Many counting and probability problems can be reduced to a box model. In a box model, there are \\(N\\) tickets in a box, and we draw \\(n\\) tickets from the box. For example, three rolls of a fair die can be modeled as \\(n=3\\) draws from the box \\[ \\fbox{$\\fbox{1}\\ \\fbox{2}\\ \\fbox{3}\\ \\fbox{4}\\ \\fbox{5}\\ \\fbox{6}$}. \\] In order to accurately model how dice behave (i.e., the outcome of one die roll does not affect the outcome of another), we have to place the ticket back in the box after each draw. In other words, the \\(n=3\\) draws are made with replacement. In other situations, the draws are made without replacement. For example, consider four friends who draw names from a hat to determine whom each person’s Secret Santa is. If we call the four friends “1”, “2”, “3”, and “4” (their actual names are unimportant, as far as probability is concerned), then we can model the Secret Santa game as \\(n=4\\) draws from the box \\[ \\fbox{$\\fbox{1}\\ \\fbox{2}\\ \\fbox{3}\\ \\fbox{4}$}. \\] Since every person has exactly one Secret Santa, the draws must be made without replacement. Once a Secret Santa has been chosen for person 3, we remove \\(\\fbox{3}\\) from the box so that they do not end up with two Secret Santas. Using the multiplication principle (Theorem 1.1), we can count the number of ways to draw \\(n\\) tickets from the box \\[ \\fbox{$\\fbox{1}\\ \\fbox{2}\\ \\ldots\\ \\fbox{\\(N\\)}$}. \\] If drawing with replacement, the number of possible ways is \\[ \\underbrace{N \\cdot N \\cdot N \\cdot \\ldots \\cdot N}_{\\text{$n$ terms}} = N^n, \\] since we have \\(N\\) tickets to choose from on each draw. If drawing without replacement, the number of possible ways is \\[ \\underbrace{N \\cdot (N-1) \\cdot (N-2) \\cdot \\ldots \\cdot (N-n+1)}_{\\text{$n$ terms}} = \\frac{N!}{(N-n)!}, \\] since the number of tickets remaining in the box decreases by 1 on each draw. For example, if we assign a number 1 to 52 to each card in a standard playing deck, then a poker hand can be modeled as \\(n=5\\) draws, without replacement, from the box \\[ \\fbox{$\\fbox{1}\\ \\fbox{2}\\ \\ldots\\ \\fbox{52}$}. \\] The number of possible poker hands is \\[ \\frac{52!}{(52-5)!} = 52 \\cdot 51 \\cdot 50 \\cdot 49 \\cdot 48 = 311,875,200. \\] How many of these possible outcomes result in a four-of-a-kind? Here is the reasoning: Let’s start by assuming that the first four cards in the hand are the four-of-a-kind and the last card is the kicker. The first card can be any one of the 52 cards. Once we have chosen the first card, the rank of the four-of-a-kind is determined. The second card must be one of the 3 remaining cards of the same rank. The third card must be one of the 2 remaining cards of that rank. The fourth card must be the 1 remaining card of that rank. The last card, the kicker, is one of the other 48 cards in the deck. We assumed that the kicker was the last card in the hand. But the kicker could just as well have been the first card in the hand. In fact, the kicker could have been in any one of 5 positions. So we need to multiply everything by 5 in the end. So the probability of a four-of-a-kind is \\[ \\frac{(52 \\cdot 3 \\cdot 2 \\cdot 1 \\cdot 48) \\cdot 5}{52 \\cdot 51 \\cdot 50 \\cdot 49 \\cdot 48} \\approx .00024. \\] This calculation was complicated because we had to consider the different orders in which the cards might be drawn. It is often easier to ignore the order when counting outcomes. That is, we treat \\(\\fbox{1}\\ \\fbox{3}\\ \\fbox{4}\\ \\fbox{5}\\ \\fbox{8}\\) as the same outcome as \\(\\fbox{3}\\ \\fbox{5}\\ \\fbox{4}\\ \\fbox{1}\\ \\fbox{8}\\); we do not double count different reorderings of the same draws. Fortunately, when the draws are made without replacement, the unordered outcomes are also equally likely, so it is equally valid to count unordered outcomes as ordered ones for the purposes of calculating probabilities. If we ignore order when counting, we say that “order doesn’t matter”. Theorem 3.1 (Combinations) The number of ways to draw \\(n\\) tickets from the box \\[ \\fbox{$\\fbox{1}\\ \\fbox{2}\\ \\ldots\\ \\fbox{\\(N\\)}$}, \\] when order doesn’t matter, is symbolized \\(\\binom{N}{n}\\) (pronounced: “\\(N\\) choose \\(n\\)”) and is equal to \\[\\begin{equation} \\binom{N}{n} = \\frac{N!}{n! (N-n)!}. \\tag{3.1} \\end{equation}\\] Proof. We know that any set of \\(n\\) distinct objects can be reordered in \\(n!\\) ways. So when we count different reorderings of the same set of \\(n\\) tickets, we end up counting each set of distinct tickets \\(n!\\) times. By the multiplication principle (Theorem 1.1): \\[\\begin{align*} \\left(\\text{# ways when order matters}\\right) &amp;= \\left(\\text{# ways when order doesn&#39;t matter}\\right) \\cdot n!. \\end{align*}\\] But we already know the left-hand side of this equation, the number of ways to draw \\(n\\) tickets without replacement when order matters: it is \\(\\frac{N!}{(N-n)!}\\). Solving for the unknown in this equation, we end up with: \\[\\begin{align*} \\binom{N}{n} \\overset{\\text{def}}{=} \\left(\\text{# ways when order doesn&#39;t matter}\\right) &amp;= \\frac{\\left(\\text{# ways when order matters}\\right)}{n!} \\\\ &amp;= \\frac{N!}{n! (N-n)!} \\end{align*}\\] Example 3.1 (Commitee Chair Example) How many different chaired commitees of \\(k\\) people can be formed from \\(m\\) people? A “chaired committee” is a committee where one person has been designated as chair. Two possible committees consisting of the same \\(k\\) people are considered different if they have different chairs. One way to form the chaired committee is to first choose the \\(k\\) people, and then designate one of the \\(k\\) people as chair. By the multiplication principle (Theorem 1.1), there are \\[ \\binom{m}{k} \\cdot k \\] ways to do this. (Note that we only care about who is on the committee, not the order in which they were selected to be on the committee, so for the purposes of this problem, order does not matter.) Another way to form the chaired committee is to first choose one of the \\(m\\) people to be chair, and then choose the \\(k-1\\) other members from the remaining \\(n-1\\) people. There are \\[ m \\cdot \\binom{m-1}{k-1} \\] ways to do this. Both answers are correct, so they must be equal to one another, yielding the useful combinatorial identity \\[\\begin{equation} k \\binom{m}{k} = m \\binom{m-1}{k-1}. \\tag{3.2} \\end{equation}\\] The “story proof” (about the chaired committee) proves this identity. Of course, we could also prove this identity by expanding the combinations using (3.1) and simplifying. One of the Essential Practice problems asks you to do this. However, this algebraic proof does not give much insight into why the identity is true. The story proof gives us the insight that will help us remember this identity in the future. We will use this combinatorial identity many times throughout this book. Now, let’s revisit the probability of a four-of-a-kind using combinations. If we ignore the order of the cards in the hand, there are \\[ \\binom{52}{5} = 2,598,960. \\] possible poker hands. (Binomial coefficients can be calculated using Wolfram Alpha.) Notice how much smaller this number is than the 300+ million ordered poker hands. That is because when order matters, each distinct (unordered) poker hand gets counted \\(5! = 120\\) times, once for each possible way of reordering the 5 cards in the hand. How many “unordered” four-of-a-kind hands are there? Here is how to count them: There are 13 ranks (Ace through King). Any one of these ranks could be the rank for the four-of-a-kind. Once we have chosen the rank, that completely determines 4 of the 5 cards in the four-of-a-kind hand. There is only one way to include all 4 cards of a given rank, since we are no longer concerned with the order in which they are drawn or their position in the hand. So all that’s left is to choose the kicker, which can be any one of the remaining 48 cards. So when we ignore order, there are \\[ 13 \\cdot 48 = 624 \\] ways to get a four-of-a-kind. The probability is therefore \\[ \\frac{13 \\times 48}{\\binom{52}{5}} = \\frac{624}{2,598,960} \\approx .00024, \\] which matches the answer from before. Notice how much simpler \\(13 \\cdot 48\\) is, compared with the mental gymnastics needed to account for the order. Essential Practice Prove the identity (3.2) by expanding the combinations using (3.1) and simplifying. Prove the identity \\[ \\binom{m}{k} = \\binom{m}{m-k} \\] in two ways: using a “story proof” (as in Example 3.1) and using algebra. Calculate \\(\\binom{m}{1}\\). Why does this answer make sense? In Lesson 1, you calculated the probability of a “flush of hearts” in poker by counting the possible hands. There, you took order into account. Repeat the calculation by counting the possible hands where order does not matter. How many different 8-letter “words” can be formed by rearranging the letters in LALALAAA? (Hint: Model this situation using \\(n=3\\) draws from the box \\(\\fbox{\\(\\fbox{1}\\ \\fbox{2}\\ \\ldots\\ \\fbox{8}\\)}\\). The tickets that you draw correspond to the positions of the three Ls. So, for example, drawing \\(\\fbox{3}, \\fbox{1}, \\fbox{5}\\) corresponds to the word LALALAAA. You still need to figure out whether the draws should be made with replacement and whether you should count different orderings of the same 3 tickets.) You toss a coin 60 times. Each toss results in two equally likely outcomes, heads or tails. What is the probability that you get exactly 30 heads in the 60 tosses? (Hint: To count the number of ways of getting exactly 30 heads, you need to count the number of ways of arranging 30 H and 30 Ts. The general strategy from the previous question may be helpful here.) Additional Practice Use a story proof to show that \\[ x(x-1) \\binom{n}{x} = n (n-1) \\binom{n-2}{x-2}. \\] (Hint: Consider selecting a committee with a chair and a vice-chair.) "],
["replacement.html", "Lesson 4 Sampling With Replacement Motivating Example Discussion Examples Bonus Material", " Lesson 4 Sampling With Replacement Motivating Example Recall Galileo’s problem from Lesson 1. He wanted to know whether a sum of 9 or a sum of 10 was more likely when 3 dice are rolled. In fact, Galileo’s peers reasoned that the two events should be equally likely, since there are six ways to get a sum of 9 \\[\\begin{align*} 3 + 3 + 3 &amp; &amp; 2 + 3 + 4 &amp; &amp; 2 + 2 + 5 &amp; &amp; 1 + 4 + 4 &amp; &amp; 1 + 3 + 5 &amp; &amp; 1 + 2 + 6 \\end{align*}\\] and also six ways to get a sum of 10: \\[\\begin{align*} 3 + 3 + 4 &amp; &amp; 2 + 4 + 4 &amp; &amp; 2 + 3 + 5 &amp; &amp; 2 + 2 + 6 &amp; &amp; 1 + 4 + 5 &amp; &amp; 1 + 3 + 6 \\end{align*}\\] But gamblers of the day knew better. From experience, they knew that a sum of 10 was more likely than a sum of 9. But where did Galileo’s peers go wrong in their reasoning? Discussion Recall from Lesson 3 that the three rolls of a die can be modeled as \\(n=3\\) draws with replacement from the box \\[ \\fbox{$\\fbox{1}\\ \\fbox{2}\\ \\fbox{3}\\ \\fbox{4}\\ \\fbox{5}\\ \\fbox{6}$}. \\] Galileo’s peers showed that there are 6 ways to get a sum of 9 if you ignore the order in which the tickets were drawn. (Notice that they included 2 + 3 + 5, but not 3 + 5 + 2 and other orderings of the same three rolls.) They also showed that there are 6 ways to get a sum of 10. Why does this not guarantee the probabilities of the two events are the same? Notice that this case (draws with replacement, order doesn’t matter) is one that we have not studied yet. with replacement without replacement order matters \\(N^n\\) \\(\\frac{N!}{(N-n)!}\\) order doesn’t matter ??? \\(\\binom{N}{n} = \\frac{N!}{n!(N-n)!}\\) To settle the question, let’s go back to counting ordered outcomes. The outcome \\(2 + 3 + 4\\) corresponds to \\(3! = 6\\) outcomes, when you account for the possible orderings: \\(2 + 3 + 4\\) \\(2 + 4 + 3\\) \\(3 + 2 + 4\\) \\(3 + 4 + 2\\) \\(4 + 2 + 3\\) \\(4 + 3 + 2\\) On the other hand, the outcome \\(2 + 2 + 5\\) can only be reordered \\(3\\) different ways: \\(2 + 2 + 5\\) \\(2 + 5 + 2\\) \\(5 + 2 + 2\\) And the outcome \\(3 + 3 + 3\\) only has one possible ordering. In other words, when we draw with replacement, the same ticket can be drawn more than once, and repetitions reduce the number of ways that tickets can be reordered. The problem with simply counting the number of outcomes is that the 6 outcomes \\[\\begin{align*} 3 + 3 + 3 &amp; &amp; 2 + 3 + 4 &amp; &amp; 2 + 2 + 5 &amp; &amp; 1 + 4 + 4 &amp; &amp; 1 + 3 + 5 &amp; &amp; 1 + 2 + 6 \\end{align*}\\] are not all equally likely. \\(2 + 3 + 4\\) is twice as likely as \\(2 + 2 + 5\\) and six times as likely as \\(3 + 3 + 3\\). When draws are made with replacement, only ordered outcomes are equally likely. This was Galileo’s insight. When he took into account the number of possible orderings associated with each unordered outcome: \\[\\begin{array}{rr} \\hline \\text{Unordered Outcome} &amp; \\text{Possible Orderings} \\\\ \\hline 3 + 3 + 3 &amp; \\text{1 way}\\ \\\\ 2 + 3 + 4 &amp; \\text{6 ways} \\\\ 2 + 2 + 5 &amp; \\text{3 ways} \\\\ 1 + 4 + 4 &amp; \\text{3 ways} \\\\ 1 + 3 + 5 &amp; \\text{6 ways} \\\\ 1 + 2 + 6 &amp; + \\text{6 ways} \\\\ \\hline &amp; \\text{25 ways} \\end{array}\\] he found that the probability of a 9 was actually \\[ \\frac{25}{216}. \\] (Remember that there are \\(6^3 = 216\\) equally likely outcomes when order matters.) Repeating the calculation for the probability of a 10, Galileo showed that the two probabilities were indeed different. Examples Here’s a different illustration of the fact that not all unordered outcomes are equally likely when draws are made with replacement. In the Pick 3 Lotto, a winning number is chosen between 000 to 999. Contestants win if the digits in their chosen number matches the winning number, in any order. What is your chance of winning if you bet on 053? What is your chance of winning if you bet on 055? What is your chance of winning if you bet on 555? Complete the solution to Galileo’s problem. What is the probability that the sum is 10 when 3 fair dice are rolled? How does this compare with the probability that the sum is 9? Bonus Material You will rarely need to count the unordered ways that \\(n\\) tickets can be drawn with replacement, since the unordered outcomes are not equally likely. However, in case you are curious how this can be calculated, the following video explains how. This video is completely optional! "],
["double-counting.html", "Lesson 5 Double Counting Motivating Example Theory Examples", " Lesson 5 Double Counting Motivating Example The French nobleman (and avid gambler) Chevalier de Méré knew that betting on at least one six (⚅) in 4 rolls of a die was a favorable bet for him. Once other gamblers caught on, he devised a new bet: at least one double-six (⚅⚅) in 24 rolls of two dice. Although he did not know how to calculate the probabilities, he reasoned that the two bets should be equivalent, since double-sixes are \\(1/6\\) as likely as a single six, but there are \\(6\\) times as many rolls to compensate Are the two bets equivalent? Theory Here is a common (but wrong) way of calculating the probability of getting at least one six in 4 rolls of a die. \\[\\begin{align*} P(\\text{at least one ⚅}) &amp;= P(\\text{⚅ on 1st roll, or ⚅ on 2nd roll, or ⚅ on 3rd roll or ⚅ on 4th roll}) \\\\ &amp;= P(\\text{⚅ on 1st roll}) + P(\\text{⚅ on 2nd roll}) + P(\\text{⚅ on 3nd roll}) + P(\\text{⚅ on 4th roll}) \\\\ &amp;= \\frac{1}{6} + \\frac{1}{6} + \\frac{1}{6} + \\frac{1}{6} \\\\ &amp;= \\frac{4}{6} ? \\end{align*}\\] What’s wrong with the above reasoning? The problem is that \\[ P(A \\text{ or } B) \\neq P(A) + P(B) \\] in general. The reason is that \\(P(A) + P(B)\\) double counts outcomes where \\(A\\) and \\(B\\) both happen. For example, suppose \\(A\\) is “⚅ on 1st roll” and \\(B\\) is “⚅ on 2nd roll”. Then, it is not hard to see that the event \\(A \\text{ or } B\\) happens on 11 out of 36 outcomes, so \\[ P(A \\text{ or } B) = \\frac{11}{36} \\neq \\frac{12}{36} = \\frac{1}{6} + \\frac{1}{6} = P(A) + P(B). \\] \\(P(A) + P(B)\\) double counts the outcome where both rolls were ⚅s. Figure 5.1: Double Counting Dice Rolls One way to avoid double counting is to subtract the cases that are double counted. Theorem 5.1 (Inclusion-Exclusion Principle) \\[ P(A \\text{ or } B) = P(A) + P(B) - P(A \\text{ and } B) \\] Figure 5.2: Intuition for the Inclusion-Exclusion Principle So, for example: \\[\\begin{align*} P(\\text{at least one ⚅ in 2 rolls}) &amp;= P(\\text{⚅ on 1st roll}) + P(\\text{⚅ on 2nd roll}) - P(\\text{⚅ on both rolls}) \\\\ &amp;= \\frac{1}{6} + \\frac{1}{6} - \\frac{1}{36} \\\\ &amp;= \\frac{11}{36} \\end{align*}\\] However, this approach does not scale well to calculating the probability of at least one ⚅ in 4 rolls. In many situations, it is easier to calculate the probability that an event does not happen, also known as the complement of the event. Because the total probability has to be 1, the two probabilities are related by the following formula. Theorem 5.2 (Complement Rule) \\[ P(\\text{not } A) = 1 - P(A). \\] Let’s apply the Complement Rule to the Chevalier de Méré’s problem. To calculate the probability of getting at least one ⚅ in 4 rolls, we can calculate the probability of the complement. If we did not get at least one ⚅, that must mean that we got no ⚅s. This means that every roll was one of the other 5 outcomes. This probability is much easier to calculate using the counting tricks we have learned. \\[\\begin{align*} P(\\text{at least one ⚅}) &amp;= 1 - P(\\text{no ⚅s}) \\\\ &amp;= 1 - \\frac{5^4}{6^4} \\\\ &amp;\\approx 0.5177. \\end{align*}\\] Examples In poker, a “two pair” hand has 2 cards of one rank, 2 cards of another rank, and 1 card of a third rank. For example, the hand 2, 2, Q, Q, J is a “two pair”. Your friend calculates the probability of “two pair” as follows: There are \\(\\binom{52}{5}\\) equally likely hands (where order does not matter). We count the number of ways to choose the first pair. There are \\(13\\) choices for the rank and \\(\\binom{4}{2}\\) choices for the two cards within the rank, so there are \\(13 \\times \\binom{4}{2}\\) ways. Next, we count the ways to choose the second pair. Since one rank has already been chosen, there are \\(12 \\times \\binom{4}{2}\\) ways to do this. Finally, we choose the remaining card. There are \\(11 \\times \\binom{4}{1} = 44\\) ways to do this. Your friend calculates the probability as \\[ \\frac{13 \\times \\binom{4}{2} \\times 12 \\times \\binom{4}{2} \\times 44}{\\binom{52}{5}} \\approx .095, \\] but then finds online that the actual probability of “two pair” is only \\(.0475\\). This number is exactly half the probability that your friend got, so he suspects that he double-counted. But where? Complete the calculation for the Chevalier de Méré. Calculate the probability of getting at least one ⚅⚅ in 24 rolls of two dice. "],
["conditional.html", "Lesson 6 Conditional Probability Motivating Example Theory Examples Additional Exercises", " Lesson 6 Conditional Probability Motivating Example You know that your coworker has two children. Absent any other information, the probability that both are boys is \\(P(\\text{both boys}) = \\frac{1}{4}\\). One day, she mentions to you, “I need to stop by St. Joseph’s after work for a PTA meeting.” St. Joseph’s is a local all-boys school. So now you know that at least one of her children is a boy. What is the probability now that both her children are boys? Most people assume that the answer is \\(\\frac{1}{2}\\), since the other child is equally likely to be a boy or a girl, and the gender of one child does not affect the gender of another. The actual answer may surprise you…. Theory To quantify how probabilities change in light of new information, we calculate the conditional probability. \\[ P(\\text{both boys}\\ |\\ \\text{at least one boy}) \\] The \\(|\\) symbol is read “given” and the event after the \\(|\\) symbol represents information that we know. In general, to calculate a conditional probability, we use the following formula. Definition 6.1 (Conditional Probability) \\[ P(B | A) = \\frac{P(A \\textbf{ and } B)}{P(A)}. \\] The probability \\(P(A \\textbf{ and } B)\\) is called the joint probability of the two events \\(A\\) and \\(B\\). So the conditional probability above is \\[\\begin{align*} P(\\text{both boys}\\ |\\ \\text{at least one boy}) &amp;= \\frac{P(\\text{both boys} \\textbf{ and } \\text{at least one boy})}{P(\\text{at least one boy})} \\\\ &amp;= \\frac{P(\\text{both boys})}{P(\\text{at least one boy})} \\\\ &amp;= \\frac{1/4}{3/4} \\\\ &amp;= \\frac{1}{3}. \\end{align*}\\] In the above example, the joint probability \\(P(\\text{both boys} \\textbf{ and } \\text{at least one boy})\\) is easy to calculate because the two events are redundant. If we know that both are boys, then we automatically know that at least one is a boy. The information that at least one of her children attends St. Joseph’s (and, thus, is a boy) increases the probability that she has two boys from \\(1/4\\) to \\(1/3\\). If this result was counterintuitive to you, the video below gives some intuition. We can rearrange the conditional probability formula to get a formula that is useful for calculating the joint probability when the conditional probability is known. Theorem 6.1 (Multiplication Rule) \\[ P(A \\textbf{ and } B) = P(A) \\cdot P(B | A). \\] Example 6.1 Two cards are dealt off the top of a shuffled deck of cards. What is the probability that both are queens? Solution. In this case, we want to calculate the joint probability \\[ P(\\text{1st card is Q} \\textbf{ and } \\text{2nd card is Q}), \\] and the conditional probability \\[ P(\\text{2nd card is Q} | \\text{1st card is Q}) \\] is simple. If it is known that the 1st card was a queen, then there are only 51 cards remaining in the deck, of which 3 are queens, so \\[ P(\\text{2nd card is Q} | \\text{1st card is Q}) = \\frac{3}{51}. \\] By the Multiplication Rule (6.1), \\[\\begin{align*} P(\\text{1st card is Q} \\textbf{ and } \\text{2nd card is Q}) &amp;= P(\\text{1st card is Q}) \\cdot P(\\text{2nd card is Q} | \\text{1st card is Q}) \\\\ &amp;= \\frac{4}{52} \\cdot \\frac{3}{51} \\end{align*}\\] Let’s compare this with a solution based on counting the outcomes directly. There are \\(52 \\cdot 51\\) equally likely (ordered) outcomes, of which \\(4 \\cdot 3\\) are both queens. Therefore, the probability is \\[ P(\\text{1st card is queen} \\textbf{ and } \\text{2nd card is queen}) = \\frac{4 \\cdot 3}{52 \\cdot 51}. \\] We get the same answer; the only thing that changes is the order of operations: In counting, we first multiply to get the number of outcomes, then divide to get probabilities. In the multiplication rule, we first divide to get probabilities, then multiply the probabilities. Examples You and your friend Amy are each dealt two cards: hers face up and yours face down. In which of the following scenarios are you more likely to have a pair: when she has a pair of queens when she has a queen and a 5? Dr. No has captured James Bond and forces him to play a game of Russian roulette. (Note: Russian roulette is very different from the casino game roulette!) Dr. No shows him an revolver with 6 chambers, all initially empty. He places 2 bullets into adjacent chambers. He makes Bond spin the cylinder, place the muzzle against his head, and pull the trigger. He survives! Luckily for Bond, the cylinder stopped on one of the empty chambers. Now Dr. No gives Bond two options: he can re-spin the cylinder before firing again or he can fire with the gun in its current state. (Keep in mind that the cylinder rotates to the next chamber each time the gun is fired.) What option should Bond choose to maximize his chance of surviving? Clearly write out the conditional probability of interest using \\(P(B|A)\\) notation. Find the probability. (Hint: You should not need to do any calculations. You should be able to find the probability just by thinking carefully about the information you have. Make sure you explain your reasoning carefully.) Additional Exercises "],
["independence.html", "Lesson 7 Independence Motivating Example Theory Examples Additional Exercises", " Lesson 7 Independence Motivating Example Many gamblers believe that after a string of losses, they are “due” for a win. Consider a gambler who repeatedly bets on reds in roulette, an event with probability \\(18 / 38 \\approx 0.474\\). The ball has not landed in a red pocket on any of the last 4 spins of the wheel. Does this make it more likely that he will win on the next spin? This is really a conditional probability question in disguise. We want to know the probability that the ball will land in a red pocket on the 5th spin, given that it did not land in a red pocket on any of the first 4 spins: \\[ P(\\text{red on 5th spin}\\ |\\ \\text{not red on first 4 spins}). \\] Theory To verify that the two probabilities are exactly the same, we do the calculation: \\[\\begin{align*} P(\\text{red on 5th spin}\\ |\\ \\text{not red on first 4 spins}) &amp;= \\frac{P(\\text{not red on first 4 spins} \\textbf{ and } \\text{red on 5th spin}) }{P(\\text{not red on first 4 spins})} \\\\ &amp;= \\frac{ 20^4 \\cdot 18 \\big/ 38^5 }{20^4 \\big/ 38^4} \\\\ &amp;= \\frac{18}{38}. \\end{align*}\\] We see that the conditional probability is \\(18 / 38\\), which is the same as the probability that the 5th spin is red if we did not know the outcome of the first 4 spins. In mathematical notation, \\[\\begin{align*} P(\\text{red on 5th spin}\\ |\\ \\text{not red on first 4 spins}) &amp;= P(\\text{red on 5th spin}) \\end{align*}\\] When conditioning on one event (e.g., “not red on first 4 spins”) does not change the probability of another event (e.g., “red on 5th spin”), we say that the two events are independent. In this case, whether the gambler wins on the 5th spin is independent of the fact that he has lost each of the last 4 spins. The folk belief that one is “due” for a win after a series of losses is plain wrong and is known as the gambler’s fallacy. Definition 7.1 (Independence) Two events \\(A\\) and \\(B\\) are said to be independent if the \\[\\begin{equation} P(B | A) = P(B). \\tag{7.1} \\end{equation}\\] The next result follows by applying the Multiplication Rule (6.1) to the definition of independence. Theorem 7.1 Two events \\(A\\) and \\(B\\) are independent if and only if their probabilities multiply: \\[\\begin{equation} P(A \\textbf{ and } B) = P(A) P(B). \\tag{7.2} \\end{equation}\\] Proof. First, we assume (7.1) and show that (7.2) holds: \\[\\begin{align*} P(A \\textbf{ and } B) &amp;= P(A) P(B | A) &amp; \\text{by the Multiplication Rule} \\\\ &amp;= P(A) P(B) &amp; \\text{by assumption}. \\end{align*}\\] Conversely, we assume (7.2) and show that (7.1) holds: \\[\\begin{align*} P(B | A) &amp;= \\frac{P(A \\textbf{ and } B)}{P(A)} &amp; \\text{by the definition of conditional probability} \\\\ &amp;= \\frac{P(A) P(B)}{P(A)} &amp; \\text{by assumption} \\\\ &amp;= P(B). \\end{align*}\\] Here is an example that combines several concepts from the past few lessons. Example 7.1 You and a fellow castaway are stranded on a desert island, playing dice for the last banana. Two dice will be rolled. If the biggest number is 1, 2, 3, or 4, then Player 1 wins. If the biggest number is 5 or 6, then Player 2 wins. Would you rather be Player 1 or Player 2? Solution. Player 2 has a \\(20/36 = 0.5556\\) chance of winning. Here’s why: \\[\\begin{align*} P(\\text{biggest number is 5, 6}) &amp;= 1 - P(\\text{biggest number is 1, 2, 3, 4}) \\\\ &amp;= 1 - P(\\text{1st die is 1, 2, 3, 4} \\textbf{ and } \\text{2nd die is 1, 2, 3, 4}) \\\\ &amp;= 1 - \\frac{4}{6} \\cdot \\frac{4}{6}\\ \\ \\text{(by independence)} \\\\ &amp;= 1 - \\frac{16}{36} \\\\ &amp;= \\frac{20}{36} \\end{align*}\\] Examples One card is dealt off the top of a well-shuffled deck of cards. Is the event that the card is a heart independent of the event that the card is an ace? Two cards are dealt off the top of a well-shuffled deck of cards. Is the event that the first card is a heart independent of the event that the second card is a heart? In the dice game Yahtzee, five dice are rolled. The outcomes of the five dice are independent. What is the probability of rolling a “Yahtzee” (i.e., when all five dice show the same number)? Additional Exercises "],
["ltp.html", "Lesson 8 Law of Total Probability Motivating Example Theory Examples", " Lesson 8 Law of Total Probability Motivating Example You watch a magician place 4 ordinary quarters and 1 double-headed quarter into a box. If you select a coin from the box at random and toss it, what is the probability that it lands heads? Theory In some situations, calculating the probability of an event is easy, once you condition on the right information. For example, in the example above, if we knew that the coin we chose was ordinary, then: \\[ P(\\text{heads} | \\text{ordinary}) = \\frac{1}{2}. \\] On the other hand, if the coin we chose was double-headed, then \\[ P(\\text{heads} | \\text{double-headed}) = 1. \\] How do we combine these conditional probabilities to come up with \\(P(\\text{heads})\\), the overall probability that the coin lands heads? Theorem 8.1 (Law of Total Probability) Let \\(A_1, ..., A_n\\) be a partition of the possible outcomes. Then: \\[ P(B) = \\sum_{i=1}^n P(A_i) P(B | A_i). \\] A partition is a collection of non-overlapping events that cover all the possible outcomes. For example, in the example above, \\(A_1 = \\{ \\text{ordinary}\\}\\) and \\(A_2 = \\{ \\text{double-headed} \\}\\) is a partition, since the coin that we selected has to be one of the two and cannot be both. Applying the Law of Total Probability to this problem, we have \\[\\begin{align*} P(\\text{heads}) &amp;= P(\\text{ordinary}) P(\\text{heads} | \\text{ordinary}) + P(\\text{double-headed}) P(\\text{heads} | \\text{double-headed}) \\\\ &amp;= 0.8 \\cdot \\frac{1}{2} + 0.2 \\cdot 1 \\\\ &amp;= 0.6 \\end{align*}\\] So the overall probability \\(P(B)\\) is just a weighted average of the conditional probabilities \\(P(B | A_i)\\), where the “weights” are \\(P(A_i)\\). (Note that these “weights” have to add up to 1, since \\(A_1, ..., A_n\\) are a partition of all the possible outcomes, whose total probability is \\(1.0\\).) This means that the overall probability \\(P(B)\\) will always lie somewhere between the conditional probabilities \\(P(B | A_i)\\), with more weight given to the more probable scenarios. For example, we could have predicted that \\(P(\\text{heads})\\) would lie somewhere between \\(\\frac{1}{2}\\) and \\(1\\); the fact that it is much closer to the former is because choosing the ordinary coin was more probable. Examples Here are some things we already know about a deck of cards: The top card in a shuffled deck of cards has a \\(13/52\\) chance of being a diamond. If the top card is a diamond, then the second card has a \\(12/51\\) chance of being a diamond. If the top card is not a diamond, then the second card has a \\(13/51\\) chance of being a diamond. Now, suppose we “burn” (i.e., discard) the top card without looking at it. What is the probability that the second card is a diamond? Use the Law of Total Probability, conditioning on the top card. Does burning cards affect probabilities? Anny is a fan of chess competitor Hikaru Nakamura, and tomorrow is the World Chess Championship. She is superstitious and believes that the weather influences how he will perform. Hikaru has a 60% chance of winning if it rains, a 25% chance if it is cloudy, and a 10% chance if it is sunny. Anny checks the weather the night before, and the forecast says that the chance of rain tomorrow is 40%; otherwise, it is equally likely to be cloudy as sunny. What is the probability that Hikaru wins the World Chess Championship? "],
["bayes.html", "Lesson 9 Bayes’ Theorem 9.1 Motivating Example 9.2 Theory 9.3 Examples", " Lesson 9 Bayes’ Theorem 9.1 Motivating Example The ELISA test is used to screen blood for HIV. When the blood contains HIV, it gives a positive result 98% of the time. When the blood does not contain HIV, it gives a negative result 94% of the time. The prevalence of HIV is about 1% in the adult male population. A patient has just tested positive and wants to know the probability that he has HIV. What would you tell him? The solution to this problem involves an important theorem in probability and statistics called Bayes’ Theorem. This video covers some of the intuition and the history behind Bayes’ Theorem. Don’t worry about the details for now. This video is meant to be more inspiring than informative. 9.2 Theory The conditional probabilities \\(P(A | B)\\) and \\(P(B | A)\\) are not the same. For example, let \\(A\\) be “currently a Cal Poly student” and \\(B\\) be “went to high school in California”. \\(P(B | A)\\) is very high, about \\(0.85\\), since most Cal Poly students are in-state. \\(P(A | B)\\) is very low, as only a very small fraction of people who went to high school in CA are currently in college, much less at Cal Poly. Bayes’ Theorem is a way to convert probabilities of the form \\(P(B | A)\\) into probabilities of the form \\(P(A | B)\\). This switcheroo is surprisingly common in probability and statistics. For example, Doctors know the probability that a patient tests positive (\\(B\\)) given that they have the disease (\\(A\\)), but a patient is more interested in the probability that he has the disease (\\(A\\)) given that he tested positive (\\(B\\)). E-mail providers can collect data on the probability that an e-mail contains a certain word (\\(B\\)) given that it is spam (\\(A\\)), but a spam filter needs the probability that the e-mail is spam (\\(A\\)) given that it contains the word (\\(B\\)). Don’t be deceived by its simplicity; Bayes’ Theorem is one of the most important and powerful results in all of probability and statistics. Theorem 9.1 (Bayes’ Theorem) \\[ P(A | B) = \\frac{P(A) P(B | A)}{P(B)}. \\] Proof. By the definition of conditional probability (6.1) and the multiplication rule (6.1): \\[\\begin{equation} P(A | B) = \\frac{P(A \\textbf{ and } B)}{P(B)} = \\frac{P(A) P(B | A)}{P(B)}. \\end{equation}\\] The next video provides intuition about this proof, connecting it with concepts from the past few lessons, including conditional probability and independence. To solve most problems, you will need to combine Bayes’ Theorem with the Law of Total Probability (8.1). The solution to the HIV testing example from above demonstrates some of the common tricks. Solution. Let’s represent HIV positive by \\(H\\) and a positive ELISA test by \\(T\\). The problem statement tells us that \\[\\begin{align*} P(H) &amp;= 0.01 &amp; P(T | H) &amp;= 0.98 &amp; P(\\textbf{not } T | \\textbf{not } H) &amp;= 0.94. \\end{align*}\\] By the Complement Rule, we can infer that \\[\\begin{align*} P(\\textbf{not } H) &amp;= 0.99 &amp; P(\\textbf{not } T | H) &amp;= 0.02 &amp; P(T | \\textbf{not } H) &amp;= 0.06. \\end{align*}\\] Since we already have \\(P(T | H)\\) and we want to know \\(P(H | T)\\), this is a job for Bayes’ Rule: \\[ P(H | T) = \\frac{P(H) P(T | H)}{P(T)} = \\frac{0.01 \\cdot 0.98}{P(T)}. \\] Unfortunately, we do not know \\(P(T)\\), the probability of testing positive overall. However, we do know its probability, conditional on HIV status. So we apply the Law of Total Probability, partitioning by HIV status: \\[ P(T) = P(H) P(T | H) + P(\\textbf{not } H) P(T | \\textbf{not } H) = 0.01 \\cdot 0.98 + 0.99 \\cdot 0.06. \\] Finally, we plug this result into Bayes’ Rule: \\[ P(H | T) = \\frac{0.01 \\cdot 0.98}{0.01 \\cdot 0.98 + 0.99 \\cdot 0.06} = .142. \\] So even though the patient tested positive for HIV, he only has a 14.2% chance of actually having HIV! The low probability is surprising at first. But it makes sense if we think about the problem geometrically. The figure below partitions adult males based on their HIV status and test status. The shaded area represents all people who tested positive. The people who actually have HIV make up only a tiny fraction of all the people who tested positive because there are so many more people who do not have the disease, that the false positives overwhelm the true positives. Figure 9.1: Intuition for Bayes’ Rule The next video will give you deep insights about Bayes’ rule. You should be able to follow most of it, but you may want to come back to this video after trying some of the examples below. 9.3 Examples The rare mineral unobtanium is present in only 1% of rocks in a mine. You have an unobtanium detector, which never fails to detect unobtanium when it is present. Otherwise, it is still reliable, returning accurate readings 90% of the time when unobtanium is not present. What is \\(P(\\text{unobtanium detected} | \\text{unobtanium present})\\)? What is \\(P(\\text{unobtanium present} | \\text{unobtanium detected})\\)? (Hint: One of these probabilities can be read off directly from the question prompt. The other needs to be calculated using Bayes’ Rule.) One application where Bayes’ Theorem has been extremely successful is spam filtering. From historical data, 80% of all e-mail is spam, and the phrase “free money” is used in 10% of spam e-mails. That is, \\(P(\\text{&quot;free money&quot;} | \\text{spam}) = 0.1\\). The phrase is also used in 1% of non-spam e-mails. A new e-mail has just arrived which contains the phrase “free money”. Given this information, what is the probability that it is spam, \\(P(\\text{spam} | \\text{&quot;free money&quot;})\\)? A certain disease afflicts 10% of the population. A test for the disease is 90% accurate for patients with the disease and 80% accurate for patients without the disease. Suppose you test positive for the disease. What is the probability that you actually have the disease? "],
["rv.html", "Lesson 10 Random Variables Motivating Example Theory Essential Practice Additional Exercises", " Lesson 10 Random Variables Motivating Example Texas hold ’em is a popular variant of poker. In Texas hold’em, each player starts with 2 cards (called “hole cards”) that are only known to them. In addition, there are 5 cards in the center (called “community cards”) that are shared by all the players. The player that wins is the one with the best five-card poker hand among the 7 cards (i.e., the 2 hole cards unique to them, plus the 5 community cards). Alice and Bob are playing Texas hold’em using a single deck of cards. The 5 community cards have not been revealed yet. Alice is looking at her 2 hole cards, which are Because she already has two diamonds, she wonders how many more diamonds there are in the community cards. If there are 3 or more, then she has a flush. Bob, on the other hand, has the following hole cards Because he has two jacks of different suits, he is less interested in the suit than in the number of jacks among the community cards. If there are 2, then he has a four-of-a-kind. If there are 0, then he just has a lowly pair. Both Alice and Bob are interested in the same random phenomenon: the 5 community cards with their \\(\\binom{48}{5} \\approx 1,712,304\\) possible outcomes. However, their attention is drawn to different quantities: Alice to the number of diamonds Bob to the number of jacks The number of diamonds and the number of jacks are two examples of random variables associated with this phenomenon. A random variable is simply a way of assigning a number to every possible outcome in a probability experiment. As we have seen, depending on the quantity of interest, there may be many random variables associated with the same probability experiment. To appreciate that Alice and Bob are interested in different random variables, suppose the 5 community cards are revealed to be Alice’s random variable (the number of diamonds) is 2, while Bob’s (the number of jacks) is 1. To help them decide how much to bet, Alice and Bob need to know the probabilities, such as the probability that the number of diamonds is at least 3. the probability that the number of jacks equals 2. Theory We describe random variables (such as the number of diamonds or the number of jacks) by the probabilities of their possible values. This is summarized by a function called the probability mass function. Definition 10.1 (Probability Mass Function) The probability mass function (p.m.f.) of a random variable \\(X\\) is a function that specifies the probability of different outcomes: \\[ f(x) = P(X = x). \\] Informally, the information contained in the p.m.f. is called the distribution of the random variable. Example 10.1 (Calculating the P.M.F.) Let’s calculate the p.m.f. of the number of diamonds, \\(X\\), among the community cards. We deal 5 cards from a deck of cards that has had 4 cards removed (because they have already been dealt to Alice and Bob). Furthermore, we know that 2 of these cards were diamonds. So the deck has 48 cards left, of which 11 are diamonds. First, we calculate \\(f(0)\\), the probability that \\(X = 0\\). In order for there to be no diamonds, all 5 cards must be selected from the \\(48 - 11 = 37\\) non-diamonds. So the probabiilty is \\[ f(0) = P(X = 0) = \\frac{\\binom{37}{5}}{\\binom{48}{5}} = .2546. \\] Next, we calculate \\(f(1)\\), the probability that \\(X = 1\\). We can choose any one of the 11 diamonds and pair it with any of the \\(\\binom{37}{4}\\) ways to choose 4 cards from the non-diamonds. \\[ f(1) = P(X = 1) = \\frac{11 \\cdot \\binom{37}{4}}{\\binom{48}{5}} = .4243. \\] Now, we calculate \\(f(2)\\), the probability that \\(X = 2\\). We can match any one of the \\(\\binom{11}{2}\\) ways to choose 2 diamonds with the \\(\\binom{37}{3}\\) ways to choose 3 non-diamonds: \\[ f(2) = P(X = 2) = \\frac{\\binom{11}{2} \\cdot \\binom{37}{3}}{\\binom{48}{5}} = .2496. \\] Continuing in this way, we can calculate \\(f(3)\\), \\(f(4)\\), and \\(f(5)\\). (Try these yourself!) When the random variable only takes on a handful of possible values, we can write out the probabilities in a table. 0 1 2 3 4 5 \\(f(x)\\) .2546 .4243 .2496 .0642 .0071 .0002 For random variables that take on many possible values, it is usually more convenient to specify the p.m.f. as a formula. In this example, the formula below produces the same probabilities as the table above, when you plug in the right value of \\(x\\): \\[\\begin{align*} f(x) &amp;= \\frac{\\binom{11}{x} \\binom{37}{5-x}}{\\binom{48}{5}} &amp; x &amp;= 0, 1, 2, 3, 4, 5. \\end{align*}\\] Try plugging different values of \\(x\\) into this formula and verifying that you get the probabilities in the table above. Example 10.2 (Using the P.M.F.) In order for Alice to have a flush, there must be at least 3 diamonds among the community cards. Let’s see how she can easily calculate this probability, once she has the p.m.f. \\(f(x)\\). In terms of the random variable \\(X\\), the probability that there are at least 3 diamonds is \\(P(X \\geq 3)\\), which is \\[\\begin{align*} P(X \\geq 3) &amp;= f(3) + f(4) + f(5) \\\\ &amp;= .0642 + .0071 + .0002 \\\\ &amp;= .0715. \\end{align*}\\] The complement rule (5.2) can sometimes save time. Although it would not helped in this example, we could have also calculated the probability as follows: \\[\\begin{align*} P(X \\geq 3) &amp;= 1 - P(X &lt; 3) \\\\ &amp;= 1 - (f(0) + f(1) + f(2)) \\\\ &amp;= 1 - (.2546 + .4243 + .2496) \\\\ &amp;= .0715. \\end{align*}\\] Example 10.3 (Graphing the P.M.F.) A graph of the p.m.f. is the best way to understand the distribution of a random variable over its possible values. On the graph below, the \\(x\\)-axis represents the possible values of the random variable. Each impulse represents the probability of a possible value. From the graph, it is immediately clear that 1 diamond is most probable. Unfortunately for Alice, it does not seem promising that she will get the 3 or more diamonds she needs to secure a flush. Essential Practice Continuing with the example from the lesson, let \\(Y\\) be the number of Jacks in the community cards. Calculate and graph the p.m.f. of \\(Y\\). Two fair, six-sided dice are rolled. Let \\(S\\) be the sum of the two numbers. Calculate and graph the p.m.f. of \\(S\\). Let \\(D\\) be the absolute difference between the two numbers. (That is, \\(D\\) is always a positive number.) Calculate and graph the p.m.f. of \\(D\\). A fair coin is tossed 5 times. Let \\(Z\\) be the number of heads. Calculate and graph the p.m.f. of \\(Z\\). Use the p.m.f. to calculate the probability of getting at least 2 heads. Additional Exercises In college basketball, when a player is fouled while not in the act of shooting and the opposing team is “in the penalty,” the player is awarded a “1 and 1.” In the 1 and 1, the player is awarded one free throw, and if that free throw goes in, the player is awarded a second free throw. Find the p.m.f. of \\(Y\\), the number of points scored in a 1 and 1 given that any free throw goes in with probability \\(0.7\\), independent of any other free throw. "],
["cdf.html", "Lesson 11 Cumulative Distribution Functions Theory Examples", " Lesson 11 Cumulative Distribution Functions Theory The p.m.f. 10.1 is one way to describe a random variable, but it is not the only way. The cumulative distribution function is a different representation that contains the same information as the p.m.f. Definition 11.1 (Cumulative Distribution Function) The cumulative distribution function (c.d.f.) is a function that returns the probability that a random variable is less than or equal to a particular value: \\[\\begin{equation} F(x) \\overset{\\text{def}}{=} P(X \\leq x). \\tag{11.1} \\end{equation}\\] It is called “cumulative” because it includes all the probability up to (and including) \\(x\\). Example 11.1 (Calculating the C.D.F.) Let’s calculate the c.d.f. of \\(X\\), the number of diamonds among the community cards, using the p.m.f. that we calculated in Lesson 10. Note that \\(F(x)\\) is the sum of all the probabilities up to \\(x\\). So, for example, \\[\\begin{align*} F(2.8) = P(X \\leq 2.8) &amp;= f(0) + f(1) + f(2) \\\\ &amp;= .2546 + .4243 + .2496 \\\\ &amp;= .9284. \\end{align*}\\] There is no simple formula for \\(F(x)\\). However, we can describe it piecewise. \\[ F(x) = \\begin{cases} 0 &amp; x \\leq 0 \\\\ .2546 &amp; 0 \\leq x &lt; 1 \\\\ .6788 &amp; 1 \\leq x &lt; 2 \\\\ .9284 &amp; 2 \\leq x &lt; 3 \\\\ .9926 &amp; 3 \\leq x &lt; 4 \\\\ .9997 &amp; 4 \\leq x &lt; 5 \\\\ 1.0 &amp; x \\geq 5 \\end{cases}. \\] Note that the c.d.f. of \\(X\\) has the following properties: It is constant between integers. Because it is impossible for the random variable \\(X\\) to assume non-integer values, \\(F(1.2) = P(X \\leq 1.2)\\) and \\(F(1) = P(X \\leq 1)\\) must be the same. The value of \\(F(x)\\) increases from 0 to 1 as \\(x\\) increases. This makes sense because as \\(x\\) increases, we accumulate more and more probability. Example 11.2 (Graphing the C.D.F.) The properties of the c.d.f. become clearer on a graph, like the one below. Because the random variable \\(X\\) cannot take on decimal values, the c.d.f. of \\(X\\) does not change between integers, giving it its step-function appearance. Figure 11.1: Graph of a cumulative distribution function Note that the c.d.f. \\(F(x)\\) can be evaluated at all values \\(x\\), not just at integer values. Example 11.3 (Using the C.D.F.) Some probabilities are easier to calculate using the c.d.f. than using the p.m.f. For example, the probability that Alice gets a flush, \\(P(X \\geq 3)\\), can be calculated by using the complement rule (5.2) and looking up the appropriate probability directly from the c.d.f. \\(F(x)\\). \\[\\begin{align*} P(X \\geq 3) &amp;= 1 - P(X &lt; 3) \\\\ &amp;= 1 - P(X \\leq 2) \\\\ &amp;= 1 - F(2) \\\\ &amp;= 1 - .9284 \\\\ &amp;= .0716 \\end{align*}\\] Remember that the c.d.f. \\(F(x)\\) always includes the probability of \\(x\\). Since \\(P(X &lt; 3)\\) should not include the probability of \\(3\\), we use \\(F(2)\\) instead of \\(F(3)\\). At the beginning of this lesson, we mentioned that the c.d.f. contains the exact same information as the p.m.f., no more and no less. Therefore, it should be possible to recover the p.m.f. from the c.d.f. For example, how would we calculate \\(f(3) = P(X = 3)\\), if we only knew the c.d.f. \\(F(x)\\)? We could subtract \\(P(X \\leq 2)\\) from \\(P(X \\leq 3)\\) to get just the probability that it is equal to 3. \\[\\begin{align*} f(3) = P(X = 3) &amp;= P(X \\leq 3) - P(X \\leq 2) \\\\ &amp;= F(3) - F(2) \\\\ &amp;= .9926 - .9284 \\\\ &amp;= .0642, \\end{align*}\\] which agrees with the p.m.f. from Lesson 10. Examples Continuing with the example from the lesson, let \\(Y\\) be the number of Jacks among the community cards. Calculate and graph the c.d.f. of \\(Y\\). Consider a random variable \\(Z\\) with c.d.f. given by the formula \\[\\begin{align*} F(x) &amp;= \\begin{cases} 1 - 3^{-\\lfloor x \\rfloor} &amp; x \\geq 0 \\\\ 0 &amp; \\text{otherwise} \\end{cases}. \\end{align*}\\] (Note that \\(\\lfloor x \\rfloor\\) denotes the floor operator, which rounds \\(x\\) down to the nearest integer. So \\(\\lfloor 3.9 \\rfloor = 3\\) and \\(\\lfloor 7.1 \\rfloor = 7\\).) Graph the c.d.f. \\(F(x)\\). Then, use it to calculate: \\(P(Z &gt; 3)\\) \\(P(Z = 2)\\) "],
["hypergeometric.html", "Lesson 12 Hypergeometric Distribution Motivating Example Theory Essential Practice Additional Exercises", " Lesson 12 Hypergeometric Distribution Motivating Example We revisit the Texas Hold’em example from Lesson 10, when we first learned about random variables. In that example, Alice was dealt and she wanted to know the distribution of the number of diamonds among the community cards. If this random variable is at least 3, then she has a flush. In Lesson 10, we derived the p.m.f. of the number of diamonds from scratch. In this lesson, we will derive the p.m.f. by matching this random variable to a template. Theory In probability, some distributions are so common that they have been given names. The first named distribution that we will learn is the hypergeometric distribution. Theorem 12.1 (Hypergeometric Distribution) If a random variable can be described as the number of \\(\\fbox{1}\\)s in \\(n\\) random draws, without replacement, from the box \\[ \\overbrace{\\underbrace{\\fbox{0}\\ \\ldots \\fbox{0}}_{N_0}\\ \\underbrace{\\fbox{1}\\ \\ldots \\fbox{1}}_{N_1}}^N, \\] then its p.m.f. is given by \\[\\begin{equation} f(x) = \\dfrac{\\binom{N_1}{x}\\binom{N_0}{n-x}}{\\binom{N}{n}}, x=0, ..., n, \\tag{12.1} \\end{equation}\\] where \\(N = N_1 + N_0\\) is the number of tickets in the box. We say that the random variable has a \\(\\text{Hypergeometric}(n, N_1, N_0)\\) distribution, and \\(n\\), \\(N_1\\), \\(N_0\\) are called parameters of the distribution. We will derive the formula (12.1) later in this lesson. First, let’s see how this result allows us to avoid most calculations. Example 12.1 (The Number of Diamonds) In Alice’s case, the community cards are \\(5\\) cards taken at random, without replacement, from a deck of \\(48\\) cards. So we can represent it by a box model with \\(N=48\\) tickets, with \\[\\begin{align*} \\text{$N_1=11$ tickets labeled } \\fbox{1} &amp;\\text{ representing the diamond cards} \\\\ \\text{$N_0=37$ tickets labeled } \\fbox{0} &amp;\\text{ representing the non-diamond cards}. \\end{align*}\\] Now, if we draw \\(n=5\\) times from this box without replacement, then the number of \\(\\fbox{1}\\)s we get corresponds to the number of diamonds. Therefore, by Theorem 12.1, we know that the number of diamonds follows a \\(\\text{Hypergeometric}(n=5, N_1=11, N_0=37)\\) distribution. We can now write down the p.m.f. by plugging the values of the parameters \\(n\\), \\(N_1\\), \\(N_0\\) into (12.1): \\[ f(x) = \\frac{\\binom{11}{x} \\binom{37}{5-x}}{\\binom{48}{5}}, x=0, 1, \\ldots, 5. \\] Now that we have a formula for the p.m.f., we can calculate probabilities by plugging numbers into it. So, for example, the probability that Alice gets a flush is: \\[\\begin{align*} P(X \\geq 3) &amp;= f(3) + f(4) + f(5) \\\\ &amp;= \\frac{\\binom{11}{3} \\binom{37}{5-3}}{\\binom{48}{5}} + \\frac{\\binom{11}{4} \\binom{37}{5-4}}{\\binom{48}{5}} + \\frac{\\binom{11}{5} \\binom{37}{5-5}}{\\binom{48}{5}} \\\\ &amp;\\approx .0715. \\end{align*}\\] Now, let’s derive the p.m.f. of the hypergeometric distribution. Understanding this derivation will help you remember the formula! Proof (Theorem 12.1). If we number each ticket \\(1, 2, \\ldots, N\\), then there are \\(\\binom{N}{n}\\) equally likely unordered outcomes. Note that in this way of counting, the \\(\\fbox{1}\\)s in the box are distinct. So drawing the first \\(\\fbox{1}\\) in the box is not the same as drawing the second \\(\\fbox{1}\\) in the box. How many of the possible outcomes have exactly \\(x\\) \\(\\fbox{1}\\)s? There are \\(\\binom{N_1}{x}\\) unordered ways to choose \\(x\\) \\(\\fbox{1}\\)s from the \\(N_1\\) \\(\\fbox{1}\\)s. There are \\(\\binom{N_0}{n-x}\\) unordered ways to choose the remaining \\(n-x\\) \\(\\fbox{0}\\)s. Since any one of the \\(\\binom{N_1}{x}\\) ways of choosing the \\(\\fbox{1}\\)s can be paired with any one of the \\(\\binom{N_0}{n-x}\\) ways of choosing the \\(\\fbox{0}\\)s, the total number of ways to choose \\(n\\) tickets, resulting in \\(x\\) \\(\\fbox{1}\\)s and \\(n-x\\) \\(\\fbox{0}\\)s, is \\[ \\binom{N_1}{x} \\cdot \\binom{N_0}{n-x}, \\] by the multiplication principle of counting (Theorem 1.1). Therefore, the probability of getting exactly \\(x\\) \\(\\fbox{1}\\)s in \\(n\\) draws is: \\[ f(x) = P(X = x) = \\dfrac{\\binom{N_1}{x}\\binom{N_0}{n-x}}{\\binom{N}{n}}. \\] Visualizing the Distribution Let’s graph the hypergeometric distribution for different values of \\(n\\), \\(N_1\\), and \\(N_0\\). First, we hold the number of draws constant at \\(n=5\\) and vary the composition of the box. The distribution shifts, depending on the composition of the box. The more \\(\\fbox{1}\\)s there are in the box, the more \\(\\fbox{1}\\)s in the sample. Next, we study how the distribution changes as a function of \\(n / N\\), the relative fraction of tickets removed from the box. For all of the graphs below, \\(N_1 = N_0 = N/2\\). All three plots are symmetric, which makes sense, since there are exactly as many \\(\\fbox{1}\\)s as \\(\\fbox{0}\\)s in the box. However, when the number of draws makes up a large fraction of the box, as in the leftmost plot, the distribution is very tightly concentrated around intermediate values, such as 4, 5, and 6. This makes sense because sampling without replacement is “self-balancing”. Each time we draw a \\(\\fbox{1}\\), it becomes less likely that we will draw a \\(\\fbox{1}\\) again (and more likely to draw a \\(\\fbox{0}\\)). This makes extreme outcomes, such as drawing all \\(\\fbox{1}\\)s, less likely. Calculating Hypergeometric Probabilities on the Computer Calculating hypergeometric probabilities by hand is unwieldy when \\(n\\), \\(N_1\\), and \\(N_0\\) are large. Fortunately, the hypergeometric distribution is built into many software packages. For example, suppose we want to solve the following problem. Example 12.2 (Capture-Recapture) One way to estimate the number of animals in a population is capture-recapture. For example, suppose we want to estimate the number of fish in a lake. Clearly, it is impractical to catch all of the fish. Instead, we capture \\(m\\) fish one week, tag them, and release them back into the lake. We go back the next week, after these tagged fish have had a chance to mix with the population, and catch another \\(n\\) distinct fish. Some, but not all, of these \\(n\\) fish will be tagged. The number of tagged fish in this second catch allows us to estimate the population of fish in the lake. Suppose there are actually 100 fish in the lake; we capture \\(m=20\\) fish the first week and \\(n=30\\) fish the next week. What is the probability that at least \\(7\\) of the \\(30\\) fish will be tagged? Solution. We can represent this using a box model. The fish in the lake will be represented by \\(N=100\\) tickets, with \\[\\begin{align*} \\text{$N_1=20$ tickets labeled } \\fbox{1} &amp;\\text{ representing the tagged fish} \\\\ \\text{$N_0=80$ tickets labeled } \\fbox{0} &amp;\\text{ representing the non-tagged fish}. \\end{align*}\\] Now, if we draw \\(n=30\\) times from this box without replacement, then the number of \\(\\fbox{1}\\)s we get corresponds to the number of tagged fish we get. Therefore, the number of tagged fish is a \\(\\text{Hypergeometric}(n=30, N_1=20, N_0=80)\\) random variable. However, to calculate the probability that at least \\(7\\) of the \\(30\\) fish will be tagged, we have to evaluate the p.m.f. at 7, 8, 9, etc. This is a job for a computer, not a human. In Python, we use a library called Symbulate. We first specify the parameters of the hypergeometric distribution; then we evaluate the p.m.f. using the .pmf() method. Note that .pmf() accepts either a single number or a list of numbers. If a list of numbers is passed into .pmf(), then it will evaluate the p.m.f. at each of those numbers, returning a list of probabilities. from symbulate import * probs = Hypergeometric(n=30, N1=20, N0=80).pmf(range(7, 31)) probs ## array([1.80287211e-01, 1.16176457e-01, 5.77600464e-02, 2.22376179e-02, ## 6.62820205e-03, 1.52341741e-03, 2.67853610e-04, 3.55743076e-05, ## 3.50270105e-06, 2.48771382e-07, 1.22310776e-08, 3.89715707e-10, ## 7.13438366e-12, 5.60558716e-14, 0.00000000e+00, 0.00000000e+00, ## 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ## 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]) To add these probabilities, we call sum(): sum(probs) ## 0.38492014376629696 We could have also gotten the same answer by using c.d.f.s. Note that \\(P(X \\geq 7) = 1 - F(6)\\). 1 - Hypergeometric(n=30, N1=20, N0=80).cdf(6) ## 0.384920143766305 You can play around with the Python code in this Colab notebook. It is possible to do the same calculation in R, a statistical programming language. Note that R uses different names for the parameters. Like Python, R can evaluate the p.m.f. at a single value or a vector of values. probs &lt;- dhyper(x=7:30, m=20, n=80, k=30) probs ## [1] 1.802872e-01 1.161765e-01 5.776005e-02 2.223762e-02 6.628202e-03 ## [6] 1.523417e-03 2.678536e-04 3.557431e-05 3.502701e-06 2.487714e-07 ## [11] 1.223108e-08 3.897157e-10 7.134384e-12 5.605587e-14 0.000000e+00 ## [16] 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 ## [21] 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 To add these probabilities, we call sum(): sum(probs) ## [1] 0.3849201 We could have also gotten the same answer by using c.d.f.s. Notice how R uses the prefix d for p.m.f.s and the prefix p for c.d.f.s. 1 - phyper(6, m=20, n=80, k=30) ## [1] 0.3849201 You can play around with the R code in this Colab notebook. Another Formula for the Hypergeometric Distribution (optional) There is another formula for the hypergeometric p.m.f. that looks different but is equivalent to (12.1). It is based on counting the number of ordered outcomes, instead of the number of unordered outcomes. You should verify that this formula gives the same probabilities as (12.1). Theorem 12.2 (Another Formula for the Hypergeometric) The p.m.f. of a \\(\\text{Hypergeometric}(n, N_1, N_0)\\) random variable can also be written as \\[ f(x) = \\frac{\\binom{n}{x} \\cdot \\frac{N_1!}{(N_1 - x)!} \\cdot \\frac{N_0!}{(N_0 - n + x)!}}{\\frac{N!}{(N-n)!}}. \\] Proof. There are \\(\\frac{N!}{(N-n)!}\\) ways to choose \\(n\\) tickets from \\(N\\), if we account for the order in which \\(n\\) the tickets were drawn. How many of these ordered outcomes have exactly \\(x\\) \\(\\fbox{1}\\)s and \\(n-x\\) \\(\\fbox{0}\\)s? Let’s start by counting the number of outcomes that look like \\[\\begin{equation} \\underbrace{\\fbox{1}, \\ldots, \\fbox{1}}_{x}, \\underbrace{\\fbox{0}, \\ldots, \\fbox{0}}_{n-x}, \\tag{12.2} \\end{equation}\\] in this exact order. There are \\(N_1\\) choices for the first \\(\\fbox{1}\\), \\(N_1 - 1\\) choices for the second, and so on, until we get to the last \\(\\fbox{1}\\), for which there are \\(N_1 - x + 1\\) choices. Then, there are \\(N_0\\) choices for the first \\(\\fbox{0}\\), \\(N_0 - 1\\) choices for the second, and so on. By the multiplication principle of counting (Theorem 1.1), there are \\[\\begin{equation} \\underbrace{N_1 \\cdot (N_1 - 1) \\cdot \\ldots \\cdot (N_1 - x + 1)}_{\\displaystyle\\frac{N_1!}{(N_1 - x)!}} \\cdot \\underbrace{N_0 \\cdot (N_0 - 1) \\cdot \\ldots \\cdot (N_0 - (n - x) + 1)}_{\\displaystyle\\frac{N_0!}{(N_0 - n + x)!}}. \\tag{12.3} \\end{equation}\\] ways to get an outcome like (12.2), in that exact order. However, because we are counting ordered outcomes, we need to account for the possibility that the \\(\\fbox{1}\\)s and \\(\\fbox{0}\\)s were drawn in a different order than (12.2). There are \\(\\binom{n}{x}\\) ways to reorder the \\(\\fbox{1}\\)s and \\(\\fbox{0}\\)s, each of which can be obtained in (12.3) ways. So the total number of (ordered) ways to get \\(x\\) \\(\\fbox{1}\\)s and \\(n-x\\) \\(\\fbox{0}\\)s is \\[ \\binom{n}{x} \\cdot \\frac{N_1!}{(N_1 - x)!} \\cdot \\frac{N_0!}{(N_0 - n + x)!} \\] So the p.m.f. can be written as \\[ f(x) = P(X = x) = \\frac{\\binom{n}{x} \\cdot \\frac{N_1!}{(N_1 - x)!} \\cdot \\frac{N_0!}{(N_0 - n + x)!}}{\\frac{N!}{(N-n)!}}. \\] It is easy to see that this formula is equivalent to (12.1), if you write out the binomial coefficients in (12.1) as factorials and regroup \\(\\frac{n!}{x! (n-x)!}\\) as \\(\\binom{n}{x}\\). Essential Practice Recall in the example from Lesson 10, there was another player, Bob, who had two Jacks and was looking to get a four-of-a-kind. For Bob, the random variable of interest was the number of Jacks among the community cards. Use a box model to argue that Bob’s random variable also has a hypergeometric distribution. What are its parameters? In order to ensure safety, a random sample of cars on each production line are crash-tested before being released to the public. The process of crash testing destroys the car. Suppose that a production line contains 10 defective and 190 working cars. If 4 of these cars are chosen at random for crash-testing, what is: the probability that at least 1 car will be found defective? the probability that exactly 2 cars will be found defective? The state proposes a lottery in which you select \\(6\\) numbers from \\(1\\) to \\(15\\). When it is time to draw, the lottery selects \\(8\\) different numbers, and you win if at least \\(4\\) of the \\(6\\) numbers you picked are among the \\(8\\) numbers that the lottery drew. What is the probability you win the prize? Additional Exercises You are enrolled in \\(3\\) courses this quarter, and the breakdown of majors by class is as follows: Class 1: \\(4\\) Statistics majors and \\(6\\) Computer Science majors Class 2: \\(17\\) Statistics majors and \\(13\\) Computer Science majors Class 3: \\(11\\) Statistics majors and \\(9\\) Computer Science majors If you take a simple random sample of \\(20\\%\\) of the students in Class 1, what is the probability that the number of Statistics majors in your sample is equal to the number of Computer Science majors? (Note: In a simple random sample, each student can be selected at most once.) Now, suppose you pick one of your \\(3\\) classes at random and then choose a random sample of \\(20\\%\\) of students from that class. What is the probability that the number of Statistics majors in your sample is equal to the number of Computer Science majors in your sample? In Texas Hold’em, each player has \\(2\\) cards of their own, and all players share \\(5\\) cards in the center of the table. A player has a flush when there are at least \\(5\\) cards of the same suit out of the \\(7\\) total cards. The deck is shuffled between hands, so that the probability you obtain a flush is independent from hand to hand. What is the probability that you get a flush at least once in \\(10\\) hands of Texas Hold’em? (Hint: First, calculate the probability of a flush of spades. Then, repeat for the other suits, and add the probabilities together to obtain the overall probability of a flush.) There are \\(25\\) coins in a jar. \\(15\\) are quarters, \\(7\\) are dimes, and \\(3\\) are pennies. Each time you reach in the jar, you are equally likely to pick any of the coins in the jar. The coins are not replaced in the jar after each draw. What is the minimum number of times you must reach in the jar to have at least a \\(50\\%\\) chance of getting all \\(3\\) pennies? (Hint: In this question, \\(n\\) is unknown. You will have to try a few different values of \\(n\\) to get the answer.) "],
["binomial.html", "Lesson 13 Binomial Distribution Motivating Example Theory Essential Practice Additional Exercises", " Lesson 13 Binomial Distribution Motivating Example In 1693, Samuel Pepys (who is best remembered today for his diary) wrote a letter to Isaac Newton inquiring about a wager that Pepys was planning to make. Pepys wanted to know which of the following events had the highest probability of occurring. A. 6 dice are thrown and at least 1 is a ⚅ B. 12 dice are thrown and at least 2 are ⚅s C. 18 dice are thrown and at least 3 are ⚅s Pepys thought that C had the highest probability, but Newton disagreed. The probability of A is straightforward to calculate. We use the Complement Rule (Theorem 5.2), much like we did in the Chevalier de Méré example from Lesson 5. \\[\\begin{align*} P(\\text{at least 1 ⚅ in 6 rolls}) &amp;= 1 - P(\\text{0 ⚅s in 6 rolls}) \\\\ &amp;= 1 - \\frac{5^6}{6^6} \\\\ &amp;\\approx .665 \\end{align*}\\] However, the probabilities of the other two events are trickier to calculate. For example, it is not obvious how to count the number of ways to get exactly 2 sixes in 18 dice rolls. In this lesson, we learn how this is done. Theory In this lesson, we learn another named distribution that is virtually identical to the hypergeometric distribution, except in one important detail: the draws are made with replacement instead of without replacement. Theorem 13.1 (Binomial Distribution) If a random variable can be described as the number of \\(\\fbox{1}\\)s in \\(n\\) random draws, with replacement, from the box \\[ \\overbrace{\\underbrace{\\fbox{0}\\ \\ldots \\fbox{0}}_{N_0}\\ \\underbrace{\\fbox{1}\\ \\ldots \\fbox{1}}_{N_1}}^N, \\] then its p.m.f. is given by \\[\\begin{equation} f(x) = \\dfrac{\\binom{n}{x} N_1^x N_0^{n-x}}{N^n}, x=0, ..., n, \\tag{13.1} \\end{equation}\\] where \\(N = N_1 + N_0\\) is the number of tickets in the box. We say that the random variable has a \\(\\text{Binomial}(n, N_1, N_0)\\) distribution, and \\(n\\), \\(N_1\\), \\(N_0\\) are called parameters of the distribution. Equivalently, (13.1) can be written as \\[\\begin{equation} f(x) = \\binom{n}{x} p^x (1 - p)^{n-x}, x=0, ..., n, \\tag{13.2} \\end{equation}\\] where \\(p = N_1 / N\\) is the proportion of \\(\\fbox{1}\\)s in the box. We will derive the formulas (13.1) and (13.2) later in this lesson. For now, let’s see how these formulas allow us to bypass calculations. Example 13.1 (The Newton-Pepys Problem) Let’s model each die roll as a draw from a box. Each die has \\(6\\) equally likely outcomes, so we place \\(N=6\\) tickets into the box. Since we are only interested in the number of ⚅s, we will label only one these tickets \\(\\fbox{1}\\), corresponding to a ⚅; the other five tickets will be labeled \\(\\fbox{0}\\). \\[ \\fbox{$\\fbox{1}\\ \\fbox{0}\\ \\fbox{0}\\ \\fbox{0}\\ \\fbox{0}\\ \\fbox{0}$} \\] To model 12 rolls of the die, we draw \\(n=12\\) tickets with replacement. We draw with replacement so that the outcome of one die roll does not affect the outcome of another. In other words, we want the dice rolls to be independent, and drawing with replacement is the only way to model independence. The number of \\(\\fbox{1}\\)s in these 12 draws represents the number of ⚅s that one would get in 12 rolls of a fair die. Therefore, by Theorem 13.1, we now know that the number of ⚅s in 12 rolls follows a \\(\\text{Binomial}(n=12, N_1=1, N_0=5)\\) distribution. We can now write down the p.m.f. by plugging the values of the parameters \\(n\\), \\(N_1\\), \\(N_0\\) into (13.1): \\[ f(x) = \\frac{\\binom{12}{x} 1^x 5^{12-x}}{6^{12}}, x=0, 1, \\ldots, 12. \\] Equivalently, we have \\(p = N_1/N = 1/6\\), and plugging in the values of the parameters \\(n\\) and \\(p\\) into (13.2), we have: \\[ f(x) = \\binom{12}{x} \\left(\\frac{1}{6}\\right)^x \\left(\\frac{5}{6} \\right)^{12-x}, x=0, 1, \\ldots, 12. \\] Both formulas should produce the same probabilities. To answer Pepys’ question about the probability of getting at least 2 ⚅s in 12 rolls, we combine the binomial distribution with the complement rule, \\[\\begin{align*} P(X \\geq 2) &amp;= 1 - P(X \\leq 1) \\\\ &amp;= 1 - (f(0) + f(1)) \\\\ &amp;= 1 - \\binom{12}{0} \\left(\\frac{1}{6}\\right)^0 \\left(\\frac{5}{6} \\right)^{12} - \\binom{12}{1} \\left(\\frac{1}{6}\\right)^1 \\left(\\frac{5}{6} \\right)^{11} \\\\ &amp;= 1 - \\left(\\frac{5}{6} \\right)^{12} - 12 \\left(\\frac{1}{6}\\right) \\left(\\frac{5}{6} \\right)^{11} \\\\ &amp;\\approx .6187. \\end{align*}\\] Now, let’s derive the p.m.f. of the binomial distribution. Proof (Theorem 13.1). To calculate the p.m.f. at \\(x\\), we need to calculate the probability of getting exactly \\(x\\) \\(\\fbox{1}\\)s in \\(n\\) draws. First, there are \\(N^n\\) ordered ways to draw \\(n\\) tickets from \\(N\\) with replacement. (We must count ordered outcomes because the unordered outcomes are not all equally likely. See Lesson 4.) Next, we count the outcomes that have exactly \\(x\\) \\(\\fbox{1}\\)s. We proceed in two steps: Count outcomes that look like \\[\\begin{equation} \\underbrace{\\fbox{1}, \\ldots, \\fbox{1}}_{x}, \\underbrace{\\fbox{0}, \\ldots, \\fbox{0}}_{n-x}, \\tag{13.3} \\end{equation}\\] where the \\(x\\) \\(\\fbox{1}\\)s are drawn first. There are \\(N_1\\) choices for the first \\(\\fbox{1}\\), \\(N_1\\) choices for the second \\(\\fbox{1}\\), and in fact, \\(N_1\\) choices for each of the \\(x\\) \\(\\fbox{1}\\)s, since we are drawing with replacement. Likewise, there are \\(N_0\\) choices for each of the \\(n-x\\) \\(\\fbox{0}\\)s. By the multiplication principle of counting (Theorem 1.1), there are \\[\\begin{equation} N_1^x \\cdot N_0^{n-x}. \\tag{13.4} \\end{equation}\\] ways to get an outcome like (13.3), in that exact order. Account for the possibility that the \\(\\fbox{1}\\)s and \\(\\fbox{0}\\)s were drawn in a different order than (13.3). There are \\(\\binom{n}{x}\\) ways to rearrange the \\(\\fbox{1}\\)s and \\(\\fbox{0}\\)s. So the total number of (ordered) ways to get \\(x\\) \\(\\fbox{1}\\)s and \\(n-x\\) \\(\\fbox{0}\\)s is \\[ \\binom{n}{x} \\cdot N_1^x \\cdot N_0^{n-x}. \\] Dividing this by the total number of outcomes \\(N^x\\) gives the p.m.f.: \\[ f(x) = P(X = x) = \\frac{\\binom{n}{x} \\cdot N_1^x \\cdot N_0^{n-x}}{N^n}. \\] To see that this formula is the same as (13.2), we write \\(N^n = N^x \\cdot N^{n-x}\\). Then, we have: \\[\\begin{align*} f(x) &amp;= \\binom{n}{x}\\frac{N_1^x \\cdot N_0^{n-x}}{N^x \\cdot N^{n-x}} \\\\ &amp;= \\binom{n}{x} \\left( \\frac{N_1}{N} \\right)^x \\left( \\frac{N_0}{N} \\right)^{n-x} \\\\ &amp;= \\binom{n}{x} p^x (1 - p)^{n-x}, \\end{align*}\\] where in the last line, we used the fact that \\(\\frac{N_0}{N} = \\frac{N - N_1}{N} = 1 - \\frac{N_1}{N} = 1 - p\\). Visualizing the Distribution Let’s graph the binomial distribution for different values of \\(n\\), \\(N_1\\), and \\(N_0\\). First, we hold the number of draws constant at \\(n=5\\) and vary the composition of the box. The distribution shifts, depending on the composition of the box. The more \\(\\fbox{1}\\)s there are in the box, the more \\(\\fbox{1}\\)s in the sample. Next, we study how the distribution changes as a function of \\(n / N\\), the relative fraction of draws we make from the box. For all of the graphs below, \\(N_1 = N_0 = N/2\\). In contrast to the hypergeometric distribution, the binomial distribution does not change when we vary the number of tickets in the box, as long as we keep the relative proportions of \\(\\fbox{1}\\)s and \\(\\fbox{0}\\)s the same. This makes sense because we are drawing with replacement, so it does not matter how many draws we make; the box always looks the same. The binomial distribution is indifferent to the exact number of tickets \\(N\\) in the box. For example, to model a coin toss, we could use \\[ \\displaystyle \\fbox{\\(\\fbox{1}\\ \\fbox{0}\\)} \\] or \\[ \\displaystyle \\fbox{\\(\\fbox{1}\\ \\fbox{1}\\ \\fbox{0}\\ \\fbox{0}\\)}. \\] Although the first box may be more natural, the second box is equally valid. Any box with the same number of \\(\\fbox{1}\\)s as \\(\\fbox{0}\\)s can be used to model a coin toss, since they all guarantee a 50% chance of drawing a \\(\\fbox{1}\\). The fact that the binomial distribution does not depend on \\(N\\) should not be surprising in light of (13.2), which shows that the binomial p.m.f. can be written solely in terms of \\(p = N_1 / N\\), the proportion of \\(\\fbox{1}\\)s in the box. Calculating Binomial Probabilities on the Computer Calculating binomial probabilities by hand can be unwieldy when \\(n\\) is large. Fortunately, the binomial distribution is built into many software packages. For example, suppose we want to solve the following problem. Example 13.2 (Parity Checks) Messages that are exactly 50-bits long are regularly sent over a noisy communication channel. Each bit has a 1% chance of being corrupted by the channel. That is, the receiver saw a \\(0\\) where the original message had a \\(1\\), and vice versa. Each bit is corrupted independently of any other bit. To help detect errors, a 51st bit, called a parity bit, is sent along with the message. This bit is chosen to make the sum of all 51 bits come out to an even integer. When the receiver receives the message, she can calculate the sum of all 51 bits herself. If the sum is odd, then she knows that the message has been corrupted and can ask the sender to resend the message. This is called a parity check. The parity check works if exactly one bit is corrupted. However, if exactly two bits are corrupted, then the sum of all 51 bits will be even, and hence the receiver will not detect the error. In general, errors will not be detected if an even number of bits are corrupted. What is the probability that a corrupted message goes undetected? Solution. First, we will set up a box model for the number of corrupted bits. We have a box with \\(N_0 = 99\\) tickets labeled \\(\\fbox{0}\\) \\(N_1 = 1\\) tickets labeled \\(\\fbox{1}\\) to represent the 1% chance that each bit is corrupted. We will draw 51 times from this box to represent the 51 bits in the message. We draw with replacement, since the bits are corrupted independently. Now, the number of \\(\\fbox{1}\\)s in the 51 draws corresponds to the number of corrupted bits. Therefore, we know that the number of corrupted bits, which we will call \\(X\\), follows a \\(\\text{Binomial}(n=51, N_1=1, N_0=99)\\) distribution. The probability that a corrupted message goes undetected is the probability that \\(X\\) is positive and even. (If \\(X=0\\), then the message was not corrupted in the first place. If \\(X\\) is odd, then the error will be caught by the parity check.) To calculate this probability, we sum the p.m.f. over the relevant values: \\[\\begin{align*} P(\\text{corrupted message goes undetected}) &amp;= P(\\text{$X$ is positive and even}) \\\\ &amp;= f(2) + f(4) + f(6) + \\ldots + f(50) \\end{align*}\\] This requires evaluating the p.m.f. at 25 different values! This is a job for a computer, not a human. Here’s how we would calculate the probability using the Python library Symbulate. We first specify the parameters of the binomial distribution. Note that Symbulate requires that the parameters be \\(n\\) and \\(p\\), so we have to convert \\(N_1=1, N_0=99\\) into \\(p = 0.01\\). Then, we create a list of the positive even values and evaluate the p.m.f. at all of these values, in one fell swoop, using the .pmf() method. from symbulate import * probs = Binomial(n=51, p=0.01).pmf(range(2, 51, 2)) probs ## array([7.79174480e-02, 1.55818996e-03, 1.14573571e-05, 4.13324569e-08, ## 8.46244910e-11, 1.07274277e-13, 8.91255091e-17, 5.04689904e-20, ## 2.00253338e-23, 5.67792557e-27, 1.16616574e-30, 1.75027722e-34, ## 1.92868014e-38, 1.56177790e-42, 9.26787459e-47, 4.00356955e-51, ## 1.24511721e-55, 2.74244677e-60, 4.17928311e-65, 4.26413949e-70, ## 2.77920480e-75, 1.07909959e-80, 2.23393269e-86, 2.02064767e-92, ## 5.04900000e-99]) To add these probabilities, we call sum(): sum(probs) ## 0.07948713677652883 You can play around with the Python code in this Colab notebook. It is also possible to do this calculation in R, a statistical programming language. Note that R uses the names size= and prob= for \\(n\\) and \\(p\\), respectively. We create a list of the positive even integers from 2 to 51, and evaluate the binomial p.m.f. at these values. probs &lt;- dbinom(seq(from=2, to=51, by=2), size=51, prob=0.01) probs ## [1] 7.791745e-02 1.558190e-03 1.145736e-05 4.133246e-08 8.462449e-11 ## [6] 1.072743e-13 8.912551e-17 5.046899e-20 2.002533e-23 5.677926e-27 ## [11] 1.166166e-30 1.750277e-34 1.928680e-38 1.561778e-42 9.267875e-47 ## [16] 4.003570e-51 1.245117e-55 2.742447e-60 4.179283e-65 4.264139e-70 ## [21] 2.779205e-75 1.079100e-80 2.233933e-86 2.020648e-92 5.049000e-99 To add these probabilities, we call sum(): sum(probs) ## [1] 0.07948714 You can play around with the R code in this Colab notebook. Essential Practice Show Mr. Pepys that C (at least 3 ⚅s in 18 rolls) is actually the least likely of the three options. About 10% of passengers who are scheduled to take a particular flight fail to show up. For this reason, airlines overbook flights, selling more tickets than they have seats, with the expectation that they will have some no shows. An airline with seating for 100 passengers sells 110 tickets for the flight. What is the probability that they will have enough seats for all the passengers for all of the passengers who show up for the flight? (Assume that passengers independently show up for the flight. Can you think of a situation where this would not be a reasonable assumption?) In the World Series of baseball, two teams (call them A and B) play a sequence of games against each other, and the first team to win four games wins the series. Suppose team \\(A\\) is slightly better, with a \\(0.6\\) probability of winning each game, and assume the games are independent. What is the probability that team \\(A\\) wins the series? (Hint: After 7 games, one of the teams must have won the Series. Even though the teams only play until one team has won four games, this calculation is easiest if you assume that the teams always play 7 games.) Additional Exercises In the carnival game chuck-a-luck, three dice are rolled. You can make a bet on a particular number (1, 2, 3, 4, 5, 6) showing up. The payout is 1 to 1 if that number shows on (exactly) one die, 2 to 1 if it shows on two dice, and 3 to 1 if it shows up on all three. (You lose your initial stake if your number does not show on any of the dice.) If you make a $1 bet on the number three, what is the distribution of the amount you win? (Hint: The random variable is not binomial but very closely related to a binomial. You can should be able to write the p.m.f. as a table.) "],
["geometric.html", "Lesson 14 Geometric Distribution Motivating Example Theory Essential Practice", " Lesson 14 Geometric Distribution Motivating Example In the casino game craps, after the “point” has been set, two dice are rolled repeatedly until either the “point” or a 7 comes up, at which time the round ends. Suppose the point is 4. What is the probability that it takes more than 6 rolls for the round to end? We can calculate the probability that the round ends on a given roll by directly counting the 36 possible outcomes of two dice: \\[ P(\\text{roll a 4 or a 7}) = \\frac{9}{36}. \\] But how do we use this to determine the probability that it takes more than 6 rolls for the round to end? Theory Theorem 14.1 (Geometric Distribution) If a random variable can be described as the number of draws, with replacement, from the box \\[ \\overbrace{\\underbrace{\\fbox{0}\\ \\ldots \\fbox{0}}_{N_0}\\ \\underbrace{\\fbox{1}\\ \\ldots \\fbox{1}}_{N_1}}^N \\] until a \\(\\fbox{1}\\) is drawn, then its p.m.f. is given by \\[\\begin{equation} f(x) = \\dfrac{N_0^{x-1} \\cdot N_1}{N^x}, x=1, 2, 3, \\ldots \\tag{14.1} \\end{equation}\\] where \\(N = N_1 + N_0\\) is the number of tickets in the box. We say that the random variable has a \\(\\text{Geometric}(N_1, N_0)\\) distribution, and \\(N_1\\), \\(N_0\\) are called parameters of the distribution. Equivalently, (14.1) can be written as \\[\\begin{equation} f(x) = (1-p)^{x-1} p, x=1, 2, 3, \\ldots, \\tag{14.2} \\end{equation}\\] where \\(p = N_1 / N\\) is the proportion of \\(\\fbox{1}\\)s in the box. So we can instead specify the distribution as \\(\\text{Geometric}(p)\\), where \\(p\\) is the parameter. Note that in contrast to the hypergeometric and binomial distributions, there is no upper bound on the possible values of the geometric distribution. We could draw an unlimited number of \\(\\fbox{0}\\)s, so in theory, we might need to wait an arbitrarily long time for a \\(\\fbox{1}\\). We will derive the formulas (14.1) and (14.2) later in this lesson. For now, let’s see how these formulas can be used to solve problems. Example 14.1 (The Craps Problem) Let’s model each roll as a draw from a box. There are \\(36\\) equally likely outcomes when we roll two dice, so we place \\(N=36\\) tickets into the box. Only 9 of these outcomes results in the end of the round, so we label \\(N_1=9\\) of these tickets as \\(\\fbox{1}\\); the other \\(N_0=27\\) tickets are labeled \\(\\fbox{0}\\). \\[ \\overbrace{\\underbrace{\\fbox{1}\\ \\ldots \\fbox{1}}_{N_1=9}\\ \\underbrace{\\fbox{0}\\ \\ldots \\fbox{0}}_{N_0=27}}^{N=36} \\] Now, the number of rolls until the end of the round is just the number of draws until a \\(\\fbox{1}\\) is drawn. So the number of rolls follows the \\(\\text{Geometric}(N_1=9, N_0=27)\\) distribution. We can now write down its p.m.f. by plugging the values of the parameters \\(N_1\\), \\(N_0\\) into (14.1): \\[ f(x) = \\frac{27^{x-1} \\cdot 9}{36^x}, x=1, 2, \\ldots. \\] Equivalently, we have \\(p = N_1/N = 9/36\\), and plugging in this value into (14.2), we have: \\[ f(x) = \\left(1 - \\frac{9}{36}\\right)^{x-1} \\frac{9}{36}, x=1, 2, \\ldots. \\] Finally, we can calculate probability that it takes more than 6 rolls for the round to end in a few different ways: Using the complement rule and the geometric distribution: \\[\\begin{align*} P(X &gt; 6) &amp;= 1 - P(X \\leq 6) \\\\ &amp;= 1 - (f(1) + f(2) + \\ldots + f(6)) \\\\ &amp;= 1 - \\left( \\frac{27}{36} \\right)^0 \\frac{9}{36} - \\left( \\frac{27}{36} \\right)^1 \\frac{9}{36} - \\ldots - \\left( \\frac{27}{36} \\right)^5 \\frac{9}{36} \\\\ &amp;\\approx .178. \\end{align*}\\] Directly, using the geometric distribution and the geometric series: \\[\\begin{align*} P(X &gt; 6) &amp;= f(7) + f(8) + f(9) + ... \\\\ &amp;= \\left( \\frac{27}{36} \\right)^6 \\frac{9}{36} + \\left( \\frac{27}{36} \\right)^7 \\frac{9}{36} + \\left( \\frac{27}{36} \\right)^8 \\frac{9}{36} + \\ldots \\\\ &amp;= \\frac{\\left( \\frac{27}{36} \\right)^6 \\frac{9}{36}}{ 1 - \\frac{27}{36}} \\\\ &amp;\\approx .178. \\end{align*}\\] In the second-to-last line, we used the formula for an infinite geometric series: \\[ a + ar + ar^2 + ar^3 + \\ldots = \\frac{a}{1 - r}, |r| &lt; 1. \\] Without using the geometric distribution at all. In order for the round to end after more than 6 rolls, the first 6 rolls must all have failed to end the round. In other words, all 6 of these rolls resulted in one of the other 27 outcomes. The probability of this is \\[ \\frac{27^6}{36^6} \\approx .178. \\] Now, let’s derive the p.m.f. of the geometric distribution. Proof (Theorem 14.1). To calculate the p.m.f. at \\(x\\), we need to determine the probability that it takes exactly \\(x\\) draws to get the first \\(\\fbox{1}\\). First, there are \\(N^x\\) equally likely ways to draw \\(x\\) tickets from \\(N\\) with replacement, taking order into account. (We must count ordered outcomes because the unordered outcomes are not all equally likely. See Lesson 4.) Next, we count the outcomes where the first \\(\\fbox{1}\\) is on the \\(x\\)th draw. In order for this to happen, the first \\(x-1\\) draws must all be \\(\\fbox{0}\\)s and the \\(x\\)th draw a \\(\\fbox{1}\\): \\[\\begin{equation} \\underbrace{\\fbox{0}, \\ldots, \\fbox{0}}_{x-1}, \\fbox{1}. \\tag{14.3} \\end{equation}\\] The number of ways to do this is: \\[\\begin{equation} \\underbrace{N_0 \\cdot \\ldots \\cdot N_0}_{x-1} \\cdot N_1, \\tag{14.4} \\end{equation}\\] since we are drawing with replacement (so the composition of the box does not change from one draw to the next). Dividing this by the total number of outcomes, we obtain the p.m.f. \\[ f(x) = P(X = x) = \\frac{N_0^{x-1} \\cdot N_1}{N^x}. \\] To see that this formula is the same as (14.2), we write \\(N^x = N^{x-1} \\cdot N\\). Then, we have: \\[\\begin{align*} f(x) &amp;= \\frac{N_0^{x-1} \\cdot N_1}{N^{x-1} \\cdot N} \\\\ &amp;= \\left( \\frac{N_0}{N} \\right)^{x-1} \\frac{N_1}{N} \\\\ &amp;= (1 - p)^{x-1} p, \\end{align*}\\] where in the last line, we used the fact that \\(\\frac{N_0}{N} = \\frac{N - N_1}{N} = 1 - \\frac{N_1}{N} = 1 - p\\). Visualizing the Distribution Let’s graph the geometric distribution for different values of \\(N_1\\) and \\(N_0\\). As the number of \\(\\fbox{1}\\)s in the box increases, we tend to draw a \\(\\fbox{1}\\) sooner, so not surprisingly, smaller values of the geometric random variable become more probable. Essential Practice Carl is a bad driver, so each time he takes the driving test, he only has a \\(30\\%\\) chance of passing, independently of all previous attempts. If he takes the driving test over and over until he passes, what is the probability that he passes within his first 5 attempts? Samuel Pepys was interested in the probability of getting at least 1 ⚅ in 6 throws of a die. Previously, we saw how this probability could be calculated using the complement rule or the binomial distribution. Show how this probability can also be calculated by defining an appropriate geometric random variable. "],
["negative-binomial.html", "Lesson 15 Negative Binomial Distribution Motivating Example Theory Essential Practice Additional Exercises", " Lesson 15 Negative Binomial Distribution Motivating Example On a (American) roulette wheel, there are 38 spaces: 18 black, 18 red, and 2 green. You’ve been at the casino for a while now and decide to leave after you have won 3 bets on red. What is the probability that you leave the casino after placing exactly 5 bets on red? Theory To answer the question posed at the beginning of the lesson, we need a distribution like the geometric, except that stops after \\(3\\) \\(\\fbox{1}\\)s have been drawn (instead of after the first \\(\\fbox{1}\\)). The negative binomial is that distribution. Theorem 15.1 (Negative Binomial Distribution) If a random variable can be described as the number of draws, with replacement, from the box \\[ \\overbrace{\\underbrace{\\fbox{0}\\ \\ldots \\fbox{0}}_{N_0}\\ \\underbrace{\\fbox{1}\\ \\ldots \\fbox{1}}_{N_1}}^N \\] until \\(r\\) \\(\\fbox{1}\\)s have been drawn, then its p.m.f. is given by \\[\\begin{align} f(x) &amp;= \\dfrac{\\binom{x-1}{r-1} N_0^{x-r} \\cdot N_1^r}{N^x}, &amp; x&amp;=r, r+1, r+2, \\ldots \\tag{15.1} \\end{align}\\] where \\(N = N_1 + N_0\\) is the number of tickets in the box. We say that the random variable has a \\(\\text{NegativeBinomial}(r, N_1, N_0)\\) distribution, and \\(r\\), \\(N_1\\), \\(N_0\\) are called parameters of the distribution. Equivalently, (15.1) can be written as \\[\\begin{align} f(x) &amp;= \\binom{x-1}{r-1} (1-p)^{x-r} p^r, &amp; x &amp;= r, r+1, r+2, \\ldots, \\tag{15.2} \\end{align}\\] where \\(p = N_1 / N\\) is the proportion of \\(\\fbox{1}\\)s in the box. So we can instead specify the distribution as \\(\\text{NegativeBinomial}(r, p)\\), where \\(r\\) and \\(p\\) are the parameters. Like the geometric distribution, there is no upper bound on the possible values of a negative binomial random variable. We might have to wait arbitrarily long to collect \\(r\\) \\(\\fbox{1}\\)s. Also, note that the minimum possible value of a negative binomial random variable is \\(r\\). This makes sense because you need to have drawn at least \\(r\\) times before you can have \\(r\\) \\(\\fbox{1}\\)s. We will derive the formulas (15.1) and (15.2) later in this lesson. For now, let’s see how these formulas can be applied to real problems. Example 15.1 (Three Wins in Roulette) There are 38 equally likely spaces on a roulette wheel, 18 of which are red. So we set up a box model where the \\(\\fbox{1}\\)s represent the red spaces: \\[ \\overbrace{\\underbrace{\\fbox{1}\\ \\ldots \\fbox{1}}_{N_1=18}\\ \\underbrace{\\fbox{0}\\ \\ldots \\fbox{0}}_{N_0=20}}^{N=38} \\] The number of draws until we get \\(r=3\\) \\(\\fbox{1}\\)s corresponds to the number of bets we make until we have won 3 times. So the number of bets follows a \\(\\text{NegativeBinomial}(r=3, N_1=18, N_0=20)\\) distribution. Therefore, we know its p.m.f. by (15.2): \\[ f(x) = \\binom{x-1}{3-1} \\left( \\frac{20}{38} \\right)^{x-3} \\left( \\frac{18}{38} \\right)^3. \\] To calculate the probability that we leave the casino after exactly 5 bets, we plug in \\(5\\) for \\(x\\): \\[ f(5) = \\binom{4}{2} \\left( \\frac{20}{38} \\right)^2 \\left( \\frac{18}{38} \\right)^3 \\approx .1766. \\] Now, let’s derive the p.m.f. of the binomial distribution. Proof (Theorem 15.1). To calculate the p.m.f. at \\(x\\), we need to determine the probability that it takes exactly \\(x\\) draws to get \\(r\\) \\(\\fbox{1}\\)s. First, there are \\(N^x\\) equally likely ways to draw \\(x\\) tickets from \\(N\\) with replacement, taking order into account. (We must count ordered outcomes because the unordered outcomes are not all equally likely. See Lesson 4.) Next, we count the outcomes where the \\(r\\)th \\(\\fbox{1}\\) happens on the \\(x\\)th draw. We proceed in two steps: Count outcomes that look like \\[\\begin{equation} \\underbrace{\\fbox{0}, \\ldots, \\fbox{0}}_{x-r}, \\underbrace{\\fbox{1}, \\ldots, \\fbox{1}}_{r}, \\tag{15.3} \\end{equation}\\] where the \\(r\\) \\(\\fbox{1}\\)s are all at the end. There are \\(N_0\\) choices for the first \\(\\fbox{0}\\), \\(N_0\\) choices for the second \\(\\fbox{0}\\), and in fact, \\(N_0\\) choices for each of the \\(x-r\\) \\(\\fbox{0}\\)s, since we are drawing with replacement. Likewise, there are \\(N_1\\) choices for each of the \\(r\\) \\(\\fbox{1}\\)s. By the multiplication principle of counting (Theorem 1.1), there are \\[\\begin{equation} N_0^{x-r} \\cdot N_1^r. \\tag{15.4} \\end{equation}\\] ways to get an outcome like (15.3), in that exact order. Account for the possibility that the \\(\\fbox{1}\\)s and \\(\\fbox{0}\\)s were drawn in a different order than (15.3). Unlike the binomial, we cannot rearrange the \\(\\fbox{1}\\)s and \\(\\fbox{0}\\)s any order we like. With the negative binomial, the \\(x\\)th draw must be a \\(\\fbox{1}\\), since we need the \\(r\\)th \\(\\fbox{1}\\) to come on the \\(x\\)th draw. Other than this last draw, we have complete freedom to rearrange the remaining \\(r-1\\) \\(\\fbox{1}\\)s among the first \\(x-1\\) draws. Therefore, there are \\(\\binom{x-1}{r-1}\\) valid arrangements of the \\(\\fbox{1}\\)s and \\(\\fbox{0}\\)s where that the \\(r\\)th \\(\\fbox{1}\\) comes on the \\(x\\)th draw. So the total number of (ordered) ways to get the \\(r\\)th \\(\\fbox{1}\\)s on the \\(x\\)th draw is: \\[ \\binom{x-1}{r-1} \\cdot N_0^{x-r} \\cdot N_1^r. \\] Dividing this by the total number of outcomes, \\(N^x\\), gives the p.m.f.: \\[ f(x) = P(X = x) = \\frac{\\binom{x-1}{r-1} \\cdot N_0^{x-r} \\cdot N_1^r}{N^x}. \\] To see that this formula is the same as (15.2), we write \\(N^n = N^{x-r} \\cdot N^{r}\\). Then, we have: \\[\\begin{align*} f(x) &amp;= \\binom{x-1}{r-1} \\frac{N_0^{x-r} \\cdot N_1^r}{N^{x-r} \\cdot N^{r}} \\\\ &amp;= \\binom{x-1}{r-1} \\left( \\frac{N_0}{N} \\right)^{x-r} \\left( \\frac{N_1}{N} \\right)^{r} \\\\ &amp;= \\binom{x-1}{r-1} (1 - p)^{x-r} p^r, \\end{align*}\\] where in the last line, we used the fact that \\(\\frac{N_0}{N} = \\frac{N - N_1}{N} = 1 - \\frac{N_1}{N} = 1 - p\\). Visualizing the Distribution Let’s graph the negative binomial distribution for different values of \\(n\\), \\(N_1\\), and \\(N_0\\). First, we fix the number of \\(\\fbox{1}\\)s at \\(r=5\\) and vary the composition of the box. Not surprisingly, as we increase the number of \\(\\fbox{1}\\)s in the box, the \\(\\fbox{1}\\)s are drawn sooner, so the \\(r=5\\)th \\(\\fbox{1}\\) comes after fewer draws. Next, we study the effect of increasing \\(r\\) on the negative binomial distribution. Not surprisingly, when we require more \\(\\fbox{1}\\)s by increasing \\(r\\), the distribution shifts to the right, indicating that it takes longer to achieve that goal. Calculating Negative Binomial Probabilities on the Computer The negative binomial distribution is built into many software packages. However, we have to check which definition the package is using. Some packages define a negative binomial random variable to be the number of \\(\\fbox{0}\\)s that were drawn, instead of the total number of draws. Example 15.2 (Telemarketing) Suppose a telemarketer has a 15% chance of making a sale on any given phone call. He is required to make 10 successful sales before leaving for the day. What is the probability that he needs to make more than 40 calls? Solution. First, we will set up a box model for the number of calls. We have a box with \\(N_0 = 85\\) tickets labeled \\(\\fbox{0}\\) \\(N_1 = 15\\) tickets labeled \\(\\fbox{1}\\) to represent the 15% chance of making a sale. We will draw from this box until we have drawn 10 \\(\\fbox{1}\\)s, representing the 10 successful calls. We will assume that his success on one call is independent of his success on any other call, so we make the draws with replacement. This shows that the number of calls, which we will call \\(X\\), follows a \\(\\text{NegativeBinomial}(r=10, N_1=15, N_0=85)\\) distribution. The probability that he has to make more than 40 calls is \\(P(X &gt; 40)\\). To calculate this directly, we would have to evaluate an infinite sum: \\[ P(X &gt; 40) = f(41) + f(42) + f(43) + \\ldots. \\] The complement rule makes this slightly more palatable: \\[ P(X &gt; 40) = 1 - P(X \\leq 40) = 1 - f(40) - f(39) - \\ldots - f(10), \\] but this is still a calculation that would be unpleasant to do by hand. Here’s how we would calculate the probability using the Python library Symbulate. We first specify the parameters of the negative binomial distribution. Note that Symbulate requires that the parameters be \\(r\\) and \\(p\\), so we have to convert \\(N_1=15, N_0=85\\) into \\(p = 0.15\\). Calculating the probability directly involves evaluating the p.m.f. at infinitely many values, so we look at the complement. We can evaluate the p.m.f. at all of these values using the .pmf() method and add the probabilities using sum(). from symbulate import * probs = NegativeBinomial(r=10, p=0.15).pmf( range(10, 41) # range(..., 41) does not include 41 ) 1 - sum(probs) ## 0.9327797386121522 Alternatively, we could also calculate this using the c.d.f. and the complement rule: 1 - NegativeBinomial(r=10, p=0.15).cdf(40) ## 0.9327797386121518 You can play around with the Python code in this Colab notebook. It is also possible to do this calculation in R, a statistical programming language. R defines the negative binomial distribution a bit differently; it only counts the number of \\(\\fbox{0}\\)s that were drawn, rather than the total number of draws. So we have to remember to subtract the \\(r=10\\) \\(\\fbox{1}\\)s from the total number of draws before passing the values to dnbinom or pnbinom. probs &lt;- dnbinom((10:40) - 10 , size=10, prob=0.15) 1 - sum(probs) ## [1] 0.9327797 We can also use the c.d.f. function: 1 - pnbinom(40 - 10, size=10, prob=0.15) ## [1] 0.9327797 You can play around with the R code in this Colab notebook. Essential Practice Complete the sentence: The geometric distribution is a special case of the negative binomial distribution where \\(r=\\) _____. Calculate the following probabilities. You toss a coin 4 times. The probability that you get (exactly) 2 heads. You toss a coin until you get 2 heads. The probability that it takes (exactly) 4 tosses. Which is larger? Explain why the answer makes intuitive sense. In Major League Baseball’s Home Run Derby, each contestant is allowed to keep swinging the bat until they have made 10 “outs”. (An “out” is anything that is not a home run.) If Barry Bonds has a 70% chance of hitting a home run on any given swing, what is the probability that he hits at least 10 home runs before his turn is up? Additional Exercises A medical researcher is recruiting 20 subjects for a study on an experimental drug for COVID-19. Each person that she interviews has a 60% chance of being eligible to participate in the study. What is the probability that she will have to interview more than 40 people? Your coach tells you that you cannot leave basketball practice until you have made at least \\(20\\) free throws. If you free throw probability is \\(80\\%\\), find the probability that you are out of practice after taking an even amount of free throws. You have two coins. One coin is a fair coin with a \\(.5\\) probability of landing on heads. The other coin is a biased coin with a \\(.25\\) probability of landing on heads. You pick one of these two coins at random, and begin flipping until you get \\(5\\) heads. It takes you \\(12\\) flips in order to get your \\(5\\) heads. What is the probability that the coin you picked was the fair coin? What is the probability you picked the biased coin? "],
["poisson.html", "Lesson 16 Poisson Distribution Motivating Example Theory Essential Practice", " Lesson 16 Poisson Distribution Motivating Example You are in a room of \\(n\\) people (including yourself). Each person in the room has contributed $1 to a central pot, so there is a total of $\\(n\\) in the pot. The money in the pot will be redistributed back to the people in the room, in the following way: each dollar is equally likely to go to any one of the \\(n\\) people, independently of the other dollars in the pot. This means that some people could get more than $1, while others end up with nothing. As \\(n\\to\\infty\\), what is the probability that you end up with no money? There are two common schools of thought: As \\(n\\to\\infty\\), the number of dollars in the pot increases to infinity, so it seems that the probability that you end up with at least one of those dollars should approach \\(1\\), i.e., the probability that you end up with no money approaches 0. As \\(n\\to\\infty\\), the chance that you earn each dollar, \\(1/n\\), decreases to 0, so it seems that the probability that you end up with no money approaches 1. Which school of thought is correct? As it turns out, both arguments are wrong. Let’s see why. We can model the number of dollars you get as the number of \\(\\fbox{1}\\)s in \\(n\\) draws, with replacement, from the box \\[ \\overbrace{\\fbox{1}\\ \\underbrace{\\fbox{0}\\ \\ldots\\ \\fbox{0}}_{n-1}}^{n}. \\] (Each ticket in the box represents a person in the room. Each draw represents a dollar, and you only get that dollar if your name is drawn.) This is exactly the description of a \\(\\text{Binomial}(n, p=\\frac{1}{n})\\) distribution. So the probability that you end up with no money is \\[\\begin{align*} f(0) &amp;= \\binom{n}{0} \\left( \\frac{1}{n} \\right)^{0} \\left( 1 - \\frac{1}{n} \\right)^{n} \\\\ &amp;= \\left(1 - \\frac{1}{n} \\right)^n. \\end{align*}\\] What is the limit of this probability as \\(n\\to\\infty\\)? Try plugging in some very large numbers for \\(n\\) into the expression above. You will see that the probability is nowhere near 0 or 1. But what is it approaching? This is a very famous limit in mathematics. In case you are not familiar with it, take the (natural) logarithm to bring the \\(n\\) down from the exponent, and apply L’Hôpital’s Rule: \\[\\begin{align*} \\lim_{n\\to\\infty} \\log \\left(1 - \\frac{1}{n} \\right)^n &amp;= \\lim_{n\\to\\infty} n \\log \\left(1 - \\frac{1}{n} \\right) &amp; \\text{(Property of logs: $\\log b^a = a \\log b$)} \\\\ &amp;= \\lim_{x \\to 0} \\frac{\\log \\left(1 - x \\right)}{x} &amp; \\text{(Let $x = 1/n$.)} \\\\ &amp;= \\lim_{x \\to 0} \\frac{\\frac{d}{dx} \\log \\left(1 - x \\right)}{\\frac{d}{dx} x} &amp; \\text{(L&#39;Hôpital&#39;s Rule on $0/0$ indeterminate form)} \\\\ &amp;= \\lim_{x \\to 0} \\frac{-\\frac{1}{1 - x}}{1} &amp; \\text{(Remember your derivatives?)} \\\\ &amp;= -1. \\end{align*}\\] Remember that \\(-1\\) is the limit of the logarithm, so to obtain the limit of the original expression, we need to “undo” the logarithm, i.e., exponentiate: \\[\\begin{equation} \\lim_{n\\to\\infty} \\left(1 - \\frac{1}{n} \\right)^n = e^{-1}. \\tag{16.1} \\end{equation}\\] So the probability that you end up with no money approaches \\(1/e \\approx 0.368\\) as \\(n\\to\\infty\\). Theory The motivating example above illustrates a general phenomenon. A binomial distribution with large \\(n\\) and small \\(p\\) can be approximated by a p.m.f. involving the constant \\(e\\). The next theorem makes this precise. Theorem 16.1 (Poisson Distribution) Let \\(X\\) be a \\(\\text{Binomial}(n, p=\\frac{\\mu}{n})\\) random variable, where \\(\\mu\\) is a constant. Then, as \\(n\\to\\infty\\), the p.m.f. of \\(X\\) approaches \\[\\begin{align} f(x) &amp;= e^{-\\mu}\\dfrac{\\mu^x}{x!} &amp; x&amp;=0, 1, 2, .... \\tag{16.2} \\end{align}\\] A random variable with (16.2) as its p.m.f. is said to follow a \\(\\text{Poisson}(\\mu)\\) distribution. Example 16.1 In the motivating example, \\(\\mu = 1\\), so \\(f(0) = e^{-1} \\frac{1^0}{0!} = e^{-1}\\), which matches (16.1). Even when the data does not originate from a binomial model, it is common to assume that count data follow a Poisson distribution. In the next example, we are explicitly told that the random variable follows a Poisson distribution. Example 16.2 (Database Queries) The number of typos in a New York Times op-ed when it reaches the copy editor is a \\(\\text{Poisson}(\\mu=4.6)\\) random variable. What is the probability that there are 2 or more typos in a randomly selected op-ed? Solution. Let \\(X\\) be the number of typos in the op-ed. We want to know \\(P(X \\geq 2)\\). We could calculate this directly, but that would involve summing the p.m.f. at infinitely many values. Instead, we use the Complement Rule (5.2): \\[\\begin{align*} P(X \\geq 2) &amp;= 1 - P(X &lt; 2) \\\\ &amp;= 1 - f(0) - f(1) \\\\ &amp;= 1 - e^{-4.6} \\frac{4.6^0}{0!} - e^{-4.6} \\frac{4.6^1}{1!} \\\\ &amp;= 1 - e^{-4.6} - 4.6 e^{-4.6} \\\\ &amp;\\approx .944. \\end{align*}\\] Why might the Poisson distribution be a reasonable model for the number of typos? Each op-ed has many words (e.g., \\(n = 1000\\)). There is a small probability that each word has a typo (e.g., \\(p = .0046\\)). If typos are independent across words, then the number of typos follows a binomial distribution. Since \\(n\\) is large and \\(p\\) is small, this binomial distribution can be approximated by a \\(\\text{Poisson}(\\mu=np=4.6)\\) distribution. However, all of this is conjecture. We are not told how many words the op-ed has, nor the probability that each word has a typo. We simply assume that the number of typos follows a Poisson distribution. In practice, the Poisson model is often used for count data, even when there is no underlying binomial model. Finally, we include the proof of Theorem 16.1 for completeness. This proof is not particularly interesting or insightful, so you do not need to know it. Proof (Theorem 16.1, optional). Substitute \\(p = \\frac{\\mu}{n}\\) into the binomial p.m.f. and watch what happens as \\(n \\to \\infty\\): \\[\\begin{align*} f(x) &amp;= \\binom{n}{x} (\\frac{\\mu}{n})^x (1 - \\frac{\\mu}{n})^{n-x} \\\\ &amp;= \\frac{n!}{x!(n-x)!} \\frac{\\mu^x}{n^x} (1 - \\frac{\\mu}{n})^{n-x} \\\\ &amp;= \\frac{n!}{(n-x)! n^x} \\cdot \\frac{\\mu^x}{x!} \\cdot (1 - \\frac{\\mu}{n})^{n-x} \\\\ &amp;\\to 1 \\cdot \\frac{\\mu^x}{x!} \\cdot e^{-\\mu} \\end{align*}\\] Visualizing the Distribution Let’s graph the Poisson distribution for different values of \\(\\mu\\). The probability mass shifts to the right as \\(\\mu\\) increases. This makes sense if we interpret the Poisson distribution as an approximation to the binomial, where \\(\\mu=np\\). To increase \\(\\mu\\), we must either increase \\(n\\) or \\(p\\), both of which tend to increase the number of \\(\\fbox{1}\\)s that we draw. Calculating Poisson Probabilities on the Computer The Poisson distribution is built into many software packages. Example 16.3 (Disk Failures at a Data Center) A data center has 10,000 disk drives. Suppose that a disk drive fails in a given day with probability \\(10^{-3}\\). What is the probability that there are 12 or more disk failures tomorrow? How many spare disk drives should be available so that all failures in a day can be replaced with probability 99%? Solution. First, we will set up a box model for the number of disk failures. We have a box with \\(N_0 = 999\\) tickets labeled \\(\\fbox{0}\\) \\(N_1 = 1\\) tickets labeled \\(\\fbox{1}\\) to represent the \\(10^{-3}\\) probability of failure. We will draw 10,000 tickets from this box, with replacement, to represent whether each of the 10,000 disks fails. This shows that the number of failures, which we will call \\(X\\), follows a \\(\\text{Binomial}(n=10^4, p=10^{-3})\\) distribution. We can calculate the exact probabilities using this binomial distribution or approximate probabilities using a \\(\\text{Poisson}(\\mu=np=10)\\) distribution. Either way, we will want to calculate the probabilities at a computer. For example, the quickest way to calculating \\(P(X \\geq 12)\\) still requires calculating \\[ 1 - f(0) - f(1) - f(2) - \\ldots - f(11), \\] which is not something we want to do by hand. Here’s how we would calculate the probability using the Python library Symbulate. from symbulate import * probs = Poisson(10).pmf( range(12) # range(12) is [0, 1, 2, ..., 11] ) 1 - sum(probs) ## 0.303223853696892 Alternatively, we could also calculate this using the c.d.f. and the complement rule. This time, let’s compare the approximate answer that we get from the Poisson distribution with the exact answer that we get from the binomial distribution. 1 - Poisson(10).cdf(11), 1 - Binomial(n=10 ** 4, p=10 ** -3).cdf(11) ## (0.30322385369689386, 0.30316693332735856) Very close indeed! The second question can be addressed by trial and error. We want to figure out the value \\(c\\) such that \\(F(c) = P(X \\leq c) = .99\\). From above, we already know that \\(F(11) \\approx 0.70\\), so we can start trying values from \\(c=12\\). The simple script below increases \\(x\\) by \\(1\\) until the cumulative probability crosses \\(.99\\). x = 12 while Poisson(10).cdf(x) &lt; .99: x += 1 # print out the value of x and the probability x, Poisson(10).cdf(x) ## (18, 0.9928134953961456) You can play around with the Python code in this Colab notebook. It is also possible to do this calculation in R, a statistical programming language. probs &lt;- dpois(0:11, 10) 1 - sum(probs) ## [1] 0.3032239 We can also use the c.d.f. function: 1 - ppois(11, 10) ## [1] 0.3032239 The second question can be addressed by trial and error. We want to figure out the value \\(c\\) such that \\(F(c) = P(X \\leq c) = .99\\). From above, we already know that \\(F(11) \\approx 0.70\\), so we can start trying values from \\(c=12\\). The simple script below increases \\(x\\) by \\(1\\) until the c.d.f. crosses \\(.99\\). x &lt;- 12 while(ppois(x, 10) &lt; .99) { x &lt;- x + 1 } # print out the value of x and the probability c(x, ppois(x, 10)) ## [1] 18.0000000 0.9928135 You can play around with the R code in this Colab notebook. Essential Practice If you buy a lottery ticket in 50 lotteries, in each of which your chances of winning a prize of \\(1/100\\), what is the probability that you will win a prize: at least once? exactly twice? at least twice? Calculate both the exact probabilities (using the binomial distribution) and the approximate probabilities (using the Poisson distribution). The number of organisms in \\(V\\) cubic meters of ballast water discharged from a ship follows a \\(\\text{Poisson}(\\mu=10 V)\\) distribution. (See “Counting at Low Concentrations: The Statistical Challenges of Verifying Ballast Water Discharge Standards”, Ecological Applications, 2013:339–351.) What is the probability that there are at least 12 organisms in 1.5 cubic meters of discharge? For what amount of discharge would the probability of containing at least one organism be .999? Thelma calculates the exact probability of winning more than 50% of the time when she places 1000 bets on red in roulette. Louise calculates an approximate probability using the Poisson distribution. They get very different answers. What answers did they get, and why did the Poisson approximation fail in this case? "],
["poisson-process.html", "Lesson 17 Poisson Process Motivating Example Theory Essential Practice", " Lesson 17 Poisson Process Motivating Example A Geiger counter is a device used for measuring radiation in the atmosphere. Each time it detects a radioactive particle, it makes a clicking sound. In the figure below, the orange points below indicate the times at which the Geiger counter detected a radioactive particle. Figure 17.1: Radioactive Particles Reaching a Geiger Counter The radioactive particles hit the Geiger Counter at seemingly random and unpredictable times. In this lesson, we learn to make sense of the randomness. Theory Radioactive particles are a classic example of a type of random process called the Poisson process. The Poisson process is used to model random events, called “arrivals”, over time. Definition 17.1 (Poisson Process) A Poisson process of rate \\(\\lambda\\) is characterized by the following properties: The number of arrivals in any interval \\((t_0, t_1)\\) follows a Poisson distribution with \\(\\mu = \\lambda (t_1 - t_0)\\). That is, the parameter \\(\\mu\\) increases proportionally to the length of the interval. The numbers of arrivals in non-overlapping intervals are independent. These two properties allow us to calculate any probability of interest. Example 17.1 (Geiger Counter) In San Luis Obispo, radioactive particles reach a Geiger counter according to a Poisson process at a rate of \\(\\lambda = 0.8\\) particles per second. What is the probability that the Geiger counter detects 3 or more particles in the next 4 seconds? What is the probability that the Geiger counter detects (exactly) 1 particle in the next second and 3 or more in the next 4 seconds? Solution. . The number of particles arriving at the detector in the next 4 seconds, \\(X\\), follows a \\(\\text{Poisson}(\\mu = 0.8 \\cdot (4 - 0) = 3.2)\\) distribution by Property 1 (17.1). Therefore, the probability of detecting 3 or more particles is: \\[\\begin{align*} P(X \\geq 3) &amp;= 1 - P(X &lt; 3) \\\\ &amp;= 1 - f(0) - f(1) - f(2) \\\\ &amp;= 1 - e^{-3.2} \\frac{3.2^0}{0!} - e^{-3.2} \\frac{3.2^1}{1!} - e^{-3.2} \\frac{3.2^2}{2!} \\\\ &amp;\\approx .6201 \\end{align*}\\] The joint probability \\[ P(\\text{1 particle in (0, 1)} \\text{ AND } \\text{3 or more particles in (0, 4)}) \\] involves two events that are not independent. However, we can rewrite the joint probability as: \\[ P(\\text{1 particle in (0, 1)} \\text{ AND } \\text{2 or more particles in (1, 4)}). \\] Now, \\((0, 1)\\) and \\((1, 4)\\) are non-overlapping intervals, so the number of particles arriving in \\((0, 1)\\) is independent of the number of particles arriving in \\((1, 4)\\) by Property 2 (17.1). Therefore, by Theorem 7.1, we obtain their joint probability by multiplying their individual probabilities: \\[ P(\\text{1 particle in (0, 1)}) \\cdot P(\\text{2 or more particles in (1, 4)}). \\] Now, we know from Property 1 (17.1) that the number of particles in \\((0, 1)\\) follows a \\(\\text{Poisson}(\\mu = 0.8)\\) distribution, and the number of particles in \\((1, 4)\\) follows a \\(\\text{Poisson}(\\mu = 2.4)\\) distribution. If we represent the p.m.f.s of these two random variables by \\(f_1\\) and \\(f_2\\), respectively, then the probability is \\[ f_1(1) \\cdot \\left(1 - f_2(0) - f_2(1) \\right) = e^{-0.8} \\frac{0.8^1}{1!} \\cdot \\left( 1 - e^{-2.4} \\frac{2.4^0}{0!} - e^{-2.4} \\frac{2.4^1}{1!} \\right) \\approx .2486. \\] We can also calculate these probabilities with the aid of software: from symbulate import * Poisson(0.8 * (1 - 0)).pmf(1) * (1 - Poisson(0.8 * (4 - 1)).cdf(1)) ## 0.24858997647262118 Why Poisson? Why does it make sense to assume that the number of arrivals on any interval follows a Poisson distribution? If we chop time up into tiny segments of length \\(\\Delta t\\), then the probability of an arrival on any one of these segments will be small—but there will be many such intervals. Figure 17.2: Chopping Up Time in a Poisson Process If we further assume that arrivals are independent across these tiny segments, then the number of arrivals follows a binomial distribution, with large \\(n\\) (because there are many segments) and small \\(p\\) (because an arrival is unlikely to fall exactly in any given segment). We saw in Theorem 16.1 that the Poisson distribution is a good approximation to the binomial when \\(n\\) is large and \\(p\\) is small. Technical Detail: In order for the number of arrivals to be binomial, each tiny segment must contain either 1 arrival or none; there cannot be 2 or more arrivals in any segment. Usually, if \\(\\Delta t\\) is so small that it is rare to get even 1 arrival in a segment, then it is essentially impossible to get 2 arrivals. Essential Practice Packets arrive at a certain node on the university’s intranet at 10 packets per minute, on average. Assume packet arrivals meet the assumptions of a Poisson process. Calculate the probability that exactly 15 packets arrive in the next 2 minutes. Calculate the probability that more than 60 packets arrive in the next 5 minutes. Calculate the probability that the next packet will arrive in within 15 seconds. Small aircraft arrive at San Luis Obispo airport according to a Poisson process at a rate of 6 per hour. What is the probability that exactly 5 small aircraft arrive in the first hour (after opening) and exactly 7 arrive in the hour after that? What is the probability that fewer than 5 small aircraft arrive in the first hour and at least 10 arrive in the hour after that? What is the probability that exactly 5 small aircraft arrive in the first hour and exactly 12 aircraft arrive in the first two hours? "],
["joint-discrete.html", "Lesson 18 Joint Distributions Motivating Example Theory Essential Practice Additional Exercises", " Lesson 18 Joint Distributions Motivating Example Xavier and Yolanda head to the roulette table at a casino. They both place bets on red on 3 spins of the roulette wheel before Xavier has to leave. After Xavier leaves, Yolanda places bets on red on 2 more spins of the wheel. Let \\(X\\) be the number of bets that Xavier wins and \\(Y\\) be the number that Yolanda wins. We know that \\(X\\) follows a \\(\\text{Binomial}(n=3, p=\\frac{18}{38})\\) distribution so its p.m.f. is \\[ f(x) = \\binom{3}{x} \\left( \\frac{18}{38} \\right)^x \\left(1 - \\frac{18}{38} \\right)^{3-x}, \\] which we can write in tabular form as \\[ \\begin{array}{r|cccc} x &amp; 0 &amp; 1 &amp; 2 &amp; 3 \\\\ \\hline f(x) &amp; .1458 &amp; .3936 &amp; .3543 &amp; .1063 \\\\ \\end{array}. \\] We also know that \\(Y\\) follows a \\(\\text{Binomial}(n=5, p=\\frac{18}{38})\\) distribution so its p.m.f. is \\[ \\begin{array}{r|cccc} y &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5\\\\ \\hline f(y) &amp; .0404 &amp; .1817 &amp; .3271 &amp; .2944 &amp; .1325 &amp; .0238 \\end{array}. \\] But this does not tell us how \\(X\\) and \\(Y\\) are related to each other. In fact, the two random variables have a very distinctive relationship. For example, \\(Y\\) must be greater than or equal to \\(X\\), since Yolanda made the same three bets that Xavier did, plus two more. In this lesson, we will learn a way to describe the distribution of two (or more) random variables. Theory Definition 18.1 The joint distribution of two random variables \\(X\\) and \\(Y\\) is described by the joint p.m.f. \\[\\begin{equation} f(x, y) = P(X=x \\text{ and } Y=y). \\tag{18.1} \\end{equation}\\] Example 18.1 Let’s work out the joint p.m.f. of \\(X\\), the number of bets that Xavier wins, and \\(Y\\), the number of bets that Yolanda wins. To do this, we will lay out the values of \\(f(x, y)\\) in a table, like the following. \\[\\begin{equation} \\begin{array}{rr|cccc} &amp; 5 &amp; f(0, 5) &amp; f(1, 5) &amp; f(2, 5) &amp; f(3, 5) \\\\ &amp; 4 &amp; f(0, 4) &amp; f(1, 4) &amp; f(2, 4) &amp; f(3, 4) \\\\ y &amp; 3 &amp; f(0, 3) &amp; f(1, 3) &amp; f(2, 3) &amp; f(3, 3) \\\\ &amp; 2 &amp; f(0, 2) &amp; f(1, 2) &amp; f(2, 2) &amp; f(3, 2) \\\\ &amp; 1 &amp; f(0, 1) &amp; f(1, 1) &amp; f(2, 1) &amp; f(3, 1) \\\\ &amp; 0 &amp; f(0, 0) &amp; f(1, 0) &amp; f(2, 0) &amp; f(3, 0) \\\\ \\hline &amp; &amp; 0 &amp; 1 &amp; 2 &amp; 3\\\\ &amp; &amp; &amp; &amp; x \\end{array} \\tag{18.2} \\end{equation}\\] First, we observe that it is impossible for Xavier to win more bets than Yolanda—since Yolanda makes all the bets that Xavier does (plus two more). Therefore, we know that \\(f(x,y) = 0\\) if \\(x &gt; y\\). We also know that Yolanda can at most two more bets than Xavier. So \\(f(x, y) = 0\\) if \\(y &gt; x + 2\\). Therefore, we can fill in half of the entries in the table with zeroes. \\[ \\begin{array}{rr|cccc} &amp; 5 &amp; 0 &amp; 0 &amp; 0 &amp; f(3, 5) \\\\ &amp; 4 &amp; 0 &amp; 0 &amp; f(2, 4) &amp; f(3, 4) \\\\ y &amp; 3 &amp; 0 &amp; f(1, 3) &amp; f(2, 3) &amp; f(3, 3) \\\\ &amp; 2 &amp; f(0, 2) &amp; f(1, 2) &amp; f(2, 2) &amp; 0 \\\\ &amp; 1 &amp; f(0, 1) &amp; f(1, 1) &amp; 0 &amp; 0 \\\\ &amp; 0 &amp; f(0, 0) &amp; 0 &amp; 0 &amp; 0 \\\\ \\hline &amp; &amp; 0 &amp; 1 &amp; 2 &amp; 3\\\\ &amp; &amp; &amp; &amp; x \\end{array} \\] Let’s calculate one of the non-zero joint probabilities: \\[ f(2, 3) = P(X=2 \\text{ and } Y=3). \\] In order for Xavier to win twice and Yolanda to win 3 times, there must have been 2 reds in the first 3 spins and 1 red in the 2 spins after that. Because the first 3 spins and the next 2 spins are independent, we can multiply the two binomial probabilities: \\[\\begin{align*} f(2, 3) &amp;= P(\\text{2 reds in first 3 spins} \\text{ and } \\text{1 red in next 2 spins}) \\\\ &amp;= \\binom{3}{2} \\left( \\frac{18}{38} \\right)^2 \\left( 1 - \\frac{18}{38} \\right)^{1} \\cdot \\binom{2}{1} \\left( \\frac{18}{38} \\right)^1 \\left( 1 - \\frac{18}{38} \\right)^{1} \\\\ &amp;\\approx .1766 \\end{align*}\\] As one more example, let’s calculate \\[ f(1, 1) = P(X=1 \\text{ and } Y=1). \\] In order for Xavier and Yolanda to each win once, there must have been 1 red in the first 3 spins and 0 reds in the next two. Since the first 3 spins and the next 2 spins are independent, we can multiply their probabilities: \\[\\begin{align*} f(1, 1) &amp;= P(\\text{1 red in first 3 spins} \\text{ and } \\text{0 reds in next 2 spins}) \\\\ &amp;= \\binom{3}{1} \\left( \\frac{18}{38} \\right)^1 \\left( 1 - \\frac{18}{38} \\right)^2 \\cdot \\binom{2}{0} \\left( \\frac{18}{38} \\right)^0 \\left( 1 - \\frac{18}{38} \\right)^2 \\\\ &amp;\\approx .1090 \\end{align*}\\] The process for calculating the other probabilities in the table is the same. We look at what each event \\(\\{ X=x \\text{ and } Y=y\\}\\) implies about the number of reds in the first 3 spins and the number of reds in the next 2 spins; because the first 3 spins and the next 2 spins are independent, we can multiply their probabilities. The completed table looks like this: \\[ \\begin{array}{rr|cccc} &amp; 5 &amp; 0 &amp; 0 &amp; 0 &amp; .0238 \\\\ &amp; 4 &amp; 0 &amp; 0 &amp; .0795 &amp; .0530 \\\\ y &amp; 3 &amp; 0 &amp; .0883 &amp; .1766 &amp; .0294 \\\\ &amp; 2 &amp; .0327 &amp; .1963 &amp; .0981 &amp; 0 \\\\ &amp; 1 &amp; .0727 &amp; .1090 &amp; 0 &amp; 0 \\\\ &amp; 0 &amp; .0404 &amp; 0 &amp; 0 &amp; 0 \\\\ \\hline &amp; &amp; 0 &amp; 1 &amp; 2 &amp; 3\\\\ &amp; &amp; &amp; &amp; x \\end{array} \\] Notice that all of the probabilities in this table add up to \\(1.0\\) (up to rounding error). Example 18.2 (Coin Tosses) A fair coin is tossed 6 times. Let \\(X\\) be the number of heads in the first 3 tosses. Let \\(Y\\) be the number of heads in the last 3 tosses. Calculate the joint p.m.f. of \\(X\\) and \\(Y\\), and use it to calculate \\(P(X + Y \\leq 2)\\). Solution. The first 3 tosses and the next 3 tosses are independent. Therefore, we know that \\[ f(x, y) = P(X=x \\text{ and } Y=y) = P(X=x) \\cdot P(Y=y) \\] for any value \\(x\\) and \\(y\\). Since \\(X\\) and \\(Y\\) are both \\(\\text{Binomial}(n=3, N_1=1, N_0=1)\\), we have a formula for their p.m.f.s: \\[\\begin{align*} P(X=x) &amp;= \\frac{\\binom{3}{x}}{2^3} &amp; P(Y=y) &amp;= \\frac{\\binom{3}{y}}{2^3}. \\end{align*}\\] Therefore, we can write the joint p.m.f. as a formula: \\[ f(x, y) = \\frac{\\binom{3}{x}}{2^3}\\cdot \\frac{\\binom{3}{y}}{2^3}, 0 \\leq x, y \\leq 3. \\] This is equivalent to writing the probabilities in a table: \\[ \\begin{array}{rr|cccc} &amp; 3 &amp; .0156 &amp; .0469 &amp; .0469 &amp; .0156 \\\\ y &amp; 2 &amp; .0469 &amp; .1406 &amp; .1406 &amp; .0469 \\\\ &amp; 1 &amp; .0469 &amp; .1406 &amp; .1406 &amp; .0469 \\\\ &amp; 0 &amp; .0156 &amp; .0469 &amp; .0469 &amp; .0156 \\\\ \\hline &amp; &amp; 0 &amp; 1 &amp; 2 &amp; 3\\\\ &amp; &amp; &amp; &amp; x \\end{array}. \\] To use this joint p.m.f. to calculate \\(P(X + Y \\leq 2)\\), we add up \\(f(x, y)\\) for values \\(x\\) and \\(y\\) satisfying \\(x + y \\leq 2\\). As a formula, we can express this as: \\[ P(X + Y \\leq 2) = \\underset{x, y:\\ x + y \\leq 2}{\\sum\\sum} f(x, y). \\] But it is easier to see what probabilities we need to add in the table: \\[ \\begin{array}{rr|cccc} &amp; 3 &amp; .0156 &amp; .0469 &amp; .0469 &amp; .0156 \\\\ y &amp; 2 &amp; \\fbox{.0469} &amp; .1406 &amp; .1406 &amp; .0469 \\\\ &amp; 1 &amp; \\fbox{.0469} &amp; \\fbox{.1406} &amp; .1406 &amp; .0469 \\\\ &amp; 0 &amp; \\fbox{.0156} &amp; \\fbox{.0469} &amp; \\fbox{.0469} &amp; .0156 \\\\ \\hline &amp; &amp; 0 &amp; 1 &amp; 2 &amp; 3\\\\ &amp; &amp; &amp; &amp; x \\end{array}. \\] The answer is: \\[\\begin{align*} P(X + Y \\leq 2) &amp;= f(0, 0) + f(1, 0) + f(0, 1) + f(0, 2) + f(1, 1) + f(2, 0) \\\\ &amp;= .0156 + .0469 + .0469 + .0469 + .1406 + .0469 \\\\ &amp;= .3438. \\end{align*}\\] Of course, we could have obtained this answer without deriving the joint p.m.f. of \\(X\\) and \\(Y\\). The random variable \\(X + Y\\) represents the number of heads in 6 tosses of a fair coin, which we know follows a binomial distribution. Therefore, we can calculate \\(P(X + Y \\leq 2)\\) using the c.d.f. of a binomial distribution: from symbulate import * Binomial(n=6, p=0.5).cdf(2) ## 0.3437500000000001 We get the same answer. Example 18.3 (Chicken and the Egg) The number of eggs laid by a hen, \\(N\\), is a \\(\\text{Poisson}(\\mu)\\) random variable. Each egg hatches with probability \\(p\\), independently of any other egg. Let \\(X\\) be the number of eggs that hatch into baby chickens. Find the joint p.m.f. of \\(N\\) and \\(X\\). Solution. First, observe that \\(N\\) is a random variable that can take on values from \\(0\\) and \\(\\infty\\). We cannot possibly write down all of the probabilities in a table. We will try to write the joint p.m.f. as a formula. We are interested in: \\[ f(n, x) = P(N = n \\text{ and } X = x). \\] By the multiplication rule (Theorem 6.1), we have \\[ P(N = n \\text{ and } X = x) = P(N = n) P(X = x | N = n). \\] Once we know how many eggs there are, then \\(X\\) follows a binomial distribution. In other words, given \\(\\{ N = n \\}\\), \\(X\\) is a \\(\\text{Binomial}(n, p)\\) random variable. Therefore, \\[\\begin{align*} P(N = n) P(X = x | N = n) &amp;= e^{-\\mu} \\frac{\\mu^n}{n!} \\cdot \\binom{n}{x} p^x (1-p)^{n-x} \\\\ &amp;= e^{-\\mu} \\frac{(\\mu p)^x}{x!} \\frac{(\\mu (1-p))^{n-x}}{(n-x)!}. \\end{align*}\\] This formula is only valid when \\(x \\leq n\\), since we cannot have more baby chickens than eggs. So, we can specify the p.m.f. as \\[ f(n, x) = \\begin{cases} e^{-\\mu} \\frac{(\\mu p)^x}{x!} \\frac{(\\mu (1-p))^{n-x}}{(n-x)!} &amp; 0 \\leq x \\leq n &lt; \\infty \\\\ 0 &amp; \\text{otherwise} \\end{cases}. \\] Essential Practice Two tickets are drawn from a box with \\(N_1\\) \\(\\fbox{1}\\)s and \\(N_0\\) \\(\\fbox{0}\\)s. Let \\(X\\) be the number of \\(\\fbox{1}\\)s on the first draw and \\(Y\\) be the number of \\(\\fbox{1}\\)s on the second draw. (Note that \\(X\\) and \\(Y\\) can only be 0 or 1.) Find the joint p.m.f. of \\(X\\) and \\(Y\\) when the draws are made with replacement. Find the joint p.m.f. of \\(X\\) and \\(Y\\) when the draws are made without replacement. (You may specify the joint p.m.f. as a table or a formula, whichever is more convenient for you.) Two fair, six-sided dice are rolled. Let \\(S\\) be the smaller of the numbers on the two dice. Let \\(L\\) be the larger of the numbers on the two dice. (Note: If doubles are rolled, then \\(S = L\\).) Find the joint p.m.f. of \\(S\\) and \\(L\\). Use the joint p.m.f. to calculate \\(P(S + L = 2)\\). Repeat for \\(P(S + L = k)\\), \\(k = 3, 4, 5, \\ldots, 12\\). Why does the answer make sense? A fair coin is tossed 3 times. Let \\(X\\) be the number of heads in these three tosses. Let \\(Y\\) be the number of tails in these three tosses. Find the joint p.m.f. of \\(X\\) and \\(Y\\). (You may specify the joint p.m.f. as a table or a formula, whichever is more convenient for you.) At Diablo Canyon nuclear plant, radioactive particles hit a Geiger counter according to a Poisson process with a rate of 3.5 particles per second. Let \\(X\\) be the number of particles detected in the first 2 seconds. Let \\(Y\\) be the number of particles detected in the second after that (i.e., the 3rd second). Find the joint p.m.f. of \\(X\\) and \\(Y\\). (You may specify the joint p.m.f. as a table or a formula, whichever is more convenient for you.) Additional Exercises A fair coin is tossed 4 times. Let \\(X\\) be the number of heads in the first three tosses. Let \\(Y\\) be the number of heads in the last three tosses. Find the joint p.m.f. of \\(X\\) and \\(Y\\). (Hint: There are only \\(2^4 = 16\\) equally likely outcomes when you toss 4 coins. If you are unable to calculate the probabilities using rules we have learned, just list all the possible outcomes!) At Diablo Canyon nuclear plant, radioactive particles hit a Geiger counter according to a Poisson process with a rate of 3.5 particles per second. Let \\(X\\) be the number of particles detected in the first 2 seconds. Let \\(Z\\) be the number of particles detected in the first 3 seconds. Find the joint p.m.f. of \\(X\\) and \\(Z\\). "],
["marginal-discrete.html", "Lesson 19 Marginal Distributions Motivating Example Theory Essential Practice Additional Exercises", " Lesson 19 Marginal Distributions Motivating Example In Lesson 18, we found the joint distribution of \\(X\\), the number of bets that Xavier wins, and \\(Y\\), the number of bets that Yolanda wins. If all we have is the joint distribution of \\(X\\) and \\(Y\\), can we recover the distribution of \\(X\\) alone? Theory Recall from Lesson 10 that the p.m.f. of \\(X\\) is defined to be \\(P(X = x)\\) as a function of \\(x\\). To calculate a probaebility from a joint p.m.f., we sum over the relevant outcomes. In this case, we need to sum the joint p.m.f. over all the possible values of \\(y\\) for the given \\(x\\): \\[\\begin{equation} P(X = x) = \\sum_y f(x, y). \\tag{19.1} \\end{equation}\\] If the joint p.m.f. is written out in table form, then (19.2) corresponds to the column sums of the table, as illustrated in Figure 19.1. Figure 19.1: Calculating the Marginal Distribution of \\(X\\) Notice how natural it was to write the column totals in the margins of the table in Figure 19.1. For this reason, this collection of probabilities has come to be known as the marginal distribution of \\(X\\). Definition 19.1 (Marginal Distribution) The marginal p.m.f. of \\(X\\) refers to the p.m.f. of \\(X\\) when it is calculated from the joint p.m.f. of \\(X\\) and \\(Y\\). Specifically, the marginal p.m.f. \\(f_X\\) can be calculated from the joint p.m.f. \\(f\\) as follows: \\[\\begin{equation} f_X(x) \\overset{\\text{def}}{=} P(X=x) = \\sum_y f(x, y). \\tag{19.2} \\end{equation}\\] Notice that we use subscripts in \\(f_X\\) to distinguish this function from the joint distribution \\(f\\) and, later, the marginal distribution of \\(Y\\). There is also a marginal distribution of \\(Y\\). As you might guess, the marginal p.m.f. is symbolized \\(f_Y\\) and is calculated by summing over all the possible values of \\(X\\): \\[\\begin{equation} f_Y(y) \\overset{\\text{def}}{=} P(Y=y) = \\sum_x f(x, y). \\tag{19.3} \\end{equation}\\] On a table, the marginal distribution of \\(Y\\) corresponds to the row sums of the table, as illustrated in Figure 19.2. Figure 19.2: Calculating the Marginal Distribution of \\(Y\\) Remember that we know the distribution of \\(Y\\). It is \\(\\text{Binomial}(n=5, p=18/38)\\). You should verify that the marginal distribution we calculated in 19.2 matches that of a \\(\\text{Binomial}(n=5, p=18/38)\\) distribution. Theorem 19.1 (Joint Distribution of Independent Random Variables) If \\(X\\) and \\(Y\\) are independent, then \\[\\begin{equation} f(x, y) = f_X(x) \\cdot f_Y(y) \\end{equation}\\] for all values \\(x\\) and \\(y\\). But only if \\(X\\) and \\(Y\\) are independent! Proof. In Lesson 18, we saw that the joint distribution is defined to be \\[ f(x, y) = P(X = x \\text{ and } Y=y). \\] If \\(X\\) and \\(Y\\) are independent, then we can multiply the probabilities, by Theorem 7.1: \\[ P(X=x) \\cdot P(Y=y). \\] But \\(P(X=x)\\) is just the marginal distribution of \\(X\\) and \\(P(Y=y)\\) the marginal distribution of \\(Y\\). So this is equal to: \\[ f_X(x) \\cdot f_Y(y) \\] Let’s calculate another marginal distribution—this time from the formula representation of the joint p.m.f. Example 19.1 (Marginal Number of Chicks) In Example 18.3, we found that the joint distribution of the number of eggs \\(N\\) and the number of chicks \\(X\\) was \\[\\begin{equation} f(n, x) = \\begin{cases} e^{-\\mu} \\frac{(\\mu p)^x}{x!} \\frac{(\\mu (1-p))^{n-x}}{(n-x)!} &amp; 0 \\leq x \\leq n &lt; \\infty \\\\ 0 &amp; \\text{otherwise} \\end{cases}. \\tag{19.4} \\end{equation}\\] What is the marginal distribution of the number of chicks, \\(X\\)? Solution. By (19.2), we need to sum the joint p.m.f. \\(f(n, x)\\) over all the possible values of \\(N\\). In (19.4), we see that the joint p.m.f. is \\(0\\) unless \\(n \\geq x\\). So we sum the complicated expression in (19.4) for all \\(n\\) from \\(x\\) to \\(\\infty\\). \\[\\begin{align*} f_X(x) &amp;= \\sum_n f(n, x) \\\\ &amp;= \\sum_{n=x}^\\infty e^{-\\mu} \\frac{(\\mu p)^x}{x!} \\frac{(\\mu (1-p))^{n-x}}{(n-x)!} \\\\ &amp;= e^{-\\mu} \\frac{(\\mu p)^x}{x!} \\sum_{n=x}^\\infty \\frac{(\\mu (1-p))^{n-x}}{(n-x)!} &amp; \\text{(pull out terms not depending on $n$)} \\\\ &amp;= e^{-\\mu} \\frac{(\\mu p)^x}{x!} \\sum_{m=0}^\\infty \\frac{\\nu^m}{m!} &amp; (m=n-x, \\nu=\\mu(1-p)) \\\\ &amp;= e^{-\\mu} \\frac{(\\mu p)^x}{x!} e^{\\nu} \\underbrace{\\sum_{m=0}^\\infty e^{-\\nu} \\frac{\\nu^m}{m!}}_{\\text{sum of Poisson$(\\nu)$ p.m.f.} = 1} &amp; \\text{(multiply by $e^{\\nu} e^{-\\nu} = 1$)} \\\\ &amp;= e^{-\\mu + \\mu(1-p)} \\frac{(\\mu p)^x}{x!} &amp; (e^{-\\mu + \\nu}, \\nu=\\mu(1-p)) \\\\ &amp;= e^{-\\mu p} \\frac{(\\mu p)^x}{x!}. \\end{align*}\\] This formula is valid for \\(x=0, 1, 2, \\ldots\\). We recognize this as the p.m.f. of a \\(\\text{Poisson}(\\mu p)\\) distribution. Essential Practice Let \\(X\\) be the number of times a certain numerical control machine will malfunction on a given day. Let \\(Y\\) be the number of times a technician is called on an emergency call. Their joint p.m.f. is given by \\[ \\begin{array}{rr|cccc} &amp; 5 &amp; 0 &amp; .20 &amp; .10 \\\\ y &amp; 3 &amp; .05 &amp; .10 &amp; .35 \\\\ &amp; 1 &amp; .05 &amp; .05 &amp; .10 \\\\ \\hline &amp; &amp; 1 &amp; 2 &amp; 3\\\\ &amp; &amp; &amp; x \\end{array}. \\] Calculate the marginal distribution of \\(X\\). Calculate the marginal distribution of \\(Y\\). Are \\(X\\) and \\(Y\\) independent? How do you know? Use the joint p.m.f. of the smaller and the larger of two dice rolls that you calculated in Lesson 18 to find the p.m.f. of the larger number. Use this p.m.f. to solve the “last banana” problem from Lesson 7. Suppose two random variables \\(X\\) and \\(Y\\) both have marginal \\(\\text{Binomial}(n=3, p=0.5)\\) distributions. In this exercise, you will see that there are many joint distributions that could have those marginal distributions. What is the joint p.m.f. if \\(X\\) and \\(Y\\) are independent? Can you find at least 2 more joint p.m.f.s with the same marginal distributions? (Hint: What happens if you define \\(X\\) and \\(Y\\) based on just 3 tosses of a coin? What about 4 tosses of a coin?) Additional Exercises Two tickets are drawn without replacement from a box with \\(N_1\\) \\(\\fbox{1}\\)s and \\(N_0\\) \\(\\fbox{0}\\)s. Let \\(X\\) be the number of \\(\\fbox{1}\\)s on the first draw and \\(Y\\) be the number of \\(\\fbox{1}\\)s on the second draw. It is clear that the first draw has a \\(\\frac{N_1}{N}\\) probability of being a \\(\\fbox{1}\\). But what about the second draw? In Lesson 18, you found the joint distribution of \\(X\\) and \\(Y\\). Use this joint p.m.f. to show that the probability that the second draw is a \\(\\fbox{1}\\) is \\(\\frac{N_1}{N}\\). "],
["conditional-discrete.html", "Lesson 20 Conditional Distributions Motivating Example Theory Essential Practice Additional Exercises", " Lesson 20 Conditional Distributions Motivating Example Continuing with the example from Lessons 18 and 19, suppose Xavier and Yolanda meet up later for coffee. Xavier has forgotten how many bets he won at roulette, but Yolanda clearly remembers that she won 3 bets. What information does this give Xavier about how many bets he won? First, if Yolanda won 3 bets, Xavier knows that he had to have won at least once, since Yolanda only made two more bets than he did. But he cannot be sure whether he won 1, 2, or 3 bets. All he can do is assign probabilities to these possible values based on the information he has been given. Theory Xavier wants to know the distribution of the random variable \\(X\\), given the information in another random variable \\(Y\\). This is called the conditional distribution of \\(X\\) given \\(Y\\). Definition 20.1 (Conditional Distribution) The conditional p.m.f. of \\(X\\) given \\(Y\\) is defined as \\[\\begin{equation} f_{X|Y}(x|y) \\overset{\\text{def}}{=} P(X = x | Y = y) = \\frac{f(x, y)}{f_Y(y)}. \\tag{20.1} \\end{equation}\\] Visually, we are taking a row of the joint p.m.f. table and dividing the values by the total of that row. The process is illustrated in Figure 20.1. Figure 20.1: Calculating the Conditional Distribution of \\(Y\\) Notice that the probabilities add up to \\(1.0\\). This makes sense, since we have exhausted all the possible values that \\(X\\) could be. Figure 20.2 provides another view of what is going on when we divide by the marginal p.m.f. of \\(Y\\). The probabilities in the joint p.m.f. \\(f(x, y)\\) are correct relative to each other; the marginal p.m.f. \\(f_{Y}(y)\\) is just a scaling factor to make the probabilities add up to \\(1.0\\). Figure 20.2: The joint distribution \\(f(x, 3)\\) in red vs. the conditional distribution \\(f_{X|Y}(x|3)\\) in black Let’s calculate another conditional distribution—this time using formulas, rather than tables. Example 20.1 (Conditional Distributions of a Poisson Process) In San Luis Obispo, radioactive particles hit a Geiger counter according to a Poisson process at a rate of \\(\\lambda = 0.8\\) particles per second. Suppose that 7 particles are detected in the first 5 seconds. What is the distribution of the number of particles that are detected in the first 3 seconds? Solution. If we let \\(X\\) be the number of particles in the first 3 seconds and \\(Y\\) be the number of particles in the first 5 seconds, then we are interested in the conditional distribution \\[ f_{X|Y}(x | 7). \\] From (20.1), we know that this is \\[ f_{X|Y}(x | 7) = \\frac{f(x, 7)}{f_Y(7)}. \\] The marginal probability \\(f_Y(7)\\) is easy to calculate. \\(Y\\) is the number of arrivals on a \\(5\\)-second interval, which we know follows a \\(\\text{Poisson}(\\mu=5 \\cdot 0.8)\\) distribution, by Property 1 of a Poisson Process (see Lesson 17). Therefore: \\[ f_Y(7) = e^{-5 \\cdot 0.8} \\frac{(5 \\cdot 0.8)^7}{7!}. \\] To calculate the joint probability \\(f(x, 7)\\), we first break the time interval \\((0, 5)\\) into two non-overlapping intervals, \\((0, 3)\\) and \\((3, 5)\\), as shown in Figure 20.3. We know from Property 2 of a Poisson Process (see Lesson 17) that the numbers of arrivals on non-overlapping intervals are independent. Let’s represent the number of arrivals on \\((3, 5)\\) by \\(Z \\overset{\\text{def}}{=} Y - X\\) so that \\(Z\\) is independent of \\(X\\). Figure 20.3: Breaking up a Poisson Process Now, we calculate the joint probability: \\[\\begin{align*} f(x, 7) &amp;= P(X=x \\text{ and } Y=7) \\\\ &amp;= P(X=x \\text{ and } Z=7-x) \\\\ &amp;= P(X=x) \\cdot P(Z=7-x) &amp; \\text{(since $X$ and $Z$ are independent)} \\\\ &amp;= e^{-(3 \\cdot 0.8)} \\frac{(3 \\cdot 0.8)^x}{x!} \\cdot e^{-(2 \\cdot 0.8)} \\frac{(2 \\cdot 0.8)^{7-x}}{(7-x)!} \\end{align*}\\] Putting everything together, we find that the conditional distribution is: \\[\\begin{align*} f_{X|Y}(x | 7) &amp;= \\frac{f(x, 7)}{f_Y(7)} \\\\ &amp;= \\frac{e^{-(3 \\cdot 0.8)} \\frac{(3 \\cdot 0.8)^x}{x!} \\cdot e^{-(2 \\cdot 0.8)} \\frac{(2 \\cdot 0.8)^{7-x}}{(7-x)!}}{e^{-5 \\cdot 0.8} \\frac{(5 \\cdot 0.8)^7}{7!}} \\\\ &amp;= \\frac{7!}{x! (7-x)!} \\frac{(3 \\cdot 0.8)^x \\cdot (2 \\cdot 0.8)^{7-x}}{(5 \\cdot 0.8)^7} \\\\ &amp;= \\frac{\\binom{7}{x} 3^x \\cdot 2^{7-x}}{5^7} \\end{align*}\\] This is just the p.m.f. of a \\(\\text{Binomial}(n=7, N_1=3, N_0=2)\\) distribution. The interpretation is this: given that there were 7 arrivals on the interval \\((0, 5)\\), each arrival has a \\(p=3/5\\) chance of falling in the first 3 seconds, independently of the other arrivals. Essential Practice Let \\(X\\) be the number of times a certain numerical control machine will malfunction on a given day. Let \\(Y\\) be the number of times a technician is called on an emergency call. Their joint p.m.f. is given by \\[ \\begin{array}{rr|cccc} &amp; 5 &amp; 0 &amp; .20 &amp; .10 \\\\ y &amp; 3 &amp; .05 &amp; .10 &amp; .35 \\\\ &amp; 1 &amp; .05 &amp; .05 &amp; .10 \\\\ \\hline &amp; &amp; 1 &amp; 2 &amp; 3\\\\ &amp; &amp; &amp; x \\end{array}. \\] Calculate the conditional distribution of \\(X\\) given \\(Y=3\\). Calculate the conditional distribution of \\(Y\\) given \\(X=2\\). Is \\(P(Y=3 | X=2)\\) the same as \\(P(X=2 | Y=3)\\)? Small aircraft arrive at San Luis Obispo airport according to a Poisson process at a rate of 6 per hour. What is the probability that (exactly) 5 small aircraft arrived in the first hour, given that (exactly) 12 aircraft arrived in the first two hours? First calculate an appropriate conditional distribution; then, use this conditional distribution to answer the question. A fair coin is tossed 10 times. Let \\(X\\) be the total number of heads in the 10 tosses. Let \\(Y\\) be the number of heads in the first 6 tosses. Find the conditional distribution of \\(Y\\), given \\(X = 7\\). This is a named distribution we have learned. Which is it? Specify all parameters of this distribution. (Hint: In order to identify the named distribution, it is easier to work with formulas rather than tables.) Additional Exercises Use the joint p.m.f. of the smaller and the larger of two dice rolls that you calculated in Lesson 18 to find the conditional distribution of the smaller number, given that the larger number was \\(4\\). "],
["sums-discrete.html", "Lesson 21 Sums of Random Variables Theory Essential Practice Additional Exercises", " Lesson 21 Sums of Random Variables Theory Let \\(X\\) and \\(Y\\) be random variables. What is the distribution of their sum—that is, the random variable \\(T = X + Y\\)? In principle, we already know how to calculate this. To determine the distribution of \\(T\\), we need to calculate \\[ f_T(t) \\overset{\\text{def}}{=} P(T = t) = P(X + Y = t), \\] which we can do by summing the joint p.m.f. over the appropriate values: \\[\\begin{equation} \\sum_{(x, y):\\ x + y = t} f(x, y). \\tag{21.1} \\end{equation}\\] For example, to calculate the total number of bets that Xavier and Yolanda win, we calculate \\(P(X + Y = t)\\) for \\(t = 0, 1, 2, \\ldots, 8\\). The probabilities that we would need to sum for \\(t=4\\) are highlighted in the joint p.m.f. table below: \\[ \\begin{array}{rr|cccc} &amp; 5 &amp; 0 &amp; 0 &amp; 0 &amp; .0238 \\\\ &amp; 4 &amp; \\fbox{0} &amp; 0 &amp; .0795 &amp; .0530 \\\\ y &amp; 3 &amp; 0 &amp; \\fbox{.0883} &amp; .1766 &amp; .0294 \\\\ &amp; 2 &amp; .0327 &amp; .1963 &amp; \\fbox{.0981} &amp; 0 \\\\ &amp; 1 &amp; .0726 &amp; .1090 &amp; 0 &amp; \\fbox{0} \\\\ &amp; 0 &amp; .0404 &amp; 0 &amp; 0 &amp; 0 \\\\ \\hline &amp; &amp; 0 &amp; 1 &amp; 2 &amp; 3\\\\ &amp; &amp; &amp; &amp; x \\end{array}. \\] For a fixed value of \\(t\\), \\(x\\) determines the value of \\(y\\) (and vice versa). In particular, \\(y = t - x\\). So we can write (21.1) as a sum over \\(x\\): \\[\\begin{equation} f_T(t) = \\sum_x f(x, t-x). \\tag{21.2} \\end{equation}\\] This is the general equation for the p.m.f. of the sum \\(T\\). If the random variables are independent, then we can actually say more. Theorem 21.1 (Sum of Independent Random Variables) Let \\(X\\) and \\(Y\\) be independent random variables. Then, the p.m.f. of \\(T = X + Y\\) is the convolution of the p.m.f.s of \\(X\\) and \\(Y\\): \\[\\begin{equation} f_T = f_X * f_Y. \\tag{21.3} \\end{equation}\\] The convolution operator \\(*\\) in (21.3) is defined as follows: \\[ f_T(t) = \\sum_x f_X(x) \\cdot f_Y(t-x). \\] Note that the verb form of “convolution” is convolve, not “convolute”, even though many students find convolution quite convoluted! Proof. This follows from (21.2), after observing that independence means that the joint distribution is the product of the marginal distributions (Theorem 19.1): \\[ f(x, t-x) = f_X(x) \\cdot f_Y(t-x). \\] Theorem 21.2 (Sum of Independent Binomials) Let \\(X\\) and \\(Y\\) be independent \\(\\text{Binomial}(n, p)\\) and \\(\\text{Binomial}(m, p)\\) random variables, respectively. Then \\(T = X + Y\\) follows a \\(\\text{Binomial}(n + m, p)\\) distribution. Proof. We apply Theorem 21.1 to binomial p.m.f.s. \\[\\begin{align*} f_T(t) &amp;= \\sum_{x=0}^t f_X(x) \\cdot f_Y(t-x) \\\\ &amp;= \\sum_{x=0}^t \\binom{n}{x} p^x (1-p)^{n-x} \\cdot \\binom{m}{t-x} p^{t-x} (1-p)^{m-(t-x)} \\\\ &amp;= \\sum_{x=0}^t \\binom{n}{x} \\binom{m}{t-x} p^t (1-p)^{n+m-t} \\\\ &amp;= \\binom{n+m}{t} p^t (1-p)^{n+m-t}, \\end{align*}\\] which is the p.m.f. of a \\(\\text{Binomial}(n + m, p)\\) random variable. In the last equality, we used the fact that \\[\\begin{equation} \\sum_{x=0}^t \\binom{n}{x} \\binom{m}{t-x} = \\binom{n+m}{t}. \\tag{21.4} \\end{equation}\\] This equation is known as Vandermonde’s identity. One way to see it is to observe \\[ \\sum_{x=0}^t \\frac{\\binom{n}{x} \\binom{m}{t-x}}{\\binom{n+m}{t}} = 1, \\] since we are summing the p.m.f. of a \\(\\text{Hypergeometric}(t, n, m)\\) random variable over all of its possible values \\(0, 1, 2, \\ldots, t\\). Now, if we multiply both sides of this equality by \\[ \\binom{n+m}{t}, \\] we obtain Vandermonde’s identity (21.4). However, we can see that the sum of two independent binomials must be binomial another way. \\(X\\) represents the number of \\(\\fbox{1}\\)s in \\(n\\) draws with replacement from a box. \\(Y\\) represents the number of \\(\\fbox{1}\\)s in \\(m\\) separate draws with replacement from the same box: The draws must be separate because we need \\(X\\) to be independent of \\(Y\\). We can use the same box because \\(p\\) (which corresponds to how many \\(\\fbox{1}\\)s and \\(\\fbox{0}\\)s there are in the box) is the same for \\(X\\) and \\(Y\\). Instead of drawing \\(m\\) times for \\(X\\) and \\(n\\) times for \\(Y\\), we could simply draw \\(m+n\\) times with replacement from this box. \\(X+Y\\) is then the number of \\(\\fbox{1}\\)s in these \\(m+n\\) draws and must also be binomial. Essential Practice Let \\(X\\) and \\(Y\\) be independent \\(\\text{Poisson}(\\mu)\\) and \\(\\text{Poisson}(\\nu)\\) random variables. Use convolution to find the distribution of \\(X + Y\\). (Hint: It is a named distribution.) Then, by making an analogy to a Poisson process, explain why this must be the distribution of \\(X + Y\\). (The binomial theorem will come in handy: \\(\\sum_{x=0}^n \\binom{n}{x} a^x b^{n-x} = (a + b)^n\\).) Let \\(X\\) and \\(Y\\) be independent \\(\\text{Geometric}(p)\\) random variables. Use convolution to find the distribution of \\(X + Y\\). (Hint: It is a named distribution. It may help to remember that \\(\\sum_{i=1}^m 1 = m = \\binom{m}{1}\\).) Then, by making an analogy to a box model, explain why this has to be the distribution of \\(X + Y\\). Give an example of two \\(\\text{Binomial}(n=3, p=0.5)\\) random variables \\(X\\) and \\(Y\\), where \\(T = X + Y\\) does not follow a \\(\\text{Binomial}(n=6, p=0.5)\\) distribution. Why does this not contradict Theorem 21.2? Additional Exercises Let \\(X\\) and \\(Y\\) be independent random variables with the p.m.f. \\(x\\) 1 2 3 4 5 6 \\(f(x)\\) \\(1/6\\) \\(1/6\\) \\(1/6\\) \\(1/6\\) \\(1/6\\) \\(1/6\\) Use convolution to find the p.m.f. of \\(T = X + Y\\). Why does the answer make sense? (Hint: \\(X\\) and \\(Y\\) represent the outcomes when you roll two fair dice.) "],
["expected-value.html", "Lesson 22 Expected Value Motivating Example Theory Essential Practice Additional Exercises", " Lesson 22 Expected Value Motivating Example A bet on a single number in roulette has a \\(1/38\\) chance of success. We would not play this game if we were only offered a 1-to-1 payout on this bet—that is, a chance to win $1 for each $1 we wager. What would the payout have to be to make this game fair? Theory So far in this class, we have described random variables by their p.m.f. or their c.d.f. These functions contain everything there is to know about the random variable. However, the p.m.f. or c.d.f. is too much information in most applications. If we want to summarize a random variable by a single number, the expected value is usually the right choice. Definition 22.1 (Expected Value) Let \\(X\\) be a random variable with p.m.f. \\(f(x)\\). Then, the expected value of \\(X\\), symbolized \\(E[X]\\) is defined as \\[\\begin{equation} E[X] \\overset{\\text{def}}{=} \\sum_x x \\cdot f(x). \\tag{22.1} \\end{equation}\\] The expected value is a weighted average of the possible values of a random variable, where the weights are the probabilities. How do we interpret the expected value? The next example explores this question. Example 22.1 (Betting on a Number in Roulette) In roulette, betting on a single number pays 35-to-1. That is, for each $1 you bet, you win $35 if the ball lands in that pocket. If we let \\(X\\) represent your net winnings (or losses) on this bet, its p.m.f. is \\[ \\begin{array}{r|cc} x &amp; -1 &amp; 35 \\\\ \\hline f(x) &amp; 37/38 &amp; 1/38 \\end{array}. \\] Now, let’s calculate the expected value of this random variable. \\[ E[X] = -1 \\cdot \\frac{37}{38} + 35 \\cdot \\frac{1}{38} = -0.053. \\] How do we interpret the expected value of -0.053? It is not even possible for our net winnings to be -$0.053 on this bet, since our net winnings can only be -$1 or $35. Instead, this -$0.053 represents a long-run average. If we were to repeatedly make the same bet at the roulette wheel, then we will win some and lose some. The amount that we win per bet will approach -$0.053 as we make more and more bets. This is illustrated in Figure 22.1. Figure 22.1: The first 50 bets were all losses, so the average winnings starts at -1. In the long run, it approaches the expected value of -.053, shown in red. The expected value can also be interpreted as the center of mass. If we imagine the p.m.f. as resting on a scale, then the expected value is the pivot point where the scale will perfectly balance. Figure 22.2: Expected Value as Center of Mass Theorem 22.1 (Expected Value as Center of Mass) The expected value of a random variable \\(X\\) with p.m.f. \\(f(x)\\) is the center of mass of the p.m.f. Proof. Each mass contributes torque around the pivot. Torque is mass times distance from the pivot. In order for the beam to balance at a pivot, the total torque around that pivot must be zero. We show that the total torque is zero when the pivot is chosen to be the expected value \\(E[X]\\). \\[\\begin{align*} \\text{torque} &amp;= \\sum \\text{mass} \\cdot (\\text{distance from pivot}) \\\\ &amp;= \\sum_x f(x) \\cdot (x - E[X]) \\\\ &amp;= \\underbrace{\\sum_x f(x) \\cdot x}_{E[X]} - \\underbrace{\\sum_x f(x)}_{1} \\cdot E[X] \\\\ &amp;= E[X] - E[X] \\\\ &amp;= 0. \\end{align*}\\] Now let’s answer the question posed at the beginning of the lesson. Although the casino’s payout of 35-to-1 is better than a 1-to-1 payout, it is still unfavorable to us. What would the payout need to be to make the game fair? In other words, we will let the p.m.f. be \\[ \\begin{array}{r|cc} x &amp; -1 &amp; c \\\\ \\hline f(x) &amp; 37/38 &amp; 1/38 \\end{array}, \\] where \\(c\\) is chosen to make the expected value 0: \\[\\begin{equation} 0 = E[X] = -1 \\cdot \\frac{37}{38} + c \\cdot \\frac{1}{38}. \\end{equation}\\] The value of \\(c\\) satisfying this equation is $37. So this is the fair payout of the game. Not surprisingly, the casino pays us less. We can also calculate expected value if we have a formula for the p.m.f. In the following example, we show how to derive a formula for the expected value. Example 22.2 (Expected Value of a Binomial Random Variable) The p.m.f. for a binomial random variable \\(X\\) is \\[ f(x) = \\binom{n}{x} \\frac{N_1^x N_0^{n-x}}{N^n}, x=0, 1, \\ldots, n. \\] Applying (22.1) to this p.m.f. and simplifying, we obtain a formula for the expected value of a binomial random variable. \\[\\begin{align*} E[X] &amp;= \\sum_{x=0}^n x \\cdot \\binom{n}{x} \\frac{N_1^x N_0^{n-x}}{N^n} \\\\ &amp;= \\sum_{x=1}^n x \\cdot \\binom{n}{x} \\frac{N_1^x N_0^{n-x}}{N^n}, \\end{align*}\\] where the only change from line 1 to line 2 was to start the sum at \\(x=1\\) instead of \\(x=0\\). (We can do this because the summand is 0 when \\(x=0\\).) Next, we replace \\(x \\cdot \\binom{n}{x}\\) using the identity (3.2): \\[\\begin{align*} &amp;= \\sum_{x=1}^n n \\binom{n-1}{x-1} \\frac{N_1^x N_0^{n-x}}{N^n} \\\\ &amp;= n\\sum_{x=1}^n \\binom{n-1}{x-1} \\frac{N_1^x N_0^{n-x}}{N^n} &amp; (\\text{pull $n$ outside the sum}) \\\\ &amp;= n \\sum_{x&#39;=0}^{n-1} \\binom{n-1}{x&#39;} \\frac{N_1^{x&#39; + 1} N_0^{n - 1 - x&#39;}}{N^n} &amp; (\\text{apply substitution $x&#39; = x - 1$}) \\\\ &amp;= n \\frac{N_1}{N} \\sum_{x&#39;=0}^{n-1} \\underbrace{\\binom{n-1}{x&#39;} \\frac{N_1^{x&#39;} N_0^{n - 1 - x&#39;}}{N^{n-1}}}_{\\text{p.m.f. of $\\text{Binomial}(n-1, N_1, N_0)$}} &amp; (\\text{pull factors of $N_1$ and $N$ outside the sum}) \\\\ &amp;= n \\frac{N_1}{N} &amp; (\\text{sum of p.m.f. over all possible values is 1}) \\end{align*}\\] Now, if we know that a random variable \\(X\\) has a binomial distribution, we can use the formula \\[ E[X] = n\\frac{N_1}{N} \\] instead of calculating it from scratch using (22.1) and the p.m.f. We can derive formulas for the expected values of all of the named distributions in a similar way. The formulas are provided in Appendix A.1. If your random variable follows one of these named distributions, then you can just look up its expected value in Appendix A.1. This is another benefit of learning these named distributions! Essential Practice Show that the expected value of a \\(\\text{Poisson}(\\mu)\\) random variable is \\(\\mu\\). (In other words, I am asking you to derive the result in the table above. You should be able to follow Example 22.2 closely, except using a \\(\\text{Poisson}(\\mu)\\) p.m.f.) Let’s calculate the expected winnings of some other roulette bets: A bet on reds pays 1-to-1. Calculate your expected net winnings from this bet. A “corner” bet is a bet that one of four numbers will come up. It pays 8-to-1. Calculate your expected net winnings from this bet. What do you notice about the expected winnings from the different bets? One minigame in The Legend of Zelda: A Link to the Past invites you to open one of three treasure chests and keep whatever prize is inside. (See the screenshot below.) The treasure chests contain 1, 20, and 300 rupees, but the prizes are shuffled so you do not which chest contains which prize. The game costs 100 rupees to play. Is this a game you want to play? In the carnival game chuck-a-luck, three dice are rolled. You make a bet on a particular number (1, 2, 3, 4, 5, 6) showing up. The payout is 1 to 1 if that number shows on (exactly) one die, 2 to 1 if it shows on two dice, and 3 to 1 if it shows up on all three. (You lose your initial stake if your number does not show on any of the dice.) If you make a $1 bet on the number three, what is your expected net winnings? Packets arrive at a certain node on the university’s intranet at 10 packets per minute, on average. Assume packet arrivals meet the assumptions of a Poisson process. How many arrivals would you expect to see over a period of 5 minutes? Additional Exercises In craps, one of the most popular side bets is the “field”. In a field bet, you are betting on a 2, 3, 4, 9, 10, 11, or 12 on the very next roll. The payout is 1 to 1, except if you roll “snake eyes” (double 1s) or “boxcars” (double 6s), in which case the payout is 2 to 1. Calculate your expected (net) winnings if you make a $1 bet on the field. (As you might expect, this is a negative number.) What would the payout for “snake eyes” and “boxcars” have to be to make this a fair game (i.e., so that your expected net winnings is zero)? Show that the expected value of a \\(\\text{Hypergeometric}(n, N_1, N_0)\\) random variable is \\(n \\frac{N_1}{N}\\), which is the same as the expected value of a binomial random variable. (In other words, the expected value is the same, whether you draw with or without replacement.) Show that the expected value of a \\(\\text{NegativeBinomial}(r, p)\\) random variable is \\(\\frac{r}{p}\\). Why does this also imply that the expected value of a \\(\\text{Geometric}(p)\\) random variable is \\(1/p\\)? "],
["ev-infinity.html", "Lesson 23 Expected Value and Infinity 23.1 Pascal’s Wager 23.2 St. Petersburg Paradox", " Lesson 23 Expected Value and Infinity 23.1 Pascal’s Wager The mathematician Blaise Pascal (1623-1662) made an argument for why it was rational to believe in God—at least the Judeo-Christian God. Pascal acknowledged that God may or may not exist and assigned the probability \\(p &gt; 0\\) to God’s existence. Then, he considered the following bets: If you believe in God, and He exists, then your reward is infinite (i.e., eternal salvation). If He does not exist, then your reward is some number \\(a\\), which may be negative but finite. If you do not believe in God, and He exists, the your reward is negative infinity (i.e., eternal damnation). If He does not exist, then your reward is some number \\(b\\), which is finite. Looking at the first bet (belief in God), Pascal calculated the expected reward \\(E[R]\\) as follows. The p.m.f. of \\(R\\) is \\[ \\begin{array}{r|cc} r &amp; a &amp; \\infty \\\\ \\hline f(r) &amp; 1-p &amp; p, \\end{array} \\] and the expected value of this bet is \\[ E[R] = a\\cdot (1-p) + \\infty \\cdot p = \\infty. \\] Can you do the same for the second bet? Pascal argued that we should pick the bet with the higher expected value, which is to believe in God. I present this only as an illustration of how expected value can be applied in surprising contexts, not to convince you to believe or not to believe. There have been many philosophical objections to Pascal’s wager. If you are interested, this video discusses some of the debates around Pascal’s wager. You can find many more discussions on Youtube. 23.2 St. Petersburg Paradox In the Pascal’s Wager example, we dealt with random variables which could take on values such as \\(\\infty\\) or \\(-\\infty\\). It is not surprising that the expected value is infinite when infinity is a possible value. However, the expected value can be infinite, even if the random variable is finite-valued. Let’s look at an example. You are offered the following game at a carnival. The game starts with $1 in a jar. You toss a coin repeatedly. Each time the coin lands heads, the amount of money in the jar is doubled. As soon as the coin lands tails, you cash out whatever money is in the jar, and the game ends. For example, if you toss the sequence HHHT, then you win $8 because: After the first H, the amount in the jar is doubled to $2. After the second H, the amount in the jar is doubled to $4. After the third H, the amount in the jar is doubled to $8. After the T, the game ends, and you win the $8 in the jar. How much would you be willing to pay to play this game? We have seen that the expected value represents the “fair value” of a game. First, let’s work out the p.m.f. of the amount of money you win, \\(W\\). Fill in the first few probabilities of this p.m.f. table. \\[ \\begin{array}{rcccccc} w &amp; 1 &amp; 2 &amp; 4 &amp; ? &amp; ? &amp; \\ldots \\\\ \\hline f(w) &amp; 1/2 &amp; 1/4 &amp; ? &amp; ? &amp; ? &amp; \\ldots \\\\ \\end{array}\\] Now calculate \\(E[W]\\) from the p.m.f. What does this suggest about how much you should be willing to pay? This is a famous puzzle in probability called the St. Petersburg Paradox. Here is a video discussing the St. Petersburg paradox. "],
["lotus.html", "Lesson 24 LOTUS Motivating Example Theory Essential Practice Additional Exercises", " Lesson 24 LOTUS Motivating Example In Lesson 23, we analyzed the St. Petersburg Paradox. There, we calculated the expected amount we win, \\(E[W]\\), by first deriving the p.m.f. of \\(W\\). However, we know that the amount we win, \\(W\\), is related to the number of tosses, \\(N\\), by \\[ W = 2^{N-1}. \\] Furthermore, we know that \\(N\\) follows a \\(\\text{Geometric}(p=1/2)\\) distribution. Can we calculate the expected amount we win, \\(E[W] = E[2^{N-1}]\\), from the p.m.f. of \\(N\\), without deriving the p.m.f. of \\(W\\)? Theory In this lesson, we will learn how to calculate expected values of functions of random variables. That is, we will calculate expected values of the form \\(E[g(X)]\\). There are two ways to do this: Calculate the p.m.f. of \\(Y = g(X)\\), then calculate \\(E[Y]\\) from the usual formula (22.1). Use the Law of the Unconscious Statistician (LOTUS), described below. Theorem 24.1 (LOTUS) Let \\(X\\) be a random variable with p.m.f. \\(f_X(x)\\). Define \\(Y = g(X)\\) for some function \\(g\\). Then, \\(E[Y] = E[g(X)]\\) is \\[\\begin{equation} E[g(X)] = \\sum_x g(x) \\cdot f_X(x). \\tag{24.1} \\end{equation}\\] Theorem 24.1 allows us to calculate the expected value of \\(Y = g(X)\\), without first finding its distribution. Instead, we can just use the known distribution of \\(X\\). This result is called the “Law of the Unconscious Statistician” because many people intuitively assume it is true. Remember that \\(E[g(X)]\\) represents the “average” value of \\(g(X)\\). To calculate the average value of \\(g(X)\\), it makes sense to take a weighted average of the possible values \\(g(x)\\), where the weights are the probabilities \\(f_X(x)\\). Let’s start with a simple example where \\(E[g(X)]\\) is easy to calculate, to understand why LOTUS works. Example 24.1 (Random Circle) We toss a fair coin twice. Let \\(X\\) be the number of heads. Then, the p.m.f. of \\(X\\) is \\[ \\begin{array}{r|ccc} x &amp; 0 &amp; 1 &amp; 2 \\\\ \\hline f_X(x) &amp; .25 &amp; .50 &amp; .25 \\end{array} \\] Now, suppose we sketch a circle whose radius is \\(X\\) (in feet), the random number we just generated by tossing the coin. Then, the area of this circle is a random variable \\(A = \\pi X^2\\) (in square feet). What is the expected area \\(E[A] = E[\\pi X^2]\\)? Clearly, the only possible values of \\(\\pi X^2\\) are \\[\\begin{align*} \\pi \\cdot 0^2 &amp;= 0, &amp; \\pi \\cdot 1^2 &amp;= \\pi, &amp; \\text{ and } \\pi \\cdot 2^2 &amp;= 4\\pi, \\end{align*}\\] and their probabilities are just the probabilities of \\(0\\), \\(1\\), and \\(2\\), respectively. That is, the p.m.f. of \\(A\\) is \\[ \\begin{array}{r|ccc} a &amp; \\pi \\cdot 0^2 &amp; \\pi \\cdot 1^2 &amp; \\pi\\cdot 2^2 \\\\ \\hline f_A(a) &amp; .25 &amp; .50 &amp; .25 \\end{array} \\] Therefore, the expected area must be \\[\\begin{align} E[\\pi X^2] &amp;= (\\pi \\cdot 0^2) \\cdot .25 + (\\pi \\cdot 1^2) \\cdot .50 + (\\pi \\cdot 2^2) \\cdot .25 \\\\ &amp;= 1.5 \\pi. \\tag{24.2} \\end{align}\\] Notice that we weighted the values of \\(g(x) = \\pi x^2\\) by the p.m.f. of \\(X\\) to calculate \\(E[g(X)]\\). This is exactly what LOTUS (Theorem 24.1) said we should do! Notice that we get a different answer if we first evaluate the expected radius and the calculate the area of a circle with that radius: \\[ \\pi E[X]^2 = \\pi \\cdot 1^2 = \\pi. \\] An average circle is not the same as a circle with an average radius! In general, \\(E[g(X)] \\neq g(E[X])\\). In the first case, you have to use LOTUS. In the second case, you first calculate the expected value, then apply the function \\(g\\) to the result. Now let’s look at the question posed at the beginning of the lesson. Example 24.2 (St. Petersburg Paradox Revisited) We know that the p.m.f. of \\(N\\), a \\(\\text{Geometric}(p=0.5)\\) random variable, is \\[ f_N(n) = (1-0.5)^{n-1} 0.5 = 0.5^n. \\] By LOTUS, \\[\\begin{align*} E[2^{N-1}] &amp;= \\sum_{n=1}^\\infty 2^{n-1} \\cdot (0.5)^n \\\\ &amp;= \\sum_{n=1}^\\infty (0.5) \\\\ &amp;= 0.5 + 0.5 + 0.5 + \\ldots \\\\ &amp;= \\infty, \\end{align*}\\] which matches answer we got in Lesson 23. Here is a more complex application of LOTUS. This particular expected value may seem unmotivated, but it will come in handy later when we talk about variance. Example 24.3 Let \\(X\\) be a \\(\\text{Binomial}(n, N_1, N_0)\\) random variable. In Example 22.2, we showed that \\(E[X] = n \\frac{N_1}{N}\\). Now, we calculate \\(E[X(X-1)]\\) by applying LOTUS (24.1) to the binomial p.m.f. \\[ f(x) = \\binom{n}{x} \\frac{N_1^x N_0^{n-x}}{N^n}, x=0, 1, \\ldots, n. \\] \\[\\begin{align*} E[X(X-1)] &amp;= \\sum_{x=0}^n x (x-1) \\cdot \\binom{n}{x} \\frac{N_1^x N_0^{n-x}}{N^n} \\\\ &amp;= \\sum_{x=2}^n x(x-1) \\cdot \\binom{n}{x} \\frac{N_1^x N_0^{n-x}}{N^n}, \\end{align*}\\] where the only change from line 1 to line 2 was to start the sum at \\(x=2\\) instead of \\(x=0\\). (We can do this because the summand is 0 when \\(x=0\\) and \\(x=1\\). Try plugging in \\(x=0\\) and \\(x=1\\) if you do not see this.) Next, we replace \\(x(x-1) \\cdot \\binom{n}{x}\\) using the combinatorial identity \\[ x(x-1) \\binom{n}{x} = n (n-1) \\binom{n-2}{x-2}. \\] Here is a story proof ot this identity: imagining selecting a committee of \\(x\\) people from \\(n\\), where one person is the chair and another person is the vice-chair. We can either: select the committee first (\\(\\binom{n}{x}\\)) and then select the chair and vice-chair (\\(x(x-1)\\)), or select the chair and vice-chair first (\\(n(n-1)\\)) and then select the rest of the committee (\\(\\binom{n-2}{x-2}\\)). Since these are two equivalent methods of selecting a committee with a chair and a vice-chair, the two expressions must be equal. \\[\\begin{align*} &amp;= \\sum_{x=2}^n n (n-1) \\binom{n-2}{x-2} \\frac{N_1^x N_0^{n-x}}{N^n} \\\\ &amp;= n(n-1)\\sum_{x=2}^n \\binom{n-2}{x-2} \\frac{N_1^x N_0^{n-x}}{N^n} &amp; (\\text{pull $n(n-1)$ outside the sum}) \\\\ &amp;= n(n-1) \\sum_{x&#39;=0}^{n-2} \\binom{n-2}{x&#39;} \\frac{N_1^{x&#39; + 2} N_0^{n - 2 - x&#39;}}{N^n} &amp; (\\text{apply substitution $x&#39; = x - 2$}) \\\\ &amp;= n(n-1) \\frac{N_1^2}{N^2} \\sum_{x&#39;=0}^{n-2} \\underbrace{\\binom{n-2}{x&#39;} \\frac{N_1^{x&#39;} N_0^{n - 2 - x&#39;}}{N^{n-2}}}_{\\text{p.m.f. of $\\text{Binomial}(n-2, N_1, N_0)$}} &amp; (\\text{pull factors of $N_1$ and $N$ outside the sum}) \\\\ &amp;= n(n-1) \\frac{N_1^2}{N^2} &amp; (\\text{sum of p.m.f. over all possible values is 1}) \\end{align*}\\] Essential Practice Suppose we generate a random length \\(L\\) (in inches) from the p.m.f. \\(\\ell\\) 1 2 3 \\(f(\\ell)\\) .2 .5 .3 and draw a square with that sidelength. Calculate \\(E[L]^2\\) and \\(E[L^2]\\). Are they the same? Which one represents the expected area of the square we drew? Let \\(X\\) be a \\(\\text{Poisson}(\\mu)\\) random variable. Calculate \\(E[X(X-1)]\\). Let \\(X\\) be a \\(\\text{Geometric}(p)\\) random variable. Let \\(t\\) be a constant. Calculate \\(M(t) = E[e^{tX}]\\) as a function of \\(t\\). Statisticians call this the moment generating function of \\(X\\), while engineers may recognize this function as the Laplace transform of the p.m.f. of \\(X\\). Additional Exercises Another resolution to the St. Petersburg Paradox is to consider expected utility \\(U\\) rather than expected wealth \\(W\\). (“Utility” is the term that economists use for “happiness”.) Because of diminishing marginal utility, the first million dollars is worth more than the next million dollars. One way to model diminishing marginal utility is to assume that \\(U = \\log(W)\\). Show that the expected utility of the St. Petersburg game is finite, even though the expected winnings is infinite. Let \\(X\\) be a \\(\\text{Hypergeometric}(n, N_1, N_0)\\) random variable. Calculate \\(E[X(X-1)]\\). Let \\(X\\) be a \\(\\text{Poisson}(\\mu)\\) random variable for \\(0 &lt; \\mu &lt; 1\\). Calculate \\(E[X!]\\). Let \\(X\\) be a \\(\\text{NegativeBinomial}(r, p)\\) random variable. Calculate \\(E[(X+1)X]\\). "],
["lotus2d.html", "Lesson 25 2D LOTUS Theory Essential Practice", " Lesson 25 2D LOTUS Theory In this lesson, we calculate the expected value of a function of two random variables, \\(E[g(X, Y)]\\). For example, \\(E[X + Y]\\) and \\(E[XY]\\) are all examples of expected values that involve more than one random variable. Theorem 25.1 (2D LOTUS) Let \\(X\\) and \\(Y\\) be random variables with joint p.m.f. \\(f(x, y)\\). Let \\(g\\) be some function. Then, \\[\\begin{equation} E[g(X, Y)] = \\sum_x \\sum_y g(x, y) \\cdot f(x, y). \\tag{25.1} \\end{equation}\\] Again, the result is intuitive. Now that there are two random variables, the probabilities are given by the joint p.m.f. We use these probabilities to weight the possible values of \\(g(X, Y)\\). Let’s apply Theorem 25.1 to the Xavier and Yolanda example from Lesson 18. Example 25.1 (Xavier and Yolanda Revisited) In Lesson 18, we showed that the joint distribution of the number of times Xavier and Yolanda win is \\[ \\begin{array}{rr|cccc} &amp; 5 &amp; 0 &amp; 0 &amp; 0 &amp; .0238 \\\\ &amp; 4 &amp; 0 &amp; 0 &amp; .0795 &amp; .0530 \\\\ y &amp; 3 &amp; 0 &amp; .0883 &amp; .1766 &amp; .0294 \\\\ &amp; 2 &amp; .0327 &amp; .1963 &amp; .0981 &amp; 0 \\\\ &amp; 1 &amp; .0727 &amp; .1090 &amp; 0 &amp; 0 \\\\ &amp; 0 &amp; .0404 &amp; 0 &amp; 0 &amp; 0 \\\\ \\hline &amp; &amp; 0 &amp; 1 &amp; 2 &amp; 3\\\\ &amp; &amp; &amp; &amp; x \\end{array}. \\] Let’s calculate \\(E[Y - X]\\), the expected number of additional times that Yolanda wins, compared to Xavier, as well as \\(E[XY]\\), the expected product of the number of times they win. Applying 2D LOTUS to the function \\(g(x, y) = y-x\\), we can calculate \\(E[g(X, Y)] = E[Y - X]\\). In the sum below, we will omit outcomes with probability 0. \\[\\begin{align*} E[Y - X] &amp;= \\sum_x \\sum_y (y - x) f(x, y) \\\\ &amp;\\approx (0 - 0) .0404 + (1 - 0) .0727 + (1 - 1) .1090 \\\\ &amp;\\ \\ \\ + (2 - 0) .0327 + (2 - 1) .1963 + (2 - 2) .0981 \\\\ &amp;\\ \\ \\ + (3 - 1) .0883 + (3 - 2) .1766 + (3 - 3) .0294 \\\\ &amp;\\ \\ \\ + (4 - 2) .0795 + (4 - 3) .0530 + (5 - 3) .0238 \\\\ &amp;= .947. \\end{align*}\\] Of course, there is an easier to calculate this particular expected value. \\(Y - X\\) is just the number of wins in the last two bets, which follows a \\(\\text{Binomial}(n=2, p=18/38)\\) distribution. From Appendix A.1, we know that the expected value of a binomial is \\(np = 2 (18/38) \\approx .947\\), which matches the answer above. We can calculate \\(E[XY]\\) in the same way, by applying 2D LOTUS to the function \\(g(x, y) = xy\\). \\[\\begin{align*} E[XY] &amp;= \\sum_x \\sum_y xy f(x, y) \\\\ &amp;= (0 \\cdot 0) .0404 + (1 \\cdot 0) .0727 + (1 \\cdot 1) .1090 \\\\ &amp;\\ \\ \\ + (2 \\cdot 0) .0327 + (2 \\cdot 1) .1963 + (2 \\cdot 2) .0981 \\\\ &amp;\\ \\ \\ + (3 \\cdot 1) .0883 + (3 \\cdot 2) .1766 + (3 \\cdot 3) .0294 \\\\ &amp;\\ \\ \\ + (4 \\cdot 2) .0795 + (4 \\cdot 3) .0530 + (5 \\cdot 3) .0238 \\\\ &amp;= 4.11. \\end{align*}\\] Essential Practice Two tickets are drawn from a box with \\(N_1\\) \\(\\fbox{1}\\)s and \\(N_0\\) \\(\\fbox{0}\\)s. Let \\(X\\) be the number of \\(\\fbox{1}\\)s on the first draw and \\(Y\\) be the number of \\(\\fbox{1}\\)s on the second draw. (Note that \\(X\\) and \\(Y\\) can only be 0 or 1.) Calculate \\(E[XY]\\) when the draws are made with replacement. Calculate \\(E[XY]\\) when the draws are made without replacement. (Hint: You worked out the joint p.m.f. of \\(X\\) and \\(Y\\) in Lesson 18. Use it!) You roll two fair, six-sided dice. Let \\(X\\) be the number on the first die. Let \\(Y\\) be the number on the second die. Calculate \\(E[\\max(X, Y)]\\), the expected value of the larger of the two numbers. There are several ways you can do this. You should try to do this by applying 2D LOTUS to the joint distribution of \\(X\\) and \\(Y\\), which is extremely simple. To check your answer, you can use the p.m.f. of \\(L = \\max(X, Y)\\) that you derived in Lesson 19. Consider the following three scenarios: A fair coin is tossed 3 times. \\(X\\) is the number of heads and \\(Y\\) is the number of tails. A fair coin is tossed 4 times. \\(X\\) is the number of heads in the first 3 tosses, \\(Y\\) is the number of heads in the last 3 tosses. A fair coin is tossed 6 times. \\(X\\) is the number of heads in the first 3 tosses, \\(Y\\) is the number of heads in the last 3 tosses. In all three scenarios, \\(X\\) and \\(Y\\) are both marginally \\(\\text{Binomial}(n=3, p=1/2)\\). However, they have different joint distributions. In Lessons 18 and 19, you worked out the joint p.m.f.s. Calculate \\(E[X + Y]\\) and \\(E[XY]\\) for each of the scenarios. Does \\(E[X + Y]\\) change, depending on the joint distribution? What about \\(E[XY]\\)? "],
["linearity.html", "Lesson 26 Linearity of Expectation Theory Essential Practice Additional Practice", " Lesson 26 Linearity of Expectation Theory In this lesson, we learn a shortcut for calculating expected values of the form \\[ E[aX + bY]. \\] In general, evaluating expected values of functions of random variables requires LOTUS. But when the function is linear, we can break up the expected value into more manageable parts. Theorem 26.1 (Adding or Multiplying a Constant) Let \\(X\\) be a random variable and \\(a, b\\) be constants. Then, \\[\\begin{align} E[aX] &amp;= aE[X] \\tag{26.1} \\\\ E[X + b] &amp;= E[X] + b \\tag{26.2} \\end{align}\\] Proof. Since \\(aX\\) and \\(X+b\\) are technically functions of \\(X\\), we use LOTUS (24.1). \\[\\begin{align*} E[aX] &amp;= \\sum_x ax f(x) &amp; \\text{(LOTUS)} \\\\ &amp;= a \\sum_x x f(x) &amp; \\text{(factor constant outside the sum)} \\\\ &amp;= a E[X] &amp; \\text{(definition of expected value)}. \\\\ E[X+b] &amp;= \\sum_x (x + b) f(x) &amp; \\text{(LOTUS)} \\\\ &amp;= \\sum_x x f(x) + \\sum_x b f(x) &amp; \\text{(break $(x + b) f(x)$ into $xf(x) + bf(x)$)} \\\\ &amp;= \\sum_x x f(x) + b\\sum_x f(x) &amp; \\text{(factor constant outside the sum)} \\\\ &amp;= E[X] + b &amp; \\text{(definitions of expected value, p.m.f.)}. \\end{align*}\\] Here is an example illustrating how Theorem 26.1 can be used. Example 26.1 (Expected Values in Roulette) In roulette, betting on a single number pays 35-to-1. That is, for each $1 you bet, you win $35 if the ball lands in that pocket. If we let \\(X\\) represent your net winnings (or losses) on this bet, its p.m.f. is \\[ \\begin{array}{r|cc} x &amp; -1 &amp; 35 \\\\ \\hline f_X(x) &amp; 37/38 &amp; 1/38 \\end{array}. \\] In Lesson 22, we calculated \\(E[X]\\) directly. Here is another way we can calculate it using Theorem 26.1. Let us define a new random variable \\(W\\), which takes on the values 0 and 1 with the same probabilities: \\[ \\begin{array}{r|cc} w &amp; 0 &amp; 1 \\\\ \\hline f_W(w) &amp; 37/38 &amp; 1/38 \\end{array}. \\] We can think of \\(W\\) as an indicator variable for whether or not we win. It is easy to see that \\(E[W] = 1/38\\). (One way is to just use the formula. Another is to note that \\(W\\) is a \\(\\text{Binomial}(n=1, p=1/38)\\) random variable, so \\(E[W] = np = 1/38\\).) Now, the amount we win, \\(X\\), is related to this indicator variable, \\(W\\), by: \\[ X = 36 W - 1. \\] (Verify that \\(X\\) takes on the values \\(35\\) and \\(-1\\) with the correct probabilities.) Now, by Theorem 26.1, the expected value is \\[ E[X] = E[36W - 1] = 36 E[W] - 1 = 36 \\left( \\frac{1}{38} \\right) - 1 = -\\frac{2}{38}, \\] which matches what we got in Lesson 22. The next result is even more useful. Theorem 26.2 (Linearity of Expectation) Let \\(X\\) and \\(Y\\) be random variables. Then, no matter what their joint distribution is, \\[\\begin{equation} E[X+Y] = E[X] + E[Y]. \\tag{26.3} \\end{equation}\\] Proof. Since \\(E[X + Y]\\) involves two random variables, we have to evaluate the expectation using 2D LOTUS (25.1), with \\(g(x, y) = x + y\\). Suppose that the joint distribution of \\(X\\) and \\(Y\\) is \\(f(x, y)\\). Then: \\[\\begin{align*} E[X + Y] &amp;= \\sum_x \\sum_y (x + y) f(x, y) &amp; \\text{(2D LOTUS)} \\\\ &amp;= \\sum_x \\sum_y x f(x, y) + \\sum_x \\sum_y y f(x, y) &amp; \\text{(break $(x + y) f(x, y)$ into $x f(x, y) + y f(x, y)$)} \\\\ &amp;= \\sum_x x \\sum_y f(x, y) + \\sum_y y \\sum_x f(x, y) &amp; \\text{(move term outside the inner sum)} \\\\ &amp;= \\sum_x x f_X(x) + \\sum_y y f_Y(y) &amp; \\text{(definition of marginal distribution)} \\\\ &amp;= E[X] + E[Y] &amp; \\text{(definition of expected value)}. \\end{align*}\\] In other words, linearity of expectation says that you only need to know the marginal distributions of \\(X\\) and \\(Y\\) to calculate \\(E[X + Y]\\). Their joint distribution is irrelevant. Let’s apply this to the Xavier and Yolanda problem from Lesson 18. Example 26.2 (Xavier and Yolanda Revisited) Xavier and Yolanda head to the roulette table at a casino. They both place bets on red on 3 spins of the roulette wheel before Xavier has to leave. After Xavier leaves, Yolanda places bets on red on 2 more spins of the wheel. Let \\(X\\) be the number of bets that Xavier wins and \\(Y\\) be the number that Yolanda wins. In Lesson 25, we calculated \\(E[Y - X]\\), the expected number of additional times that Yolanda wins, by applying 2D LOTUS to the joint p.m.f. of \\(X\\) and \\(Y\\). The calculation was tedious. In this lesson, we see how linearity of expectation allows us to avoid tedious calculations. First, by (26.1) and (26.3), we see that: \\[ E[Y - X] = E[Y] + E[-1 \\cdot X] = E[Y] + (-1) E[X] = E[Y] - E[X]. \\] We know that \\(Y\\) is \\(\\text{Binomial}(n=5, N_1=18, N_0=20)\\) and \\(X\\) is \\(\\text{Binomial}(n=3, N_1=18, N_0=20)\\). \\(X\\) and \\(Y\\) are definitely not independent, since three of Yolanda’s bets are identical to Xavier’s. But linearity of expectation says that to calculate \\(E[Y - X]\\), it does not matter how \\(X\\) and \\(Y\\) are related to each other; we only need their marginal distributions. From Appendix A.1 (and Lesson 22), we know the expected value of a binomial random variable is \\(n\\frac{N_1}{N}\\), so \\[ E[Y - X] = E[Y] - E[X] = 5\\frac{18}{38} - 3\\frac{18}{38} = 2\\frac{18}{38} \\approx .947, \\] which matches the answer we got in Lesson 25 by applying 2D LOTUS. Linearity allows us to calculate the expected values of complicated random variables by breaking them into simpler random variables. Example 26.3 (Expected Value of the Binomial and Hypergeometric Distributions) In Lesson 22, we showed that the expected values of the binomial and hypergeometric distributions are the same: \\(n\\frac{N_1}{N}\\). But the proofs we gave were tedious and did not give any insight into why this formula is true. Let’s prove this formula using linearity of expectation. If \\(X\\) is a \\(\\text{Binomial}(n, N_1, N_0)\\) random variable, then we can break \\(X\\) down into the sum of simpler random variables: \\[ X = Y_1 + Y_2 + \\ldots + Y_n, \\] where \\(Y_i\\) represents the outcome of the \\(i\\)th draw from the box. So \\(Y_i\\) equals \\(1\\) with probability \\(N_1/N\\) and is \\(0\\) otherwise. Its p.m.f. is about as simple as it gets: \\[\\begin{equation} \\begin{array}{rcc} y &amp; 0 &amp; 1 \\\\ \\hline f(y) &amp; N_0/N &amp; N_1/N \\end{array}. \\label{eq:bernoulli_pmf} \\end{equation}\\] By linearity of expectation: \\[ E[X] = E[Y_1] + E[Y_2] + \\ldots + E[Y_n]. \\] We have taken a complicated random variable \\(X\\) and broken it down into simpler random variables \\(Y_i\\), whose expected value is trivial to calculate: \\[ E[Y_i] = 0 \\cdot \\frac{N_0}{N} + 1 \\cdot \\frac{N_1}{N} = \\frac{N_1}{N}. \\] Therefore, \\[ E[X] = \\underbrace{\\frac{N_1}{N} + \\frac{N_1}{N} + \\ldots + \\frac{N_1}{N}}_{\\text{$n$ terms}} = n \\frac{N_1}{N}. \\] What if \\(X\\) is a \\(\\text{Hypergeometric}(n, N_1, N_0)\\) random variable? We can break \\(X\\) down in exactly the same way, as sum of the outcomes of each draw: \\[ X = Y_1 + Y_2 + \\ldots + Y_n, \\] except that now the \\(Y_i\\)s are not independent. However, each \\(Y_i\\) still represents a random draw from a box with \\(N_1\\) \\(\\fbox{1}\\)s and \\(N_0\\) \\(\\fbox{0}\\)s, so \\(Y_i\\) equals 1 with probability \\(N_1/N\\), just as before. Also, linearity of expectation does not care whether or not the random variables are independent. So the expected value of the hypergeometric is also: \\[ E[X] = \\underbrace{\\frac{N_1}{N} + \\frac{N_1}{N} + \\ldots + \\frac{N_1}{N}}_{\\text{$n$ terms}} = n \\frac{N_1}{N}. \\] Here is a clever application of linearity. Example 26.4 Let \\(X\\) be a \\(\\text{Binomial}(n, N_1, N_0)\\) random variable. What is \\(E[X(X-1)]\\)? In Example 24.3, we calculated this expected value using LOTUS. Here is a way to calculate it using linearity. Remember that \\(X\\) represents the number of \\(\\fbox{1}\\)s in our sample. The random variable \\(X(X-1)\\) then represents the number of (ordered) ways to choose two tickets from the \\(\\fbox{1}\\)s in our sample. In the diagram below, \\(n=4\\) and \\(X=3\\). Each arrow represents one of the \\(n(n-1) = 12\\) ways to choose two tickets from the \\(n\\) tickets in the sample. The red arrows represent the \\(X(X-1) = 6\\) ways of choosing two tickets among the \\(\\fbox{1}\\)s. Let’s define an indicator variable \\(Y_{ij}, i\\neq j\\) for each of the \\(n(n-1)\\) ways of choosing two tickets from our sample. Let \\(Y_{ij}\\) be 1 if tickets \\(i\\) and \\(j\\) are both \\(\\fbox{1}\\)s. In other words, \\(Y_{ij} = 1\\) if and only if there is a red arrow connecting the two tickets in the diagram above. Since \\(X(X-1)\\) is the number of red arrows, we have \\[ X(X-1) = \\sum_{i=1}^n \\sum_{j\\neq i} Y_{ij}. \\] Now, by linearity: \\[ E[X(X-1)] = \\sum_{i=1}^n \\sum_{j\\neq i} E[Y_{ij}]. \\] But \\(E[Y_{ij}]\\) is simply the probability that tickets \\(i\\) and \\(j\\) are both \\(\\fbox{1}\\)s. This probability is \\(E[Y_{ij}] = \\frac{N_1^2}{N^2}\\). Since there are \\(n(n-1)\\) \\(Y_{ij}\\)s, \\[ E[X(X-1)] = n(n-1) \\frac{N_1^2}{N^2}, \\] which matches the answer we got in Lesson 24 by more tedious means. Essential Practice Each year, as part of a “Secret Santa” tradition, a group of 4 friends write their names on slips of papers and place the slips into a hat. Each member of the group draws a name at random from the hat and must by a gift for that person. Of course, it is possible that they draw their own name, in which case they buy a gift for themselves. What is the expected number of people who draw their own name? Hint: Express this complicated random variable as a sum of indicator random variables (i.e., that only take on the values 0 or 1), and use linearity of expectation. McDonald’s decides to give a Pokemon toy with every Happy Meal. Each time you buy a Happy Meal, you are equally likely to get any one of the 6 types of Pokemon. What is the expected number of Happy Meals that you have to buy until you “catch ’em all”? Hint: Express this complicated random variable as a sum of geometric random variables, and use linearity of expectation. A group of 60 people are comparing their birthdays (as usual, assume that their birthdays are independent, all 365 days are equally likely, etc.). Find the expected number of days in the year on which at least two of these people were born. Hint: Express this complicated random variable as a sum of indicator random variables, and use linearity of expectation. Additional Practice A hash table is a commonly used data structure in computer science, allowing for fast information retrieval. For example, suppose we want to store some people’s phone numbers. Assume that no two of the people have the same name. For each name \\(x\\), a hash function \\(h\\) is used, where \\(h(x)\\) is the location to store x’s phone number. After such a table has been computed, to look up \\(x\\)’s phone number one just recomputes \\(h(x)\\) and then looks up what is stored in that location. Typically, \\(h\\) is chosen to be (pseudo)random. Suppose there are 100 people, with each person’s phone number stored in a random location (independently), represented by an integer between 1 and 1000. It then might happen that one location has more than one phone number stored there, if two different people \\(x\\) and \\(y\\) end up with the same random location for their information to be stored. Find the expected number of locations with no phone numbers stored, the expected number with exactly one phone number, and the expected number with more than one phone number. Calculate \\(E[X(X-1)]\\) for a \\(\\text{Hypergeometric}(n, N_1, N_0)\\) random variable \\(X\\) using linearity. (Hint: Follow Example 26.4.) "],
["ev-product.html", "Lesson 27 Expected Value of a Product Theory Essential Practice", " Lesson 27 Expected Value of a Product Theory Theorem 27.1 (Expected Value of a Product) If \\(X\\) and \\(Y\\) are independent random variables, then \\[\\begin{equation} E[XY] = E[X] E[Y]. \\tag{27.1} \\end{equation}\\] In fact, if \\(X\\) and \\(Y\\) are independent, then for any functions \\(g\\) and \\(h\\), \\[\\begin{equation} E[g(X)h(Y)] = E[g(X)] E[h(Y)]. \\tag{27.2} \\end{equation}\\] Example 27.1 (Xavier and Yolanda Revisited) In Lesson 25, we calculated \\(E[XY]\\), the expected product of the numbers of times that Xavier and Yolanda win. There, we used 2D LOTUS. Now, let’s repeat the calculation using Theorem 27.1. You might be tempted to multiply \\(E[X]\\) and \\(E[Y]\\). However, this is wrong because \\(X\\) and \\(Y\\) are not independent. Every time Xavier wins, Yolanda also wins. So we cannot apply Theorem 27.1 directly. We can express the number of times Yolanda wins as: \\[ Y = X + Z, \\] where \\(Z\\) is the number of wins in the last two spins of the roulette wheel. Now, \\(X\\) and \\(Z\\) are independent. Furthermore, we know that \\(X\\) is \\(\\text{Binomial}(n=3, N_1=18, N_0=20)\\), and \\(Z\\) is \\(\\text{Binomial}(n=2, N_1=18, N_0=20)\\). Therefore, \\[\\begin{align*} E[XY] &amp;= E[X(X + Z)] &amp; \\text{(by the representation above)} \\\\ &amp;= E[X^2 + XZ] &amp; \\text{(expand expression inside expected value)} \\\\ &amp;= E[X^2] + E[XZ] &amp; \\text{(linearity of expectation)} \\\\ &amp;= E[X^2] + E[X]E[Z] &amp; \\text{(by independence of $X$ and $Z$ and \\ref{eq:ev-product})} \\end{align*}\\] Now, \\(X\\) and \\(Z\\) are binomial, so there is a simple formula for their expected value: \\[\\begin{align*} E[X] &amp;= n\\frac{N_1}{N} = 3\\frac{18}{38} \\\\ E[Z] &amp;= n\\frac{N_1}{N} = 2\\frac{18}{38}. \\end{align*}\\] The only non-trivial part is calculating \\(E[X^2]\\). However, we showed in Examples 24.3 and 26.4 that for a binomial random variable \\(X\\), \\[ E[X(X-1)] = n(n-1) \\frac{N_1^2}{N^2}. \\] Since \\(E[X(X-1)] = E[X^2 - X] = E[X^2] - E[X]\\), we can solve for \\(E[X^2]\\): \\[\\begin{align*} E[X^2] &amp;= E[X(X-1)] + E[X] \\\\ &amp;= n(n-1) \\frac{N_1^2}{N^2} + n\\frac{N_1}{N} \\end{align*}\\] For the number of bets that Xavier wins, \\[ E[X^2] = 3(2)\\frac{18^2}{38^2} + 3\\frac{18}{38}. \\] Putting it all together, we get \\[ E[XY] = 3(2)\\frac{18^2}{38^2} + 3\\frac{18}{38} + \\left( 3\\frac{18}{38} \\right) \\left( 2\\frac{18}{38} \\right) \\approx 4.11, \\] which matches the answer from Lesson 25. Essential Practice Consider the following three scenarios: A fair coin is tossed 3 times. \\(X\\) is the number of heads and \\(Y\\) is the number of tails. A fair coin is tossed 4 times. \\(X\\) is the number of heads in the first 3 tosses, \\(Y\\) is the number of heads in the last 3 tosses. A fair coin is tossed 6 times. \\(X\\) is the number of heads in the first 3 tosses, \\(Y\\) is the number of heads in the last 3 tosses. In Lesson 25, you showed that \\(E[X + Y]\\) was the same for all three scenarios, but \\(E[XY]\\) was different. In light of Theorems 26.2 and 27.1, explain why this makes sense. Two fair dice are rolled. Let \\(X\\) be the outcome of the first die. Let \\(Y\\) be the outcome of the second die. Calculate the expected ratio between the numbers on the two dice, \\(\\displaystyle E[X / Y]\\). (You can use Theorem 27.1, since \\(X\\) and \\(Y\\) are independent. However, be careful because \\(E[X / Y] \\neq E[X] / E[Y]\\).) What is \\(E[Y / X]\\)? Why does this seem paradoxical? At Diablo Canyon nuclear plant, radioactive particles hit a Geiger counter according to a Poisson process with a rate of 3.5 particles per second. Let \\(X\\) be the number of particles detected in the first 2 seconds. Let \\(Y\\) be the number of particles detected in the second after that (i.e., the 3rd second). Find \\(E[XY]\\). "],
["variance.html", "Lesson 28 Variance Motivating Example Theory Essential Practice Additional Practice", " Lesson 28 Variance Motivating Example In Lesson 22, you showed that in roulette, every bet has exactly the same expected payoff. That is, their p.m.f.s have the same center of mass. Does that mean that all bets are alike? No! A bet on a single number is riskier because you have a small chance (\\(1/38\\)) of making a lot of money ($35). A bet on reds, on the other hand, is smaller risk and smaller reward. How do we quantify how “risky” a bet is? Theory The expected value summarizes the center of a random variable. However, we have seen that two random variables can have the same center but very different distributions. We also need to know how “spread out” the distribution is. The variance measures the “spread” of a distribution around its center. Definition 28.1 (Variance) Let \\(X\\) be a random variable. Then, the variance of \\(X\\), symbolized \\(\\text{Var}[X]\\) is defined as \\[\\begin{equation} \\text{Var}[X] \\overset{\\text{def}}{=} E[(X - E[X])^2]. \\tag{28.1} \\end{equation}\\] In general, the variance (28.1) has to be computed using LOTUS. Example 28.1 (Roulette Variances) The payout from a bet on a single number, \\(X\\), has p.m.f. \\[ \\begin{array}{r|cc} x &amp; -1 &amp; 35 \\\\ \\hline f(x) &amp; 37/38 &amp; 1/38 \\end{array}. \\] We have already seen that \\(E[X] = -\\frac{2}{38}\\). Its variance is: \\[\\begin{align*} \\text{Var}[X] &amp;= E[(X - -\\frac{2}{38})^2] &amp; \\text{(plug in known value of $E[X]$)} \\\\ &amp;= (35 - -\\frac{2}{38})^2 \\cdot \\frac{1}{38} + (-1 - -\\frac{2}{38})^2 \\cdot \\frac{37}{38} &amp; \\text{(LOTUS)}\\\\ &amp;= 33.21 \\end{align*}\\] The payout from a bet on a single number, \\(Y\\), has p.m.f. \\[ \\begin{array}{r|cc} y &amp; -1 &amp; 1 \\\\ \\hline f(y) &amp; 20/38 &amp; 18/38 \\end{array}. \\] We have already seen that \\(E[Y] = -\\frac{2}{38}\\). Its variance is: \\[\\begin{align*} \\text{Var}[Y] &amp;= E[(Y - -\\frac{2}{38})^2] &amp; \\text{(plug in known value of $E[Y]$)} \\\\ &amp;= (1 - -\\frac{2}{38})^2 \\cdot \\frac{18}{38} + (-1 - -\\frac{2}{38})^2 \\cdot \\frac{20}{38} &amp; \\text{(LOTUS)}\\\\ &amp;= 0.997. \\end{align*}\\] We see that the variances of these bets are very different, even though their expected values are the same. You might be surprised that the variance of a bet on a single number is so large. This is because variance is in squared units. That is, the variance of a bet on a single number is 33.21 dollars squared. Because squared units are often uninterpretable (what exactly is a “squared dollar”?), it is customary to report the square root of the variance, a number called the standard deviation. Definition 28.2 (Standard Deviation) The standard deviation of a random variable \\(X\\) is defined as \\[ \\text{SD}[X] = \\sqrt{\\text{Var}[X]}. \\] It is in the same units as the original random variable. It measures, on average, how far the random variable is from its center. Example 28.2 (Roulette SDs) We showed above that the variance of a \\[ \\text{Var}[X] = 33.21. \\] The standard deviation is \\[ \\text{SD}[X] = \\sqrt{\\text{Var}[X]} = \\sqrt{33.21} = \\$5.76. \\] This standard deviation is in units of dollars, just like the random variable \\(X\\). For calculations, it is often easier to use the following “shortcut formula” for the variance. Theorem 28.1 (Shortcut Formula for Variance) The variance can also be computed as: \\[\\begin{equation} \\text{Var}[X] = E[X^2] - E[X]^2. \\tag{28.2} \\end{equation}\\] Proof. \\[\\begin{align*} \\text{Var}[X] &amp;= E[(X - E[X])^2] &amp; \\text{(definition of variance)} \\\\ &amp;= E[X^2 - 2X E[X] + E[X]^2] &amp; \\text{(expand expression inside expectation)}\\\\ &amp;= E[X^2] - 2 E[X] E[X] + E[X]^2 &amp; \\text{(linearity of expectation)} \\\\ &amp;= E[X^2] - E[X]^2 &amp; \\text{(simplify)} \\end{align*}\\] Here is an example where we use the shortcut formula. Example 28.3 (Variance of a Binomial Random Variable) The p.m.f. for a binomial random variable \\(X\\) is \\[ f(x) = \\binom{n}{x} \\frac{N_1^x N_0^{n-x}}{N^n}, x=0, 1, \\ldots, n. \\] To calculate \\(\\text{Var}[X]\\), we use the shortcut formula (28.2). We already know \\(E[X] = n\\frac{N_1}{N}\\), so we just need to calculate \\(E[X^2]\\). We showed that in Examples 24.3 and 26.4 that \\[ E[X(X-1)] = n(n-1) \\frac{N_1^2}{N_0^2}. \\] Since \\(E[X(X-1)] = E[X^2 - X] = E[X^2] - E[X]\\), we can solve for \\(E[X^2]\\): \\[\\begin{align*} E[X^2] &amp;= E[X(X-1)] + E[X] \\\\ &amp;= n(n-1) \\frac{N_1^2}{N_0^2} + n\\frac{N_1}{N} \\end{align*}\\] Now, we apply the shortcut formula (28.2): \\[\\begin{align*} \\text{Var}[X] &amp;= E[X^2] - E[X]^2 \\\\ &amp;= n(n-1) \\frac{N_1^2}{N_0^2} + n\\frac{N_1}{N} - \\left( n\\frac{N_1}{N} \\right)^2 \\\\ &amp;= n \\frac{N_1}{N} \\left( (n-1) \\frac{N_1}{N} + 1 - n \\frac{N_1}{N} \\right) \\\\ &amp;= n \\frac{N_1}{N} \\underbrace{\\left( 1 - \\frac{N_1}{N} \\right)}_{\\frac{N_0}{N}}. \\end{align*}\\] Later in this book, we will see an easier way to derive this same result. Now, if we know that a random variable \\(X\\) has a binomial distribution, we can use the formula \\[ \\text{Var}[X] = n\\frac{N_1}{N} \\frac{N_0}{N} \\] instead of calculating it from scratch. We can derive formulas for the variances of all of the named distributions in a similar way. The formulas are provided in Appendix A.1. If your random variable follows one of these named distributions, then you can just look up its variance in Appendix A.1. This is another benefit of learning these named distributions! Essential Practice Show that the variance of a \\(\\text{Poisson}(\\mu)\\) random variable is \\(\\mu\\). (In other words, I am asking you to derive the result in the table above.) (Hint: In Lesson 24, you derived \\(E[X(X-1)]\\) for a Poisson random variable. Use that result, and follow Example 28.3 above.) Describe a random variable \\(X\\) with \\(\\text{Var}[X] = 0\\). In the carnival game chuck-a-luck, three dice are rolled. You make a bet on a particular number (1, 2, 3, 4, 5, 6) showing up. The payout is 1 to 1 if that number shows on (exactly) one die, 2 to 1 if it shows on two dice, and 3 to 1 if it shows up on all three. (You lose your initial stake if your number does not show on any of the dice.) If you make a $1 bet on the number three, what is the standard deviation of your net winnings? (Hint: You already calculated the expected value in Lesson 22. Use that, in conjunction with the shortcut formula (28.2).) Packets arrive at a certain node on the university’s intranet at 10 packets per minute, on average. Assume packet arrivals meet the assumptions of a Poisson process. What is the standard deviation of the number of arrivals you expect to see over a 5-minute period? Additional Practice Show that the variance of a \\(\\text{Hypergeometric}(n, N_1, N_0)\\) random variable is \\(n \\frac{N_1}{N} \\frac{N_0}{N} \\frac{N-n}{N-1}\\). (Hint: You calculated \\(E[X(X-1)]\\) for a hypergeometric random variable in Lesson 24.) Show that the variance of a \\(\\text{NegativeBinomial}(r, p)\\) random variable is \\(\\frac{r(1-p)}{p^2}\\). (Hint: You calculated \\(E[(X+1)X]\\) for a negative binomial random variable in Lesson 24.) "],
["covariance.html", "Lesson 29 Covariance Theory Essential Practice Additional Practice", " Lesson 29 Covariance Theory The covariance measures the relationship between two random variables. Definition 29.1 (Covariance) Let \\(X\\) and \\(Y\\) be random variables. Then, the covariance of \\(X\\) and \\(Y\\), symbolized \\(\\text{Cov}[X, Y]\\) is defined as \\[\\begin{equation} \\text{Cov}[X, Y] \\overset{\\text{def}}{=} E[(X - E[X])(Y - E[Y])]. \\tag{29.1} \\end{equation}\\] The sign of the covariance is most meaningful: If \\(\\text{Cov}[X, Y] &gt; 0\\), then \\(X\\) and \\(Y\\) tend to move together. When \\(X\\) is high, \\(Y\\) tends to also be high. If \\(\\text{Cov}[X, Y] &lt; 0\\), then \\(X\\) and \\(Y\\) tend to move in opposite directions. When \\(X\\) is high, \\(Y\\) tends to be low. If \\(\\text{Cov}[X, Y] = 0\\), then \\(X\\) and \\(Y\\) do not consistently move together. This does not mean that they are independent, just that they do not consistently move together. By comparing the definitions of variance (28.1) and covariance (29.1), we have the following obvious, but important, relationship between variance and covariance. Theorem 29.1 (Covariance-Variance Relationship) Let \\(X\\) be a random variable. Then: \\[\\begin{equation} \\text{Var}[X] = \\text{Cov}[X, X]. \\end{equation}\\] For calculations, it is often easier to use the following “shortcut formula” for the covariance. Theorem 29.2 (Shortcut Formula for Covariance) The covariance can also be computed as: \\[\\begin{equation} \\text{Cov}[X, Y] = E[XY] - E[X]E[Y]. \\tag{29.2} \\end{equation}\\] Proof. \\[\\begin{align*} \\text{Cov}[X, Y] &amp;= E[(X - E[X])(Y - E[Y])] &amp; \\text{(definition of covariance)} \\\\ &amp;= E[XY - X E[Y] - E[X] Y + E[X]E[Y]] &amp; \\text{(expand expression inside expectation)}\\\\ &amp;= E[XY] -E[X] E[Y] - E[X] E[Y] + E[X]E[Y] &amp; \\text{(linearity of expectation)} \\\\ &amp;= E[XY] - E[X]E[Y] &amp; \\text{(simplify)} \\end{align*}\\] Here is an example where we use the shortcut formula. Example 29.1 (Roulette Covariance) Let’s calculate the covariance between the number of bets that Xavier wins, \\(X\\), and the number of bets that Yolanda wins, \\(Y\\). We calculated \\(E[XY] \\approx 4.11\\) in Lessons 25 and 27. But if we did not already know this, we would have to calculate it (usually by 2D LOTUS). Since \\(X\\) and \\(Y\\) are binomial, we also know their expected values are \\(E[X] = 3\\frac{18}{38}\\) and \\(E[Y] = 5\\frac{18}{38}\\). Therefore, the covariance is \\[ \\text{Cov}[X, Y] = E[XY] - E[X]E[Y] = 4.11 - 3\\frac{18}{38} \\cdot 5\\frac{18}{38} = .744. \\] This covariance is positive, which makes sense—since the more Xavier wins, the more Yolanda wins. Finally, we note that if \\(X\\) and \\(Y\\) are independent, then their covariance is zero. Theorem 29.3 (Independence Implies Zero Covariance) If \\(X\\) and \\(Y\\) are independent, then \\(\\text{Cov}[X, Y] = 0\\). Proof. We use the shortcut formula (29.2) and Theorem 27.1. \\[\\begin{align*} \\text{Cov}[X, Y] &amp;= E[XY] - E[X]E[Y] \\\\ &amp;= E[X]E[Y] - E[X]E[Y] \\\\ &amp;= 0 \\end{align*}\\] However, the converse is not true. It is possible for the covariance to be 0, even when the random variables are not independent. An example of such a distibution can be found in the Essential Practice below. Essential Practice Suppose \\(X\\) and \\(Y\\) are random variables with joint p.m.f. \\[ \\begin{array}{rr|ccc} y &amp; 1 &amp; .3 &amp; 0 &amp; .3 \\\\ &amp; 0 &amp; 0 &amp; .4 &amp; 0 \\\\ \\hline &amp; &amp; 0 &amp; 1 &amp; 2 \\\\ &amp; &amp; &amp; x \\\\ \\end{array}. \\] Are \\(X\\) and \\(Y\\) independent? What is \\(\\text{Cov}[X, Y]\\)? Two tickets are drawn from a box with \\(N_1\\) \\(\\fbox{1}\\)s and \\(N_0\\) \\(\\fbox{0}\\)s. Let \\(X\\) be the number of \\(\\fbox{1}\\)s on the first draw and \\(Y\\) be the number of \\(\\fbox{1}\\)s on the second draw. (Note that \\(X\\) and \\(Y\\) can only be 0 or 1.) Calculate \\(\\text{Cov}[X, Y]\\) when the draws are made with replacement. Calculate \\(\\text{Cov}[X, Y]\\) when the draws are made without replacement. (Hint: You worked out \\(E[XY]\\) in Lesson 25. Use it!) At Diablo Canyon nuclear plant, radioactive particles hit a Geiger counter according to a Poisson process with a rate of 3.5 particles per second. Let \\(X\\) be the number of particles detected in the first 2 seconds. Let \\(Y\\) be the number of particles detected in the second after that (i.e., the 3rd second). Calculate \\(\\text{Cov}[X, Y]\\). Additional Practice Consider the following three scenarios: A fair coin is tossed 3 times. \\(X\\) is the number of heads and \\(Y\\) is the number of tails. A fair coin is tossed 4 times. \\(X\\) is the number of heads in the first 3 tosses, \\(Y\\) is the number of heads in the last 3 tosses. A fair coin is tossed 6 times. \\(X\\) is the number of heads in the first 3 tosses, \\(Y\\) is the number of heads in the last 3 tosses. Calculate \\(\\text{Cov}[X, Y]\\) for each of these three scenarios. Interpret the sign of the covariance. "],
["cov-properties.html", "Lesson 30 Properties of Covariance Optional Video Theory Essential Practice Additional Practice", " Lesson 30 Properties of Covariance Optional Video This is an old video of mine. I’m including it in case it is helpful, but you do not need to watch it. Theory Calculating variance and covariance, even from the shortcut formulas (28.2) and (29.2), is tedious. Just as linearity simplified the calculation of expected values, the properties we learn in this lesson will simplify the calculation of variances and covariances. Theorem 30.1 (Properties of Covariance) Let \\(X, Y, Z\\) be random variables, and let \\(c\\) be a constant. Then: Covariance-Variance Relationship: \\(\\displaystyle\\text{Var}[X] = \\text{Cov}[X, X]\\) (This was also Theorem 29.1.) Pulling Out Constants: \\(\\displaystyle\\text{Cov}[cX, Y] = c \\cdot \\text{Cov}[X, Y]\\) \\(\\displaystyle\\text{Cov}[X, cY] = c \\cdot \\text{Cov}[X, Y]\\) Distributive Property: \\(\\displaystyle\\text{Cov}[X + Y, Z] = \\text{Cov}[X, Z] + \\text{Cov}[Y, Z]\\) \\(\\displaystyle\\text{Cov}[X, Y + Z] = \\text{Cov}[X, Y] + \\text{Cov}[X, Z]\\) Symmetry: \\(\\displaystyle\\text{Cov}[X, Y] = \\text{Cov}[Y, X]\\) Constants cannot covary: \\(\\displaystyle\\text{Cov}[X, c] = 0\\). These properties follow immediately from the definition of covariance (29.1), so we omit their proofs. Example 30.1 How does the variance change, when we multiply the random variable by a constant \\(a\\)? We answer this question using properties of covariance: \\[\\begin{align*} \\text{Var}[aX] &amp;= \\text{Cov}[aX, aX] &amp; \\text{(Covariance-Variance Relationship)} \\\\ &amp;= a \\cdot a \\cdot \\text{Cov}[X, X] &amp; \\text{(Pulling Out Constants)} \\\\ &amp;= a^2 \\text{Var}[X] &amp; \\text{(Covariance-Variance Relationship)} \\end{align*}\\] It makes sense that the variance should scale by \\(a^2\\), since the variance is in squared units. By combining the properties, we can derive new properties. Example 30.2 Let \\(X, Y, Z, W\\) be random variables. Then, by applying the distributive property twice: \\[\\begin{align*} \\text{Cov}[X + Y, Z + W] &amp;= \\text{Cov}[X, Z+W] + \\text{Cov}[Y, Z+W] \\\\ &amp;= \\text{Cov}[X, Z] + \\text{Cov}[X, W] + \\text{Cov}[Y, Z] + \\text{Cov}[Y, W] \\end{align*}\\] The result should remind you of FOILing from your high school algebra class, i.e., \\[ (x + y)(z + w) = xz + xw + yz + yw. \\] That is because multiplication also has a “distributive property”, just like covariance. Here is a cute application of the properties of covariance that emphasizes the point that two variables can have zero covariance without being independent. Example 30.3 (Covariance between the Sum and the Difference) Two fair six-sided dice are rolled. Let \\(X\\) be the number on the first die. Let \\(Y\\) be the number on the second die. If \\(S = X + Y\\) is their sum and \\(D = X - Y\\) is their difference, what is \\(\\text{Cov}[S, D]\\)? \\[\\begin{align*} \\text{Cov}[S, D] &amp;= \\text{Cov}[X + Y, X - Y] \\\\ &amp;= \\text{Cov}[X, X] + \\text{Cov}[X, -Y] + \\text{Cov}[Y, X] + \\text{Cov}[Y, -Y] \\\\ &amp;= \\text{Var}[X]\\ \\ \\ \\ \\ - \\text{Cov}[X, Y]\\ \\ \\ \\ + \\text{Cov}[X, Y] - \\text{Var}[Y] \\\\ &amp;= \\text{Var}[X] - \\text{Var}[Y] \\\\ &amp;= 0. \\end{align*}\\] In the second-to-last line, we used the fact that \\(X\\) and \\(Y\\) both represent the outcome when a fair, six-sided die is rolled. So they must have the same distribution and the same variance. You could calculate \\(\\text{Var}[X]\\) and \\(\\text{Var}[Y]\\) if you’d like (they turn out to be about 2.917), but it is not necessary in this example because we know they will cancel. Even though their covariance is zero, \\(S\\) and \\(D\\) are not independent! Think about it: if we are given that the sum was \\(S = 12\\), we must have rolled two ⚅s. In other words, we know \\(D = 0\\). Since one random variable gives us information about the other, they are not independent. Here is yet another illustration of the power of these properties, to derive the formula for the variance of the binomial distribution. Compare the simplicity of this derivation with Example 28.3. Example 30.4 (Variance of the Binomial Distribution) In Example 26.3, we argued that a \\(\\text{Binomial}(n, N_1, N_0)\\) random variable \\(X\\) could be broken down as the sum of simpler random variables: \\[ X = Y_1 + Y_2 + \\ldots + Y_n, \\] where \\(Y_i\\) represents the outcome of the \\(i\\)th draw from the box. Since the draws are made with replacement, the \\(Y_i\\)s are independent. The distribution of each \\(Y_i\\) is \\[ \\begin{array}{r|cc} y &amp; 0 &amp; 1 \\\\ \\hline f(y) &amp; \\frac{N_0}{N} &amp; \\frac{N_1}{N} \\end{array}. \\] It is not hard to calculate that \\(E[Y_i] = \\frac{N_1}{N}\\) and \\[\\begin{align*} \\text{Var}[Y_i] &amp;= E[Y_i^2] - E[Y_i]^2 \\\\ &amp;= \\left(0^2 \\cdot \\frac{N_0}{N} + 1^2 \\cdot \\frac{N_1}{N}\\right) - \\left(\\frac{N_1}{N} \\right)^2 \\\\ &amp;= \\frac{N_1}{N} \\frac{N_0}{N}. \\end{align*}\\] Now, we will use properties of covariance to express \\(\\text{Var}[X]\\) in terms of \\(\\text{Var}[Y_i]\\), which we calculated above: \\[\\begin{align*} \\text{Var}[X] &amp;= \\text{Cov}[X, X] \\\\ &amp;= \\text{Cov}[Y_1 + Y_2 + \\ldots + Y_n, Y_1 + Y_2 + \\ldots Y_n] \\\\ &amp;= \\text{Cov}[Y_1, Y_1] + \\text{Cov}[Y_1, Y_2] + \\ldots + \\text{Cov}[Y_n, Y_n] \\end{align*}\\] Because the \\(Y_i\\)s are independent, all covariances of the form \\(\\text{Cov}[Y_i, Y_j]\\) for \\(i \\neq j\\) are zero. That leaves just terms of the form \\(\\text{Cov}[Y_i, Y_i]\\), which is equivalent to \\(\\text{Var}[Y_i]\\) by Property 1: \\[\\begin{align*} &amp;= \\text{Cov}[Y_1, Y_1] + \\text{Cov}[Y_2, Y_2] + \\ldots + \\text{Cov}[Y_n, Y_n] \\\\ &amp;= \\text{Var}[Y_1] + \\text{Var}[Y_2] + \\ldots + \\text{Var}[Y_n] \\\\ &amp;= \\frac{N_1}{N} \\frac{N_0}{N} + \\frac{N_1}{N} \\frac{N_0}{N} + \\ldots + \\frac{N_1}{N} \\frac{N_0}{N} \\\\ &amp;= n \\frac{N_1}{N} \\frac{N_0}{N}. \\end{align*}\\] This derivation gives insight into why the variance of a binomial distribution is \\(n \\frac{N_1}{N} \\frac{N_0}{N}\\). The variance of each draw is \\(\\frac{N_1}{N} \\frac{N_0}{N}\\), and the variance goes up by \\(n\\) for the \\(n\\) independent draws. It is instructive to compare this derivation with the one for the hypergeometric distribution. Example 30.5 (Variance of the Hypergeometric Distribution) In Example 26.3, we saw that a \\(\\text{Hypergeometric}(n, N_1, N_0)\\) random variable \\(X\\) can be broken down in exactly the same way as a binomial random variable: \\[ X = Y_1 + Y_2 + \\ldots + Y_n, \\] where \\(Y_i\\) represents the outcome of the \\(i\\)th draw from the box. However, since the draws are made without replacement, the \\(Y_i\\)s are no longer independent. (Knowing that one draw was a \\(\\fbox{1}\\) makes it less likely for another draw to be a \\(\\fbox{1}\\).) Each \\(Y_i\\) still has expected value \\(E[Y_i] = \\frac{N_1}{N}\\) and variance \\(\\text{Var}[Y_i] = \\frac{N_1}{N} \\frac{N_0}{N}\\). But now we also need to consider the covariance between two different draws, since the draws are not independent. You calculated the covariance between two draws without replacement in Lesson 29. It is \\(\\text{Cov}[Y_i, Y_j] = -\\frac{1}{N-1} \\frac{N_1}{N} \\frac{N_0}{N}\\). Now, we will use properties of covariance to express \\(\\text{Var}[X]\\) in terms of \\(\\text{Var}[Y_i]\\) and \\(\\text{Cov}[Y_i, Y_j]\\), which we calculated above: \\[\\begin{align*} \\text{Var}[X] &amp;= \\text{Cov}[X, X] \\\\ &amp;= \\text{Cov}[Y_1 + Y_2 + \\ldots + Y_n, Y_1 + Y_2 + \\ldots Y_n] \\\\ &amp;= \\text{Cov}[Y_1, Y_1] + \\text{Cov}[Y_1, Y_2] + \\ldots + \\text{Cov}[Y_n, Y_n] \\end{align*}\\] We have \\(n\\) terms of the form \\(\\text{Cov}[Y_i, Y_i] = \\text{Var}[Y_i]\\) and \\(n(n-1)\\) terms of the form \\(\\text{Cov}[Y_i, Y_j]\\) for \\(i\\neq j\\). \\[\\begin{align*} &amp;= n\\text{Var}[Y_i] + n(n-1)\\text{Cov}[Y_i, Y_j] \\\\ &amp;= n \\frac{N_1}{N} \\frac{N_0}{N} - n(n-1) \\frac{1}{N-1} \\frac{N_1}{N} \\frac{N_0}{N} \\\\ &amp;= n \\frac{N_1}{N} \\frac{N_0}{N} \\left(1 - \\frac{n-1}{N-1}\\right) \\end{align*}\\] Notice that the variance of the hypergeometric is same as the variance of the corresponding binomial, except for the factor \\(\\left(1 - \\frac{n-1}{N-1}\\right)\\). This factor is less than 1, so the variance of the hypergeometric is always less than that of the corresponding binomial. This makes sense because the draws are made without replacement in the hypergeometric distribution. Each time we draw a \\(\\fbox{1}\\), we are less likely to draw a \\(\\fbox{1}\\) again (and more likely to draw a \\(\\fbox{0}\\)). As a result, the number of \\(\\fbox{1}\\)s is more likely to be somewhere near the middle in the hypergeometric distribution, so the variance will be smaller. The figure below compares the p.m.f.s of the two distributions. The factor \\(\\left(1 - \\frac{n-1}{N-1}\\right)\\) is called the finite population correction. If our box had infinitely many tickets, then drawing without replacement is essentially the same as drawing with replacement. Thus, in the limit as \\(N \\to \\infty\\), the hypergeometric distribution is the binomial distribution, and the finite population correction disappears. The finite population correction is only necessary because our boxes only contain a finite number of tickets. Essential Practice Let \\(W_1\\) be your net winnings on a single spin of a roulette wheel when you bet $1 on a single number. This bet pays 35 to 1, meaning that for each dollar you bet, you win $35 if the ball lands on that number and lose $1 otherwise. We calculated the p.m.f., expected value, and variance of \\(W_1\\) in Examples 22.1 and 28.1. Let \\(W_1, W_2, ..., W_{10}\\) be independent random variables with the same distribution as \\(W_1\\). Consider the random variables \\(X = 10 W_1\\) and \\(Y = W_1 + W_2 + ... + W_{10}\\). Which one represents… …your net winnings if you bet $1 on that number on each of 10 spins of the roulette wheel? …your net winnings if you bet $10 on that number on a single spin of the roulette wheel? Now, calculate \\(E[X]\\), \\(E[Y]\\), \\(\\text{Var}[X]\\), and \\(\\text{Var}[Y]\\). How do they compare? Consider the following three scenarios: A fair coin is tossed 3 times. \\(X\\) is the number of heads and \\(Y\\) is the number of tails. A fair coin is tossed 4 times. \\(X\\) is the number of heads in the first 3 tosses, \\(Y\\) is the number of heads in the last 3 tosses. A fair coin is tossed 6 times. \\(X\\) is the number of heads in the first 3 tosses, \\(Y\\) is the number of heads in the last 3 tosses. Use properties of covariance to calculate \\(\\text{Cov}[X, Y]\\) for each of these three scenarios. You should not need to use LOTUS or the shortcut formula for covariance. Hint 1: For the first scenario, write \\(Y\\) as a function of \\(X\\). Hint 2: For the second scenario, write \\(X = A + B\\) and \\(Y = B + C\\), where \\(A, B, C\\) are independent random variables. (This problem is challenging but rewarding.) A poker hand (5 cards) is dealt off the top of a well-shuffled deck of 52 cards. Let \\(X\\) be the number of diamonds in the hand. Let \\(Y\\) be the number of hearts in the hand. Do you think \\(\\text{Cov}[X, Y]\\) is positive, negative, or zero? Explain. Let \\(D_i (i=1, ..., 5)\\) be a random variable that is \\(1\\) if the \\(i\\)th card is a diamond and \\(0\\) otherwise. What is \\(E[D_i]\\)? Let \\(H_i (i=1, ..., 5)\\) be a random variable that is \\(1\\) if the \\(i\\)th card is a heart and \\(0\\) otherwise. Of course, \\(E[H_i]\\) is the same as \\(E[D_i]\\), since there are the same number of hearts as diamonds in a 52-card deck. What is \\(\\text{Cov}[D_i, H_i]\\)? What is \\(\\text{Cov}[D_i, H_j]\\), when \\(i \\neq j\\)? (Keep in mind that \\(D_i\\) and \\(H_i\\) are indicator random variables that only take on the values 0 or 1.) Hint: Make a table for the joint p.m.f. There are only 4 possible outcomes. Use your answers to parts b and c (and the properties of covariance, of course) to calculate \\(\\text{Cov}[X, Y]\\). Additional Practice Recall the coupon collector problem from Lesson 26: McDonald’s decides to give a Pokemon toy with every Happy Meal. Each time you buy a Happy Meal, you are equally likely to get any one of the 6 types of Pokemon. Let \\(X\\) be the number of Happy Meals you have to buy until you “catch ’em all”. In that lesson, you calculated \\(E[X]\\) using linearity of expectation. Now, use properties of covariance to calculate \\(\\text{Var}[X]\\). At Diablo Canyon nuclear plant, radioactive particles hit a Geiger counter according to a Poisson process with a rate of 3.5 particles per second. Let \\(X\\) be the number of particles detected in the first 2 seconds. Let \\(Z\\) be the number of particles detected in the first 3 seconds. Find \\(\\text{Cov}[X, Z]\\). Hint: Note that \\(X\\) and \\(Z\\) are not independent. However, you should be able to write \\(Z = X + Y\\), where \\(Y\\) is a random variable that is independent of \\(X\\). "],
["random-walk.html", "Lesson 31 Random Walk Theory Essential Practice", " Lesson 31 Random Walk Theory The random walk (also known as the “drunkard’s walk”) is an example of a random process evolving over time, like the Poisson process (Lesson 17). The setup for the random walk is as follows. A drunk man is stumbling home from a bar. Because of his inebriated state, each step he takes is equally likely to be one step forward or one step backward, independent of any other step. In other words, the \\(i\\)th step is a random variable \\(Z_i\\), with p.m.f. \\[ \\begin{array}{r|cc} z &amp; -1 &amp; 1 \\\\ \\hline f(z) &amp; 0.5 &amp; 0.5 \\end{array} \\] and the \\(Z_i\\)s are independent. The drunkard’s position after \\(n\\) steps is \\[ X_n = Z_1 + Z_2 + \\ldots + Z_n. \\] (We assume that he starts at the origin \\(X_0 = 0\\).) Shown below are three possible realizations of the random walk. A realization of a random process over time is called a sample path. We plot the three sample paths below, each of which shows the position of the drunkard \\(X_n\\) as a function of \\(n\\). Although all three sample paths start at 0 at \\(n=0\\), they diverge very quickly. Essential Practice Answer the following questions about the random walk. You should use linearity of expectation and properties of covariance as much as possible. What is the distribution of \\(X_2\\), the drunkard’s position after just \\(2\\) steps? (This is not a named distribution. Just make a table showing the possible values and their probabilities.) Calculate \\(E[Z_i]\\) and \\(\\text{Var}[Z_i]\\). Calculate \\(E[X_3]\\) and \\(\\text{Var}[X_3]\\). Consider \\(X_3\\) and \\(X_5\\). Do you think their covariance is positive, negative, or zero? Calculate \\(\\text{Cov}[X_3, X_5]\\). "],
["lln.html", "Lesson 32 Law of Large Numbers Motivating Example Theory Essential Practice", " Lesson 32 Law of Large Numbers Motivating Example So far, we have seen that that casino games like roulette have negative expected value (for the player). But we have also seen that there is a lot of variance. How can casinos be sure that they will not lose all of their money to players in a stroke of bad luck? The answer lies in the Law of Large Numbers. In the long-run, as a player makes more and more negative expected value bets, it is a virtual certainty that the player will lose money. Theory Suppose we make the same bet repeatedly. Let \\(X_i\\) be our net winnings from bet \\(i\\). Then \\(X_1, X_2, X_3, \\ldots\\) are independent, and furthermore, they are identically distributed (since the bets are the same). We say that \\(X_1, X_2, X_3, \\ldots\\) are i.i.d. (which is short for “independent and identically distributed”). Theorem 32.1 (Law of Large Numbers) Let \\(X_1, X_2, X_3, \\ldots\\) be i.i.d. random variables. Then, the average of the random variables approaches the expected value: \\[\\begin{equation} \\frac{X_1 + X_2 + \\ldots + X_n}{n} \\to E[X_1] \\tag{32.1} \\end{equation}\\] as \\(n\\to\\infty\\). Proof. Here is a heuristic proof. We calculate the expected value and the variance of \\[ \\bar X_n \\overset{\\text{def}}{=} \\frac{X_1 + X_2 + \\ldots + X_n}{n}. \\] The expected value is: \\[\\begin{align*} E[\\bar X_n] &amp;= E\\left[ \\frac{X_1 + X_2 + \\ldots + X_n}{n} \\right] \\\\ &amp;= \\frac{1}{n} E[X_1 + X_2 + \\ldots + X_n] \\\\ &amp;= \\frac{1}{n} (E[X_1] + E[X_2] + \\ldots + E[X_n]) \\\\ &amp;= \\frac{1}{n} nE[X_1] \\\\ &amp;= E[X_1]. \\end{align*}\\] The variance is: \\[\\begin{align*} \\text{Var}[\\bar X_n] &amp;= \\text{Var}\\left[ \\frac{X_1 + X_2 + \\ldots + X_n}{n} \\right] \\\\ &amp;= \\frac{1}{n^2} \\text{Var}\\left[ X_1 + X_2 + \\ldots + X_n \\right] \\\\ &amp;= \\frac{1}{n^2} (\\text{Var}[X_1] + \\text{Var}[X_2] + \\ldots + \\text{Var}[X_n]) \\\\ &amp;= \\frac{1}{n^2} n \\text{Var}[X_1] \\\\ &amp;= \\frac{\\text{Var}[X_1]}{n}. \\end{align*}\\] So we see that as \\(n\\to\\infty\\), the expected value is fixed at \\(E[X_1]\\), and the variance approaches \\(0\\). A random variable with zero variance is a constant. Therefore, in the limit, the random variable \\(\\bar X_n\\) approaches the constant \\(E[X_1]\\). To appreciate the Law of Large Numbers, consider betting on reds in roulette, a bet with an expected value of -$0.05, represented by a red dashed line in the figure below. There are many possible ways it could turn out; three sample paths are shown below. There is a lot of uncertainty about how much you will make (on average) in the first 200 bets, but by the time we have made 1000 bets, there is not much uncertainty at all. We are guaranteed to lose money in the long run. The game of chance involves very little chance, especially when you are a large casino, which handles millions of such bets every year. Example 32.1 Essential Practice These questions make reference to the opening scene from the Tom Stoppard play Rosencrantz and Guildenstern are Dead (a retelling of Shakespeare’s Hamlet). You do not need to watch the scene to answer these questions, but I’ve included it just for fun. Rosencrantz and Guildenstern have just learned the Law of Large Numbers. It turns out that they have a different understanding of what the law says… Guildenstern: The Law of Large Numbers says that in the long run, the coin will land heads as often as it lands tails. Rosencrantz: I don’t think that’s what it says. The Law of Large Numbers says that the fraction of heads will get closer and closer to 1/2, which is the expected value of each toss. Guildenstern: Isn’t that the same as what I said? Rosencrantz: No, you said, “The coin will land heads as often as it lands tails,” which implies that the difference between the number of heads and the number of tails will get smaller as we toss the coin more and more. I don’t think the number of heads will be close to the number of tails. Guildenstern: If the fraction of heads is close to 1/2, then the number of heads must be close to the number of tails. How could it be otherwise? Who is right: Rosencrantz or Guildenstern? Calculate the variance of \\[ \\text{number of heads in $n$ tosses} - \\text{number of tails in $n$ tosses} \\] as a function of \\(n\\). In light of this calculation, do you agree with Guildenstern that the difference between the number of heads and the number of tails approaches 0 as the number of tosses increases? Rosencrantz and Guildenstern are tossing a coin. The coin has landed heads 85 times in a row. They discuss the probability that the next toss is heads. Rosencrantz: We are due for tails! We have had so many heads that the next toss has to be more likely to land tails. Guildenstern: Not so fast. Didn’t we call this the “gambler’s fallacy” in Lesson 7? The coin tosses are independent, so each toss is still equally likely to land heads or tails, regardless of past experience. Rosencrantz: But what about the Law of Large Numbers? It says that we have to end up with 50% tails eventually. We are in a deep hole from the 85 heads in a row. How can we get back to 50% tails if the coin is not more likely now to land tails? Of course, Guildenstern is right. The coin is not more likely to land tails. But how would you answer Rosencrantz’s question? Why does the Law of Large Numbers not contradict the gambler’s fallacy? "],
["continuous.html", "Lesson 33 Continuous Random Variables Motivating Example Theory Optional Video Essential Practice", " Lesson 33 Continuous Random Variables Motivating Example In a Poisson process, the number of arrivals in any interval is a random variable that follows a Poisson distribution. But what about the time of the first arrival? This is also a random variable, but of a different kind. The time of the first arrival does not have to be an integer. It can equal \\(1.2\\) seconds, \\(2.173\\) seconds, \\(\\sqrt{2}\\) seconds, or even \\(\\pi\\) seconds. In fact, any real number from \\(0\\) to \\(\\infty\\) is a possible value of this random variable. To be concrete, suppose radioactive particles hit a Geiger counter according to a Poisson process with a rate of \\(\\lambda = 0.8\\) particles per second. We will represent the time of the first arrival—that is, the time that the first particle hits the Geiger counter—by \\(T\\). We can calculate probabilities involving \\(T\\). For example, we can calculate the probability that the first particle arrives after 2 seconds by rewriting this event in terms of the number of arrivals on an interval: \\[ P(T &gt; 2) = P(\\text{0 particles between 0 and 2 seconds}) \\] We know that the number of particles between 0 and 2 seconds follows a \\(\\text{Poisson}(\\mu=0.8 \\cdot 2)\\) distribution, so we just need to evaluate the p.m.f. at \\(x=0\\): \\[\\begin{equation} P(T &gt; 2) = e^{-0.8 \\cdot 2} \\frac{(0.8 \\cdot 2)^0}{0!} = e^{-1.6} \\approx .202. \\tag{33.1} \\end{equation}\\] We can also calculate the probability that the first arrival happens between \\(2\\) and \\(3\\) seconds, as: \\[ P(2 &lt; T &lt; 3) = P(T &gt; 2) - P(T &gt; 3). \\] We calculate \\(P(T &gt; 3)\\) in much the same way as we calculated \\(P(T &gt; 2)\\) above: \\[\\begin{equation} P(T &gt; 3) = e^{-0.8 \\cdot 3} \\frac{(0.8 \\cdot 3)^0}{0!} = e^{-2.4} \\approx .091. \\tag{33.2} \\end{equation}\\] So we see that \\[ P(2 &lt; T &lt; 3) = e^{-1.6} - e^{-2.4} \\approx .111. \\] Although we can calculate specific probabilities involving \\(T\\), how do we describe its distribution? In particular: What is its c.d.f.? Does it have a p.m.f.? We will answer these questions in this lesson and more. Theory First, we calculate the c.d.f. of \\(T\\), which is straightforward from its definition (11.1). Example 33.1 (The CDF of the First Arrival) Remember that the c.d.f. is defined as \\(F(t) = P(T \\leq t)\\) as a function of \\(t\\). First, we use the complement rule: \\[ F(t) = P(T \\leq t) = 1 - P(T &gt; t). \\] Now, we calculate \\(P(T &gt; t)\\), in much the same way that we calculated \\(P(T &gt; 2)\\) in (33.1) and \\(P(T &gt; 3)\\) in (33.2): \\[ P(T &gt; t) = e^{- 0.8 \\cdot t} \\frac{(0.8 \\cdot t)^0}{0!} = e^{-0.8 t}. \\] This formula works for \\(t \\geq 0\\). Since times are positive, we know that \\[ P(T &gt; t) = 1 \\] for \\(t &lt; 0\\). Putting everything together, the c.d.f. of \\(T\\) is \\[ F(t) = 1 - P(T &gt; t) = \\begin{cases} 1 - e^{-0.8 t} &amp; t \\geq 0 \\\\ 0 &amp; t &lt; 0 \\end{cases}. \\] This function is graphed below. Figure 33.1: CDF of the First Arrival Notice how different this c.d.f. is, compared with the ones we graphed in Lesson 11. In Figure 11.1, the c.d.f. was a step function, with a jump at each possible value of the random variable. By contrast, the c.d.f. above is continuous. This is the main distinction between the kinds of random variables we were studying before, which are called discrete random variables, and the kinds of random variables we study in this lesson, which are called continuous random variables. Definition 33.1 (Continuous Random Variable) A random variable is called continuous if its c.d.f. is a continuous function. With discrete random variables, we can visualize the shape of the distribution by graphing its p.m.f. Recall that the p.m.f. specified the probability that the random variable is equal to \\(x\\). Continuous random variables do not have a p.m.f. because the probability of any exact outcome is zero. Example 33.2 (Probability of a Single Outcome) Continuing with Example 33.1, what is the probability that the first particle hits the Geiger counter at exactly 2 seconds—that is, \\(P(T = 2.00000...)\\)? First, consider the probability that the first arrival is in the interval \\((2 - \\epsilon, 2 + \\epsilon)\\), where \\(\\epsilon\\) is a small positive number. No matter how small an \\(\\epsilon\\) we choose, this probability will always be greater than the probability that the first arrival happens at exactly 2 seconds, since this interval includes 2 seconds, as well as some other outcomes. (For example, if \\(\\epsilon = 0.05\\), then this interval would also include the possibility that the first arrival happens at 1.98 seconds or 2.01 seconds.) The number of arrivals on the interval \\((2 - \\epsilon, 2 + \\epsilon)\\) is a Poisson random variable with parameter \\(\\mu = 0.8 \\cdot 2\\epsilon\\). Therefore, the probability that there are no arrivals on the interval is: \\[\\begin{align*} P(\\text{at least 1 arrival on interval}) &amp;= 1 - P(\\text{no arrivals on interval}) \\\\ &amp;= 1 - e^{-0.8 \\cdot 2\\epsilon} \\frac{(0.8 \\cdot 2 \\epsilon)^0}{0!} \\\\ &amp;= 1 - e^{-1.6 \\epsilon}. \\end{align*}\\] But \\(\\epsilon\\) can be arbitrarily small. As \\(\\epsilon \\to 0\\), this probability approaches 0. Therefore, the probability that the first arrival happens at exactly 2 seconds is zero. Because the probability of every outcome in a continuous random variable is zero, continuous random variables cannot be described by their p.m.f. Instead, they are described by a similar function called the probability density function. Definition 33.2 (Probability Density Function) The probability density function (or p.d.f.) of a continuous random variable is defined to be the derivative of the c.d.f. \\[ f(x) \\overset{\\text{def}}{=} F&#39;(x). \\] The values of \\(f(x)\\) do not represent the probability that the random variable is equal to \\(x\\) (because for a continuous random variable, that probability is always equal to 0). The following video presents an alternative perspective on the p.d.f. It gives more insight into what a “probability density” is. It also reinforces the message that \\(P(X = x) = 0\\) for any continuous random variable \\(X\\). Example 33.3 (The PDF of the First Arrival) Continuing with Example 33.1, the c.d.f. was calculated to be \\[ F(t) = \\begin{cases} 1 - e^{-0.8 t} &amp; t \\geq 0 \\\\ 0 &amp; t &lt; 0 \\end{cases}. \\] Taking the derivative, we have \\[\\begin{equation} f(t) = F&#39;(t) = \\begin{cases} 0.8 e^{-0.8 t} &amp; t \\geq 0 \\\\ 0 &amp; t &lt; 0 \\end{cases}. \\tag{33.3} \\end{equation}\\] Figure 33.2 below shows the p.d.f., along with the c.d.f. Since the p.d.f. is the derivative of the c.d.f., it is the slope of the c.d.f. at a given value of \\(t\\). The steeper the c.d.f., the higher the p.d.f. Figure 33.2: PDF from the CDF This p.d.f. tells us that the first arrival is more likely to happen sooner, rather than later. However, the values of the p.d.f. are not easy to interpret. They do not represent probabilities, but rather probability densities. If the values of the p.d.f. do not represent probabilities, how do we calculate probabilities using the p.d.f.? It turns out that areas under the p.d.f. represent probabilities. Theorem 33.1 (Calculating Probabilities Using the PDF) Let \\(X\\) be a continuous random variable with p.d.f. \\(f(x)\\). Then: \\[ P(a &lt; X \\leq b) = \\int_a^b f(x)\\,dx. \\] Proof. Let \\(F(x)\\) be the c.d.f. of \\(X\\). Then, we know that \\[ P(a &lt; X \\leq b) = P(X \\leq b) - P(X \\leq a) = F(b) - F(a). \\] Since \\(f = F&#39;\\), the Fundamental Theorem of Calculus says that \\[ F(b) - F(a) = \\int_a^b f(x)\\,dx. \\] Theorem 33.1 says that probabilities correspond to areas under the p.d.f. This is another way to see that the probability of any single outcome must be 0. The probability that \\(X = x\\) would be the integral from \\(x\\) to \\(x\\); since there is no area under the curve at \\(x\\), this probability must be 0. Let’s recalculate the probabilities from the Motivating Example, now using the p.d.f. (33.3). Example 33.4 (Calculating Probabilities Using the PDF) We know that the p.d.f. of the first arrival, \\(T\\), is \\[ f(t) = \\begin{cases} 0.8 e^{-0.8 t} &amp; t \\geq 0 \\\\ 0 &amp; t &lt; 0 \\end{cases}. \\] To calculate probabilities using Theorem 33.1, we integrate the p.d.f. For example, the probability that the first arrival happens between 2 and 3 seconds is: \\[ P(2 &lt; T &lt; 3) = \\int_2^3 f(t)\\,dt = \\int_2^3 0.8 e^{-0.8 t}\\,dt = .111, \\] and the probability that the first arrival happens after 2 seconds is \\[ P(T &gt; 2) = \\int_2^\\infty f(t)\\,dt = \\int_2^\\infty 0.8 e^{-0.8 t}\\,dt = .202.\\] The areas that these probabilities represent are shown on the graphs below. Figure 33.3: PDF of the First Arrival What about the probability that the first arrival happens before 3 seconds? Technically, we should integrate the p.d.f. from \\(-\\infty\\) to \\(3\\). However, \\(f(t) = 0\\) for \\(-\\infty &lt; t &lt; 0\\), so we effectively integrate the p.d.f. from \\(0\\) to \\(3\\): \\[ P(T &lt; 3) = \\int_{-\\infty}^3 f(t)\\,dt = \\int_0^3 0.8 e^{-0.8 t}\\,dt = .909. \\] So far, we saw that we take the derivative of the c.d.f. to get the p.d.f. We can also go in reverse: if we have the p.d.f., we can take its integral to get the c.d.f. \\[\\begin{equation} F(x) = \\int_{-\\infty}^x f(t)\\,dt. \\tag{33.4} \\end{equation}\\] Example 33.5 ((Re)deriving the CDF of the First Arrival) Suppose we only knew the p.d.f. of the first arrival \\(T\\): \\[ f(t) = \\begin{cases} 0.8 e^{-0.8 t} &amp; t \\geq 0 \\\\ 0 &amp; t &lt; 0 \\end{cases}. \\] To calculate the c.d.f. at \\(x\\), we integrate the p.d.f. up to \\(x\\). Since the p.d.f. is 0 when \\(t &lt; 0\\), the integral effectively starts from \\(t=0\\). \\[ F(x) = \\int_{-\\infty}^x f(t)\\,dt = \\int_0^x 0.8 e^{-0.8 t}\\,dt = 1 - e^{-0.8 x}. \\] (This integral can be calculated using the \\(u\\)-substitution \\(u=-0.8 t\\), or using Wolfram Alpha.) Figure 33.4 below illustrates how areas under the p.d.f. translate to values of the c.d.f. Figure 33.4: CDF from the PDF Optional Video This video (not my own) does an excellent job explaining the mechanics of calculations involving p.d.f.s and c.d.f.s. If you felt that you understood the material above well enough to do the Essential Practice below, you probably do not need to watch this video. Do not get too caught up in the calculus; remember that you can always use Wolfram Alpha to compute any integrals or derivatives. Essential Practice Packets arrive at a certain node on the university’s intranet at 10 packets per minute, on average. Assume packet arrivals meet the assumptions of a Poisson process. What is the p.d.f. of \\(T\\), the time of the first arrival? What is the probability that the first arrival happens between 10 seconds and 30 seconds? (Note that the rate in the problem is given in minutes.) Two Cal Poly students, Ferris and Cameron, are frequently late to class. Cal Poly classes start at 10 minutes past the hour mark. Let \\(X\\) be the time (in minutes) that Ferris arrives at class after the hour mark. The p.d.f. of \\(X\\) is \\[ f_X(x) = \\begin{cases} \\frac{1}{60} &amp; 0 \\leq x &lt; 60 \\\\ 0 &amp; \\text{otherwise} \\end{cases}. \\] Let \\(Y\\) be the time (in minutes) that Cameron arrives at class after the hour mark. The p.d.f. of \\(Y\\) is \\[ f_Y(y) = \\begin{cases} \\frac{60 - y}{1800} &amp; 0 \\leq y &lt; 60 \\\\ 0 &amp; \\text{otherwise} \\end{cases}. \\] Sketch a graph of the two p.d.f.s. Without doing any calculations, who is more likely to arrive on time (i.e., within the first 10 minutes of the hour)? Determine the c.d.f.s of \\(X\\) and \\(Y\\). Calculate the probability that Ferris arrives on time. You should be able to calculate this probability in three ways: (1) finding the area under the p.d.f. using geometry, (2) finding the area under the p.d.f. using calculus, and (3) using the c.d.f. Calculate the probability that Cameron arrives on time. You should also be able to calculate this probability in three ways. The distance (in hundreds of miles) driven by a trucker in one day is a continuous random variable \\(X\\) whose cumulative distribution function (c.d.f.) is given by: \\[ F(x) = \\begin{cases} 0 &amp; x &lt; 0 \\\\ x^3 / 216 &amp; 0 \\leq x \\leq 6 \\\\ 1 &amp; x &gt; 6 \\end{cases}. \\] Determine the p.d.f. Sketch a graph. Calculate the probability that the trucker travels more than 500 miles in a day. (You should be able to calculate this in at least 2 ways: directly from the c.d.f. and using the p.d.f. that you calculated in the previous part.) Calculate the probability that the trucker travels exactly 200 miles in a day. Let \\(T\\) be how late that a professor lets her class out (in minutes). (If \\(T\\) is negative, then she finishes the class early.) The p.d.f. of \\(T\\) is \\[ f(t) = \\begin{cases} c(2 + t) &amp; -2 &lt; t &lt; 0 \\\\ c(2 - t) &amp; 0 \\leq t &lt; 2 \\\\ 0 &amp; \\text{otherwise} \\end{cases}, \\] where \\(c\\) is a constant. Determine the value of \\(c\\) necessary to make this a proper p.d.f. (Hint: What does the total probability have to be?) Sketch the p.d.f. Calculate the probability that the professor finishes between 1 minute early and 30 seconds late, i.e., \\(P(-1 &lt; T &lt; 0.5)\\). "],
["uniform.html", "Lesson 34 Uniform Distribution Motivation Theory Essential Practice", " Lesson 34 Uniform Distribution Motivation How do we model a random variable that is equally likely to take on any real number between \\(a\\) and \\(b\\)? Theory Definition 34.1 (Uniform Distribution) A random variable \\(X\\) is said to follow a \\(\\text{Uniform}(a, b)\\) distribution if its p.d.f. is \\[ f(x) = \\begin{cases} \\frac{1}{b-a} &amp; a \\leq x \\leq b \\\\ 0 &amp; \\text{otherwise} \\end{cases}, \\] or equivalently, if its c.d.f. is \\[ F(x) = \\begin{cases} 0 &amp; x &lt; a \\\\ \\frac{x-a}{b-a} &amp; a \\leq x \\leq b \\\\ 1 &amp; x &gt; b \\end{cases}. \\] The p.d.f. and c.d.f. are graphed below. Figure 34.1: PDF and CDF of the Uniform Distribution Why is the p.d.f. of a \\(\\text{Uniform}(a, b)\\) random variable what it is? Since we want all values between \\(a\\) and \\(b\\) to be equally likely, the p.d.f. must be constant between \\(a\\) and \\(b\\). This constant is chosen so that the total area under the p.d.f. (i.e., the total probability) is 1. Since the p.d.f. is a rectangle of width \\(b-a\\), the height must be \\(\\frac{1}{b-a}\\) to make the total area 1. Example 34.1 You buy fencing for a square enclosure. The length of fencing that you buy is uniformly distributed between 0 and 4 meters. What is the probability that the enclosed area will be larger than \\(0.5\\) square meters? Solution. Let \\(L\\) be a \\(\\text{Uniform}(a=0, b=4)\\) random variable. Note that \\(L\\) represents the perimeter of the square enclosure, so \\(L/4\\) is the length of a side and the area is \\[ A = \\left( \\frac{L}{4} \\right)^2 = \\frac{L^2}{16}. \\] We want to calculate \\(P(\\frac{L^2}{16} &gt; 0.5)\\). To do this, we rearrange the expression inside the probability to isolate \\(L\\), at which point we can calculate the probability by integrating the p.d.f. of \\(L\\) over the appropriate range. \\[\\begin{align*} P(\\frac{L^2}{16} &gt; 0.5) &amp;= P(L &gt; \\sqrt{8}) \\\\ &amp;= \\int_{\\sqrt{8}}^{4} \\frac{1}{4 - 0}\\,dx \\\\ &amp;= \\frac{4 - \\sqrt{8}}{4} \\\\ &amp;\\approx .293. \\end{align*}\\] Essential Practice A point is chosen uniformly along the length of a stick, and the stick is broken at that point. What is the probability the left segment is more than twice as long as the right segment? (Hint: Assume the length of the stick is 1. Let \\(X\\) be the point at which the stick is broken, and observe that \\(X\\) is the length of the left segment.) You inflate a spherical balloon in a single breath. If the volume of air you exhale in a single breath (in cubic inches) is \\(\\text{Uniform}(a=36\\pi, b=288\\pi)\\) random variable, what is the probability that the radius of the balloon is less than 5 inches? "],
["exponential.html", "Lesson 35 Exponential Distribution Motivating Example Theory Essential Practice", " Lesson 35 Exponential Distribution Motivating Example In Fishtown, buses do not operate on a fixed schedule. Instead, they arrive according to a Poisson process at a rate of one per 10 minutes. How long would you have to wait if you show up at a bus stop at an arbitrary time? Most people guess that they would have to wait about 5 minutes, since usually you will show up at the bus stop in between bus arrivals. Surprisingly, the answer is that you have to wait just as long as if you had arrived right when the previous bus was leaving! We will see why at the end of this lesson. Theory The exponential distribution is commonly used to model time: the time between arrivals, the time until a component fails, the time until a patient dies. We have already encountered several examples of exponential random variables—the time of the first arrival in a Poisson process follows an exponential distribution. Definition 35.1 (Exponential Distribution) A random variable \\(X\\) is said to follow a \\(\\text{Exponential}(\\lambda)\\) distribution if its p.d.f. is \\[\\begin{equation} f(x) = \\begin{cases} \\lambda e^{-\\lambda x} &amp; x \\geq 0 \\\\ 0 &amp; \\text{otherwise} \\end{cases}, \\tag{35.1} \\end{equation}\\] or equivalently, if its c.d.f. is \\[\\begin{equation} F(x) = \\begin{cases} 1 - e^{-\\lambda x} &amp; x \\geq 0 \\\\ 0 &amp; \\text{otherwise} \\end{cases}. \\tag{35.2} \\end{equation}\\] The p.d.f. and c.d.f., for three different values of \\(\\lambda\\), are graphed below. Figure 35.1: PDF and CDF of the Exponential Distribution First, we show that the first arrival time in a Poisson process follows an exponential distribution. These calculations follow closely the ones we did in Lesson 33. Theorem 35.1 (First Arrival Time in a Poisson Process) The time of the first arrival in a Poisson process of rate \\(\\lambda\\) is an \\(\\text{Exponential}(\\lambda)\\) random variable. Proof. Let \\(T\\) be the time of the first arrival. Then, for \\(t &gt; 0\\), the c.d.f. of \\(T\\) is \\[\\begin{align*} F(t) &amp;= P(T \\leq t) \\\\ &amp;= 1 - P(T &gt; t) \\\\ &amp;= 1 - P(\\text{0 arrivals in $(0, t)$}) \\\\ &amp;= 1 - e^{- \\lambda t} \\frac{(\\lambda t)^0}{0!} \\\\ &amp;= 1 - e^{-\\lambda t}. \\end{align*}\\] This is the c.d.f. of an \\(\\text{Exponential}(\\lambda)\\) random variable, as shown in (35.2). In fact, the time between any two arrivals in a Poisson process follows the same distribution. Theorem 35.2 (Interarrival Times in a Poisson Process) The times between arrivals (called interarrival times) in a Poisson process of rate \\(\\lambda\\) are independent \\(\\text{Exponential}(\\lambda)\\) random variables. Proof. Let \\(T_1\\) be the time of the first arrival and \\(T_2\\) be the time between the first and second arrivals. The distribution of \\(T_2\\) given \\(T_1\\) is \\[\\begin{align*} P(T_2 \\leq x | T_1 = t) &amp;= P(\\text{at least 2 arrivals on $(0, t + x)$} | T_1 = t) \\\\ &amp;= P(\\text{at least 1 arrival on $(t, t + x)$} | T_1 = t) \\\\ &amp;= P(\\text{at least 1 arrival on $(t, t + x)$}) \\\\ &amp;= 1 - e^{-\\lambda x} \\frac{(\\lambda x)^0}{0!} \\\\ &amp;= 1 - e^{-\\lambda x}, \\end{align*}\\] which is the c.d.f. of an \\(\\text{Exponential}(\\lambda)\\) random variable. Moreover, this expression does not depend on \\(t\\), so \\(T_1\\) and \\(T_2\\) are independent, so this is also the (unconditional) distribution of \\(T_2\\). The key to the above proof was the third equality. \\(\\{ T_1 = t \\}\\) is an event that depends on what happens on the interval \\((0, t)\\). But by the definition of the Poisson process, it is independent of what happens on the interval \\((t, t + x)\\). By similar reasoning, we can show that \\(T_3\\), the time between the second and third arrivals, is independent of \\(T_1\\) and \\(T_2\\), and so on. The exponential distribution can be used to model random variables that have nothing to do with a Poisson process, as the next example illustrates. Example 35.1 (Lifetime of a Lightbulb) The lifetime of a lightbulb (in years) is an \\(\\text{Exponential}(\\lambda=0.3)\\) random variable. What is the probability that the lightbulb lasts between 1 and 5 years? Solution. Let \\(X\\) be the lifetime of the lightbulb. Then, the p.d.f. of \\(X\\) is \\[ f(x) = \\begin{cases} 0.3 e^{-0.3 x} &amp; x \\geq 0 \\\\ 0 &amp; x &lt; 0 \\end{cases}. \\] We integrate this p.d.f. from 1 to 5: \\[ P(1 &lt; X &lt; 5) = \\int_1^5 f(x)\\,dx = \\int_1^5 0.3 e^{-0.3 x}\\,dx \\approx .517. \\] Alternatively, we could have used the c.d.f. of \\(X\\): \\[ P(1 &lt; X &lt; 5) = F(5) - F(1) = (1 - e^{-0.3 \\cdot 5}) - (1 - e^{-0.3 \\cdot 1}) \\approx .517. \\] Although it is not too hard to compute probabilities from the exponential distribution, we can also use software to calculate these probabilities for us. Open up this notebook in Colab and play around with it. The exponential distribution has a surprising property called the memoryless property. Theorem 35.3 (Memoryless Property of the Exponential Distribution) An exponential random variable \\(X\\) has the memoryless property. That is, for any \\(s, t &gt; 0\\), \\[\\begin{equation} P(X &gt; s + t | X &gt; s) = P(X &gt; t) \\tag{35.3} \\end{equation}\\] Proof. We use the fact that \\(P(X &gt; x) = 1 - F(x) = 1 - (1 - e^{-\\lambda x}) = e^{-\\lambda x}\\). \\[\\begin{align*} P(X &gt; s + t | X &gt; s) &amp;= \\frac{P(X &gt; s + t \\text{ and } X &gt; s)}{P(X &gt; s)} \\\\ &amp;= \\frac{P(X &gt; s + t)}{P(X &gt; s)} \\\\ &amp;= \\frac{e^{-\\lambda (s + t)}}{e^{-\\lambda s}} \\\\ &amp;= e^{-\\lambda t} \\\\ &amp;= P(X &gt; t) \\end{align*}\\] The memoryless property has some surprising consequences. The example presented at the beginning of the lesson is one of them. Example 35.2 (The Waiting Time Paradox) If buses in Fishtown arrive at a bus stop according to a Poisson process at a rate of one per 10 minutes (i.e., \\(\\lambda = 0.1\\) arrivals per minute), how long do you have to wait before the next bus arrives? We know from Theorem 35.2 that the time \\(X\\), between when the previous bus arrived and when the next bus will arrive, follows a \\(\\text{Exponential}(\\lambda=0.1)\\) distribution. However, you showed up at the bus stop some time \\(s\\) after the previous bus had left, so you should not have to wait as long as \\(X\\). Instead, your waiting time is \\(W = X - s\\), given that \\(X &gt; s\\) (i.e., the next bus has not arrived yet when you show up at the stop). But by the memoryless property (35.3), \\[ P(W &gt; t | X &gt; s) = P(X - s &gt; t | X &gt; s) = P(X &gt; t). \\] So you have to wait just as long as if you had showed up right as the previous bus was leaving. You do not save any time by showing up in between bus arrivals! Essential Practice Let \\(X\\) denote the distance (in meters) that an animal moves from its birth site to the first territorial vacancy it encounters. Suppose that for banner-tailed kangaroo rats, \\(X\\) has an exponential distribution with parameter \\(\\lambda = .01386\\) (as suggested in the article “Competition and Dispersal from Multiple Nests,” Ecology, 1997: 873–883). What is the probability that the distance is more than 100 m? This probability is higher than it was in 1950, due to environmental changes. Suppose that in 1950, only 12% of banner-tailed kangaroo rats moved more than 100 m from their birth site. What was the value of \\(\\lambda\\) then? Small aircraft arrive at San Luis Obispo airport according to a Poisson process at a rate of 6 per hour. What is the probability that more than 15 minutes elapse before the first plane lands? What is the probability that more than 15 minutes elapse between when the first and second planes land? What is the probability that it takes more than 15 minutes elapse before the first plane lands and more than 15 minutes elapse between when the first and second planes land? What is the probability that more than 30 minutes elapse before two planes have landed? Why is the answer different than your answer to part c? (Hint: You can calculate this using properties of a Poisson process. Rewrite the event in terms of the number of planes that land in the interval \\((0, 30)\\).) A post office has 2 clerks. Alice enters the post office while 2 other customers, Bob and Claire, are being served by the 2 clerks. She is next in line. Assume that the time a clerk spends serving a customer (in minutes) follows an \\(\\text{Exponential}(\\lambda=0.2)\\) distribution. What is the probability that Alice is the last of the 3 customers to be done being served? (Hint: This can be answered without any calculations, by thinking about the memoryless property.) "],
["transformations.html", "Lesson 36 Transformations Motivating Example Theory Essential Practice Additional Practice", " Lesson 36 Transformations Motivating Example You buy fencing for a square enclosure. The length of fencing that you buy is uniformly distributed between 0 and 4 meters. What is the distribution of the area of the enclosure? Most people realize that the area must be between 0 and 1 square meters, since the length of each side must be between 0 and 1 meters, and the square of a number between 0 and 1 is also between 0 and 1. But how likely are the values in between? Theory We can formalize the above example as follows. The length of fencing, \\(L\\), is a \\(\\text{Uniform}(a=0, b=4)\\) random variable, and we are interested in the distribution of \\(A = (L/4)^2\\). First, let’s simulate the distribution of \\(A\\). The Colab below begins with a uniform random variable \\(L\\), defines \\(A = (L / 4)^2\\), and displays 10000 simulations of both \\(L\\) and \\(A\\). In the simulation above, \\(L\\) is equally likely to take on all values between 0 and 4. This is not surprising because \\(L\\) was defined to be this way (a uniform distribution between 0 and 4). The distribution of \\(A\\) is more interesting. It is much more concentrated toward the lower values than the higher values. In hindsight, this makes sense because \\((L / 4)\\) is a number between 0 and 1, and numbers between 0 and 1 get smaller when we square them. How do we derive the p.d.f. of \\(A\\)? This is a special case of a more general problem. We have a random variable \\(X\\) whose distribution we know, and we want to find the distribution of \\(Y = g(X)\\), a transformation of \\(X\\). The strategy for these problems is this: Calculate the c.d.f. of \\(Y\\) (by rewriting the event in terms of \\(X\\) and using the known distribution of \\(X\\)). Take the derivative to obtain the p.d.f. of \\(Y\\) (by Definition 33.2). Example 36.1 Let’s apply this strategy to the example at the beginning of the lesson. First, we find the c.d.f. of \\(A\\), the area of the enclosure. We write out the definition of the c.d.f., express \\(A\\) in terms of \\(L\\), and rearrange the expression to make the probability easy to calculate. \\[\\begin{align*} F_A(x) &amp;= P(A \\leq x) \\\\ &amp;= P\\left((L/4)^2 \\leq x\\right) \\\\ &amp;= P(L \\leq 4 \\sqrt{x}) &amp; \\text{(if $x \\geq 0$)} \\\\ &amp;= \\begin{cases} 0 &amp; x &lt; 0 \\\\ \\sqrt{x} &amp; 0 \\leq x \\leq 1 \\\\ 1 &amp; x &gt; 1 \\end{cases}. \\end{align*}\\] Now we take the derivative to get the p.d.f. \\[ f_A(x) = \\frac{d}{dx} F_A(x) = \\begin{cases} \\frac{1}{2\\sqrt{x}} &amp; 0 \\leq x \\leq 1 \\\\ 0 &amp; \\text{otherwise} \\end{cases}. \\] We graph the p.d.f.s of \\(L\\) and \\(A\\) below. Compare these with our simulations above. Figure 36.1: Distributions of \\(L\\) and \\(A\\) Now, we derive formulas for the two most common types of transformations: shifting by a constant and scaling by a constant. Theorem 36.1 (Shift Transformation) Let \\(X\\) be a continuous random variable with p.d.f. \\(f_X\\). The p.d.f. of \\(Y = X + b\\) is \\[\\begin{equation} f_Y(y) = f_X(y - b). \\tag{36.1} \\end{equation}\\] Proof. We can express the c.d.f. of \\(Y\\) in terms of the c.d.f. of \\(X\\): \\[\\begin{align*} F_Y(y) &amp;= P(Y \\leq y) \\\\ &amp;= P(X + b \\leq y) \\\\ &amp;= P(X \\leq y - b) \\\\ &amp;= F_X(y - b). \\end{align*}\\] Taking the derivative, we see that the p.d.f. is \\[ f_Y(y) = \\frac{d}{dy} F_Y(y) = f_X(y - b). \\] The figure below illustrates a hypothetical p.d.f. for a random variable \\(X\\) and the corresponding p.d.f. for the shifted random variable \\(Y = X + 1\\). Notice how the p.d.f. is exactly the same, except shifted to the right by 1, as we would expect. Figure 36.2: Example of a Shift Transformation Theorem 36.2 (Scale Transformation) Let \\(X\\) be a continuous random variable with p.d.f. \\(f_X\\). The p.d.f. of \\(Y = aX\\), where \\(a &gt; 0\\) is a constant, is \\[\\begin{equation} f_Y(y) = \\frac{1}{a} f_X(\\frac{y}{a}). \\tag{36.2} \\end{equation}\\] Proof. We can express the c.d.f. of \\(Y\\) in terms of the c.d.f. of \\(X\\): \\[\\begin{align*} F_Y(y) &amp;= P(Y \\leq y) \\\\ &amp;= P(aX \\leq y) \\\\ &amp;= P(X \\leq \\frac{y}{a}) \\\\ &amp;= F_X(\\frac{y}{a}). \\end{align*}\\] Taking the derivative (don’t forget the chain rule!), we see that the p.d.f. is \\[ f_Y(y) = \\frac{d}{dy} F_Y(y) = \\frac{1}{a} f_X(\\frac{y}{a}). \\] The figure below illustrates a hypothetical p.d.f. for a random variable \\(X\\) and the corresponding p.d.f. for the scaled random variable \\(Y = 2X\\). Notice that the p.d.f. is the same shape, just wider and shorter. Figure 36.3: Example of a Scale Transformation The factor of \\(\\frac{1}{a}\\) on the inside in (36.2) is what makes the p.d.f. wider, and the factor of \\(\\frac{1}{a}\\) on the outside is what makes it shorter. It is necessary to make the p.d.f. shorter if we make it wider, since the total area under a p.d.f. must always be 1. Essential Practice You inflate a spherical balloon in a single breath. If the volume of air you exhale in a single breath (in cubic inches) is \\(\\text{Uniform}(a=36\\pi, b=288\\pi)\\) random variable, what is the p.d.f. of the radius of the balloon (in inches)? The lifetime of a lightbulb (in hours) follows an \\(\\text{Exponential}(\\lambda=\\frac{1}{1200})\\) distribution. Find the p.d.f. of the lifetime of the lightbulb in days (assuming the lightbulb is on 24 hours per day). A lighthouse on a shore is shining light toward the ocean at a random angle \\(U\\) (measured in radians), where \\(U\\) follows a \\(\\text{Uniform}(a=-\\frac{\\pi}{2}, b=\\frac{\\pi}{2})\\) distribution. Consider a line which is parallel to the shore and 1 mile away from the shore, as illustrated below. An angle of 0 would mean the ray of light is perpendicular to the shore, while an angle of \\(\\pi/2\\) would mean the ray is along the shore, shining to the right from the perspective of the figure. Let \\(X\\) be the point that the light hits on the line, where the line’s origin is the point on the line that is closest to the lighthouse. Find the p.d.f. of \\(X\\). (Hint: Use trigonometry to write \\(X\\) as a function of \\(U\\).) Additional Practice The radius of a circle (in inches) is chosen from an \\(\\text{Exponential}(\\lambda=1.5)\\) distribution. Find the p.d.f. of the area of the circle. "],
["ev-continuous.html", "Lesson 37 Expected Value of Continuous Random Variables Theory Essential Practice", " Lesson 37 Expected Value of Continuous Random Variables Theory Definition 37.1 (Expected Value of a Continuous Random Variable) Let \\(X\\) be a continuous random variable with p.d.f. \\(f(x)\\). Then, the expected value of \\(X\\) is defined as \\[\\begin{equation} E[X] = \\int_{-\\infty}^\\infty x \\cdot f(x)\\,dx. \\tag{37.1} \\end{equation}\\] Compare this definition with the definition of expected value for a discrete random variable (22.1). We simply replaced the p.m.f. by the p.d.f. and the sum by an integral. Example 37.1 (Expected Value of the Uniform Distribution) Let \\(X\\) be a \\(\\text{Uniform}(a, b)\\) random variable. What is \\(E[X]\\)? First, the p.d.f. is \\[ f(x) = \\begin{cases} \\frac{1}{b-a} &amp; a \\leq x \\leq b \\\\ 0 &amp; \\text{otherwise} \\end{cases}, \\] which is non-zero only between \\(a\\) and \\(b\\). So, even though (37.1) says we should integrate from \\(-\\infty\\) to \\(\\infty\\), the integrand will only be non-zero between \\(a\\) and \\(b\\). \\[\\begin{align*} E[X] &amp;= \\int_a^b x \\cdot \\frac{1}{b-a} \\,dx \\\\ &amp;= \\frac{1}{b-a} \\left. \\frac{x^2}{2} \\right]_a^b \\\\ &amp;= \\frac{1}{b-a} (b^2 - a^2) \\frac{1}{2} \\\\ &amp;= \\frac{a + b}{2}. \\end{align*}\\] This is just the midpoint of the possible values of this uniform random variable. This is clearly the point where the p.d.f. would balance, if we put it on a scale. Figure 37.1: Expected Value of the Uniform Distribution Example 37.2 (Expected Value and Median of the Exponential Distribution) Let \\(X\\) be an \\(\\text{Exponential}(\\lambda)\\) random variable. What is \\(E[X]\\)? Does the random variable have an equal chance of being above as below the expected value? First, we calculate the expected value using (37.1) and the p.d.f. of the exponential distribution (35.1). This is an exercise in integration by parts. \\[\\begin{align*} E[X] &amp;= \\int_0^\\infty x \\cdot \\lambda e^{-\\lambda x} \\,dx \\\\ &amp;= -x e^{-\\lambda x} \\Big|_0^\\infty - \\int_0^\\infty -e^{-\\lambda x}\\,dx \\\\ &amp;= \\ (-0 + 0) - \\underbrace{\\frac{1}{\\lambda} e^{-\\lambda x} \\Big|_0^\\infty}_{0 - \\frac{1}{\\lambda}} \\\\ &amp;= \\frac{1}{\\lambda} \\end{align*}\\] Now, let’s calculate the probability that the random variable is below expected value. \\[ P(X &lt; E[X]) = P(X &lt; \\frac{1}{\\lambda}) = \\int_0^{1/\\lambda} \\lambda e^{-\\lambda x}\\,dx = 1 - e^{-1} \\approx .632. \\] The random variable does not have an 50/50 chance of being above or below its expected value. The value that a random variable has an equal chance of being above or below is called its median. To calculate the median, we have to solve for \\(m\\) such that \\[ P(X &lt; m) = 0.5. \\] (Equivalently, we could solve \\(P(X &gt; m) = 0.5\\). It also doesn’t matter whether we use \\(&lt;\\) or \\(\\leq\\), since this is a continuous random variable, so \\(P(X = m) = 0\\).) Calculating the probability in terms of \\(m\\), we have \\[ 0.5 = P(X &lt; m) = \\int_0^m \\lambda e^{-\\lambda x}\\,dx = 1 - e^{-\\lambda m}. \\] Solving for \\(m\\), we see that the median is \\(-\\log(0.5) / \\lambda\\). (Note: \\(\\log\\) here is the natural logarithm, base \\(e\\).) Figure 37.2: Mean vs. Median of the Exponential Distribution Formulas for the variance of named continuous distributions can be found in Appendix A.2. Essential Practice The distance (in hundreds of miles) driven by a trucker in one day is a continuous random variable \\(X\\) whose cumulative distribution function (c.d.f.) is given by: \\[ F(x) = \\begin{cases} 0 &amp; x &lt; 0 \\\\ x^3 / 216 &amp; 0 \\leq x \\leq 6 \\\\ 1 &amp; x &gt; 6 \\end{cases}. \\] Calculate \\(E[X]\\), the expected value of \\(X\\). Calculate the median of \\(X\\). Sketch a graph of the p.d.f., along with the locations of the expected value and median. Suppose that an electronic device has a lifetime \\(T\\) (in hours) that follows an \\(\\text{Exponential}(\\lambda=\\frac{1}{1000})\\) distribution. What is \\(E[T]\\)? Suppose that the cost of manufacturing one such item is $2. The manufacturer sells the item for $5, but guarantees a total refund if the lifetime ends up being less than 900 hours. What is the manufacturer’s expected profit per item? "],
["lotus-continuous.html", "Lesson 38 LOTUS for Continuous Random Variables Theory Essential Practice", " Lesson 38 LOTUS for Continuous Random Variables Theory Theorem 38.1 (LOTUS for a Continuous Random Variable) Let \\(X\\) be a continuous random variable with p.d.f. \\(f(x)\\). Then, the expected value of \\(g(X)\\) is \\[\\begin{equation} E[g(X)] = \\int_{-\\infty}^\\infty g(x) \\cdot f(x)\\,dx. \\tag{38.1} \\end{equation}\\] Compare this definition with LOTUS for a discrete random variable (24.1). We simply replaced the p.m.f. by the p.d.f. and the sum by an integral. Example 38.1 (Expected Value of the Square of a Uniform) Suppose the current (in Amperes) flowing through a 1-ohm resistor is a \\(\\text{Uniform}(a, b)\\) random variable \\(I\\) for \\(a, b &gt; 0\\). The power dissipated by this resistor is \\(X = I^2\\). What is the expected power dissipated by the resistor? There are two ways to calculate this. Method 1 (The Long Way) We can first derive the p.d.f. of the power, \\(X = I^2\\), using the methods of Lesson 36. \\[\\begin{align*} F_X(x) &amp;= P(X \\leq x) \\\\ &amp;= P(I^2 \\leq x) \\\\ &amp;= P(I \\leq \\sqrt{x}) &amp; (\\text{if $x \\geq 0$, since $a, b &gt; 0$})\\\\ &amp;= \\begin{cases} 0 &amp; x &lt; a^2 \\\\ \\frac{\\sqrt{x} - a}{b - a} &amp; a^2 \\leq x \\leq b^2 \\\\ 1 &amp; x &gt; b^2 \\end{cases} \\\\ f_X(x) &amp;= \\frac{d}{dx} F_X(x) \\\\ &amp;= \\begin{cases} \\frac{1}{2(b-a)\\sqrt{x}} &amp; a^2 \\leq x \\leq b^2 \\\\ 0 &amp; \\text{otherwise} \\end{cases} \\end{align*}\\] Now that we have the p.d.f., we calculate the expected value using the definition (37.1). Note the limits of integration: \\[ E[X] = \\int_{a^2}^{b^2} x \\cdot \\frac{1}{2(b-a)\\sqrt{x}}\\,dx = \\frac{b^3 - a^3}{3(b-a)}. \\] Method 2 (Using LOTUS) LOTUS allows us to calculate the expected value of \\(X\\) without working out the p.d.f. of \\(X\\). All we need is the p.d.f. of \\(I\\), which we already have and is simple. \\[ E[X] = E[I^2] = \\int_a^b i^2 \\cdot \\frac{1}{b-a}\\,di = \\frac{i^{3}}{3} \\frac{1}{b-a} \\Big|_a^b = \\frac{b^3 - a^3}{3(b-a)}. \\] In fact, we did not use the fact that \\(a, b &gt; 0\\) at all in this calculation, so this formula is valid for all uniform distributions, not just uniform distributions on positive values. Example 38.2 (Expected Value of the Square of an Exponential) Continuing with the previous example, suppose that the current \\(I\\) instead follows an \\(\\text{Exponential}(\\lambda)\\) distribution. What is the expected power dissipated by the resistor? Again, we will use LOTUS. This is an unpleasant exercise in integration by parts. We simply set up the integral and use software to evaluate the integral. \\[ E[I^2] = \\int_0^\\infty i^2 \\cdot \\lambda e^{-\\lambda i}\\,di = \\frac{2}{\\lambda^2}. \\] Example 38.3 (Expected Value of a Cosine) Let \\(\\Theta\\) be a random angle, from a \\(\\text{Uniform}(-\\pi, \\pi)\\) distribution. Then, the p.d.f. of \\(\\Theta\\) is \\[ f(\\theta) = \\begin{cases} \\frac{1}{\\pi - (-\\pi)} &amp; -\\pi \\leq x \\leq \\pi \\\\ 0 &amp; \\text{otherwise} \\end{cases}, \\] and the expected value of the cosine is: \\[\\begin{align*} E[\\cos(\\Theta)] &amp;= \\int_{-\\pi}^\\pi \\cos(\\theta)\\cdot \\frac{1}{\\pi - (-\\pi)}\\,d\\theta \\\\ &amp;= \\frac{1}{2\\pi} \\sin\\theta \\Big|_{-\\pi}^\\pi \\\\ &amp;= \\frac{1}{2\\pi} (0 - 0) \\\\ &amp;= 0. \\end{align*}\\] Essential Practice You inflate a spherical balloon in a single breath. If the volume of air you exhale in a single breath (in cubic inches) is \\(\\text{Uniform}(a=36\\pi, b=288\\pi)\\) random variable, what is the expected radius of the balloon (in inches)? (Use LOTUS, but feel free to check your answer using the p.d.f. you derived in Lesson 36.) The distance (in hundreds of miles) driven by a trucker in one day is a continuous random variable \\(X\\) whose cumulative distribution function (c.d.f.) is given by: \\[ F(x) = \\begin{cases} 0 &amp; x &lt; 0 \\\\ x^3 / 216 &amp; 0 \\leq x \\leq 6 \\\\ 1 &amp; x &gt; 6 \\end{cases}. \\] Let the random variable \\(D\\) represent the time (in days) required for the trucker to make a 1500-mile trip, so \\(D = 15 / X\\). Calculate the expected value of \\(D\\). "],
["var-continuous.html", "Lesson 39 Variance of Continuous Random Variables Theory Essential Practice Additional Practice", " Lesson 39 Variance of Continuous Random Variables Theory The variance is defined for continuous random variables in exactly the same way as for discrete random variables, except the expected values are now computed with integrals and p.d.f.s, as in Lessons 37 and 38, instead of sums and p.m.f.s. Definition 39.1 (Variance) Let \\(X\\) be a random variable. Then, the variance of \\(X\\), symbolized \\(\\text{Var}[X]\\) is defined as \\[\\begin{equation} \\text{Var}[X] \\overset{\\text{def}}{=} E[(X - E[X])^2]. \\tag{39.1} \\end{equation}\\] The “shortcut formula” also works for continuous random variables. Theorem 39.1 (Shortcut Formula for Variance) The variance can also be computed as: \\[\\begin{equation} \\text{Var}[X] = E[X^2] - E[X]^2. \\tag{39.2} \\end{equation}\\] The standard deviation is also defined in the same way, as the square root of the variance, as a way to correct the units of variance.. \\[ \\text{SD}[X] = \\sqrt{\\text{Var}[X]}. \\] We apply the shortcut formula to derive formulas for the expected values of the uniform and exponential distributions. Example 39.1 (Variance of the Uniform Distribution) Let \\(X\\) be a \\(\\text{Uniform}(a, b)\\) random variable. We calculated \\(E[X]\\) in Example 37.1 and \\(E[X^2]\\) in Example 38.1, so most of the work has already been done. \\[\\begin{align*} \\text{Var}[X] &amp;= E[X^2] - E[X]^2 \\\\ &amp;= \\frac{b^3 - a^3}{3(b-a)} - \\left( \\frac{a + b}{2} \\right)^2 \\\\ &amp;= \\frac{(b-a)^2}{12} \\end{align*}\\] Example 39.2 (Variance of the Exponential Distribution) Let \\(X\\) be a \\(\\text{Exponential}(\\lambda)\\) random variable. We calculated \\(E[X]\\) in Example 37.2 and \\(E[X^2]\\) in Example 38.2, so most of the work has already been done. \\[\\begin{align*} \\text{Var}[X] &amp;= E[X^2] - E[X]^2 \\\\ &amp;= \\frac{2}{\\lambda^2} - \\left( \\frac{1}{\\lambda} \\right)^2 \\\\ &amp;= \\frac{1}{\\lambda^2} \\end{align*}\\] Formulas for the variance of named continuous distributions can be found in Appendix A.2. Essential Practice The distance (in hundreds of miles) driven by a trucker in one day is a continuous random variable \\(X\\) whose cumulative distribution function (c.d.f.) is given by: \\[ F(x) = \\begin{cases} 0 &amp; x &lt; 0 \\\\ x^3 / 216 &amp; 0 \\leq x \\leq 6 \\\\ 1 &amp; x &gt; 6 \\end{cases}. \\] Calculate the standard deviation of \\(X\\). What is the probability that \\(X\\) is within 1 standard deviation of the mean (i.e., expected value)? Small aircraft arrive at San Luis Obispo airport according to a Poisson process at a rate of 6 per hour. What is the expected value and standard deviation of the time between two arrivals (in hours)? What is the probability that the time between two arrivals will be more than 1 standard deviation above the mean (i.e., expected value)? Additional Practice The article “Modeling Sediment and Water Column Interactions for Hydrophobic Pollutants” (Water Res., 1984: 1169–1174) suggests the uniform distribution on the interval \\([7.5, 20]\\) as a model for depth (cm) of the bioturbation layer in sediment in a certain region. What are the mean and variance of depth? What is the probability that the observed depth is within 1 standard deviation of the expected value? "],
["normal.html", "Lesson 40 Normal Distribution Motivation Standard Normal Distribution (General) Normal Distribution Essential Practice", " Lesson 40 Normal Distribution Motivation The normal distribution is the most important distribution in all of probability and statistics. It is ubiquitous in the real world, as the above video demonstrates. The normal distribution goes by a few other names: Gaussian distribution (especially common in engineering) the bell curve (in everyday life) We will discuss the normal distribution in two stages: First, we will discuss the standard normal distribution. Then, we will discuss the general normal distribution, which has the same shape as the standard normal distribution, but with a different center and scale. Standard Normal Distribution Definition 40.1 (Standard Normal Distribution) A random variable \\(Z\\) is said to follow a standard normal distribution if its p.d.f. is \\[\\begin{equation} f(z) = \\frac{1}{\\sqrt{2\\pi}} e^{-z^2 / 2}. \\tag{40.1} \\end{equation}\\] The p.d.f. is non-zero for all real numbers \\(-\\infty &lt; z &lt; \\infty\\). It is conventional to use the letter \\(Z\\) for a standard normal random variable. The c.d.f. of the standard normal distribution is \\[\\begin{equation} \\Phi(x) \\overset{\\text{def}}{=} \\int_{-\\infty}^x f(t)\\,dt. \\tag{40.2} \\end{equation}\\] Note that it is conventional to use the Greek letter \\(\\Phi\\) (“phi”) for the standard normal c.d.f., instead of \\(F\\). There is no closed-form formula for \\(\\Phi\\), so we often leave our answers in terms of \\(\\Phi\\). If a numerical value is required, we have a few options: We can use numerical integration. We can use software that calculates normal probabilities. We can use tables of the normal c.d.f., like this one. The figure below shows the p.d.f. and c.d.f. of a standard normal distribution. Figure 40.1: PDF and CDF of the Standard Normal Distribution The Colab below shows how to use software to calculate probabilities involving a standard normal distribution. Theorem 40.1 (Expected Value and Variance of the Standard Normal) Let \\(Z\\) be a standard normal random variable. Then: \\[\\begin{align*} E[Z] &amp;= 0 &amp; \\text{Var}[Z] &amp;= 1 \\end{align*}\\] Proof. \\[\\begin{align*} E[Z] &amp;= \\int_{-\\infty}^\\infty z \\cdot \\frac{1}{\\sqrt{2\\pi}} e^{-z^2/2} \\\\ &amp;= -\\frac{1}{\\sqrt{2\\pi}} e^{-z^2/2} \\Big|_{-\\infty}^\\infty \\\\ &amp;= (-0 + 0) \\\\ &amp;= 0 \\\\ \\text{Var}[Z] &amp;= E[Z^2] - E[Z]^2 \\\\ &amp;= \\int_{-\\infty}^\\infty z^2 \\cdot \\frac{1}{\\sqrt{2\\pi}} e^{-z^2/2} - 0^2 \\\\ &amp;= 1 \\end{align*}\\] (General) Normal Distribution Definition 40.2 (Normal Distribution) A random variable \\(X\\) is said to follow a \\(\\text{Normal}(\\mu, \\sigma)\\) distribution if it can be expressed as \\[\\begin{equation} X = \\mu + \\sigma Z, \\tag{40.3} \\end{equation}\\] where \\(Z\\) is a standard normal random variable. Its p.d.f. is \\[\\begin{equation} f(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-( x - \\mu)^2 / 2 \\sigma^2}. \\tag{40.4} \\end{equation}\\] To derive this, apply Theorems 36.1 and 36.2 to (40.1). However, we almost never use this p.d.f. for calculations. Instead, we typically use the representation (40.3) to convert the distribution to a standard normal before doing any calculations. Note that the standard normal distribution is the \\(\\text{Normal}(\\mu=0, \\sigma=1)\\) distribution. Shown below are the p.d.f.s and c.d.f.s of normal distributions for different values of \\(\\mu\\) and \\(\\sigma\\). Notice that \\(\\mu\\) controls where the bell is centered, while \\(\\sigma\\) controls how wide it is. Figure 40.2: PDF and CDF of the Normal Distribution The next theorem shows that \\(\\mu\\) and \\(\\sigma\\) can be interpreted as the center and spread, respectively. Theorem 40.2 (Expected Value and Variance of the Normal) Let \\(X\\) be a \\(\\text{Normal}(\\mu, \\sigma)\\) random variable. Then: \\[\\begin{align*} E[X] &amp;= \\mu &amp; \\text{Var}[X] &amp;= \\sigma^2 \\end{align*}\\] so that \\(\\mu\\) and \\(\\sigma\\) represent the mean and standard deviation, respectively. Proof. The result follows by the representation (40.3) and properties of expected value and variance: \\[\\begin{align*} E[X] &amp;= E[\\mu + \\sigma Z] \\\\ &amp;= \\mu + \\sigma E[Z] \\\\ &amp;= \\mu \\\\ \\text{Var}[X] &amp;= \\text{Var}[\\mu + \\sigma Z] \\\\ &amp;= \\sigma^2 \\text{Var}[Z] \\\\ &amp;= \\sigma^2 \\end{align*}\\] By inverting (40.3), we see that \\[\\begin{equation} Z = \\frac{X - \\mu}{\\sigma} \\tag{40.5} \\end{equation}\\] follows a standard normal distribution. The process of converting a (general) normal random variable into a standard normal is known as standardization. One strategy for calculating probabilities from a normal distribution is to standardize and calculate the corresponding probability from the standard normal distribution. The case study below shows how to calculate probabilities from a normal distribution, using a combination of algebra and software. Essential Practice Based on extensive data from an urban freeway near Toronto, Canada, “it is assumed that free speeds can best be represented by a normal distribution” (“Impact of Driver Compliance on the Safety and Operational Impacts of Freeway Variable Speed Limit Systems,” J. of Transp. Engr., 2011: 260–268). The mean and standard deviation reported in the article were 119 km/h and 13.1 km/h, respectively. What is the probability that the speed of a randomly selected vehicle is between 100 and 120 km/h? What speed characterizes the fastest 10% of all speeds? If five vehicles are randomly and independently selected, what is the probability that at least one car is traveling under the posted speed limit of 100 km/h? Daily highs in San Luis Obispo in August are approximately normally distributed with a mean of \\(76.9^\\circ\\textrm{F}\\). The temperature exceeds 100 degrees Fahrenheit on about 1.5% of August days. What can you say about the standard deviation? Suppose the mean increases by 2 degrees Fahrenheit. By what (multiplicative) factor will the percentage of 100-degree days increase? (The moral of this exercise is: small changes in the mean can have massive effects on the tail probabilities.) Suppose that the wrapper of a certain candy bar lists its weight as 2.13 ounces. Naturally, the weights of individual bars vary somewhat. Suppose that the actual weights of these candy bars vary according to a normal distribution with mean \\(\\mu = 2.20\\) ounces and standard deviation \\(\\sigma = 0.04\\) ounces. What proportion of candy bars weigh less than the advertised weight? If the weights of candy bars are independent, what is the expected number of candy bars before you encounter one that weighs less than the advertised weight? If the manufacturer decides that it’s unacceptable to have so many candy bars weigh less than the advertised weight, they might want to adjust the production process so that only 1 candy bar in 1000 weighs less than advertised. What should the mean of the actual weights be (assuming that the standard deviation of the weights remains 0.04 ounces)? Is this more or less than before? Why does this makes sense? If the manufacturer does not want to add weight to the candy bars (because this costs money), an alternative is to adjust the SD of the weights in the production process. If the mean weight remains at 2.20 ounces but only 1 candy bar in 1000 weighs less than the advertised weight, how small does the standard deviation of the weights need to be? Is this smaller or larger than before? Why does this makes sense? Let \\(Z\\) be a standard normal random variable. Derive the p.d.f. of \\(X = e^Z\\). Sketch this p.d.f. Hint: This is a transformation, so you can use the method of Lesson 36. When calculating the c.d.f., leave your answer in terms of \\(\\Phi\\), the c.d.f. of the standard normal distribution. It does not have a closed-form expression, but you know its derivative. (What is the derivative of any c.d.f.?) (This distribution has a name: the log-normal distribution. This is a popular distribution for modeling random variables with long right tails, such as income. Hopefully, you can appreciate this if you sketch the p.d.f.) "],
["joint-continuous.html", "Lesson 41 Joint Continuous Distributions Theory Worked Examples Essential Practice Additional Practice", " Lesson 41 Joint Continuous Distributions Theory Definition 41.1 The joint distribution of two continuous random variables \\(X\\) and \\(Y\\) is described by their joint p.d.f. \\[\\begin{equation} f(x, y). \\tag{41.1} \\end{equation}\\] The joint p.d.f. is a surface over the \\(xy\\)-plane. To calculate the probability of an event \\(B\\), we integrate this joint p.d.f. over \\(B\\): \\[\\begin{equation} P((X, Y) \\in B) = \\underset{B}{\\iint} f(x, y)\\,dy\\,dx. \\tag{41.2} \\end{equation}\\] In other words, volumes under the joint p.d.f. surface represent probabilities. Figure 41.1: Joint Distributions of Continuous Random Variables The hardest part of calculating (41.2) is setting up the limits of integration. So we will often draw a bird’s-eye view of the \\(xy\\)-plane, ignoring the surface, to help us determine the limits of integration. Figure 41.2: Bird’s Eye View of the Event Above That’s all there is to the theory. The only way to get good at this is to brush up on your multivariable calculus and do many, many examples. Worked Examples Example 41.1 (Joint Distribution of the First and Second Arrival Times) In San Luis Obispo, radioactive particles reach a Geiger counter according to a Poisson process at a rate of \\(\\lambda = 0.8\\) particles per second. The time \\(X\\) that the first particle is detected and the time \\(Y\\) that the second particle is detected can be shown to have the joint p.d.f.: \\[ f(x, y) = \\begin{cases} 0.64 e^{-0.8 y} &amp; 0 &lt; x &lt; y \\\\ 0 &amp; \\text{otherwise} \\end{cases}. \\] This p.d.f. is non-zero when \\(0 &lt; x &lt; y\\). The region where the p.d.f. is non-zero is known as the support of the distribution. First, let’s note the following features of this p.d.f. The joint p.d.f. \\(f(x, y) = 0\\) when \\(x &gt; y\\). This makes sense physically. By definition, it is impossible for the first particle to be detected after the second particle. So the probability of this must be 0. The joint p.d.f. depends on both \\(x\\) and \\(y\\). Although the expression \\(0.64 e^{-0.8 y}\\) only depends on \\(y\\), the support \\(0 &lt; x &lt; y\\) makes this a function of both \\(x\\) and \\(y\\). Let’s calculate the probability that both arrivals happen between 1 and 2 seconds. That is, we want to calculate \\(P(1 &lt; X &lt; 2 \\text{ and } 1 &lt; Y &lt; 2)\\). We can obtain this probability by integrating this p.d.f. over the square \\([1, 2] \\times [1, 2]\\), shaded in blue in the bird’s-eye view below. Since the p.d.f. is zero, except on the support \\(\\{ y &gt; x \\}\\) (shaded in red in the figure above), we can just integrate the p.d.f. on the overlap between the blue square and the red support. The figure helps us determine the limits of integration. As \\(x\\) ranges from 1 to 2, \\(y\\) needs to range from \\(x\\) to 2, if we want to cover the entire triangle where the square and support overlap. \\[\\begin{align*} P(1 &lt; X &lt; 2 \\text{ and } 1 &lt; Y &lt; 2) &amp;= \\int_1^2 \\int_x^2 0.64 e^{-0.8 y}\\,dy\\,dx \\\\ &amp;\\approx .0859. \\end{align*}\\] After setting up the double integral, the integral was evaluated using Wolfram Alpha. You are encouraged to use software to evaluate integrals. However, software does not translate the real world problem into the integral you need to set up. That, for now, still has to be done by a human! Sometimes, the geometry is simple enough that we can calculate the volume without integrals. Example 41.2 (Actuarial Example) Two insurers provide bids on an insurance policy to a large company. The bids must be between 2000 and 2200. The company decides to accept the lower bid if the two bids differ by 20 or more. Otherwise, the company will consider the two bids further. Suppose the two bids \\(X\\) and \\(Y\\) are equally likely to be any of the allowable bids. That is, their joint p.d.f. \\[ f(x, y) = \\begin{cases} c &amp; 2000 &lt; x, y &lt; 2200 \\\\ 0 &amp; \\text{otherwise} \\end{cases}, \\] where \\(c\\) is a constant. What is the probability that the company considers the two bids further? Solution. First, we sketch a bird’s eye view of the joint p.d.f. The support of the distribution is the red square. The surface is a constant height above the square, so the total volume under it is \\[ (\\text{area of base}) \\cdot (\\text{height of surface}) = \\underbrace{(2200 - 2000)^2}_{40000} \\cdot c. \\] We know that the the total volume must be 1, which means that \\[ c = \\frac{1}{40000}. \\] Now, the company will consider the bids further if \\(X\\) is within 20 of \\(Y\\). That is, we want to calculate \\(P(|X - Y| &lt; 20)\\). Shaded in blue above are all points \\((x, y)\\) where \\(|x - y| &lt; 20\\). To calculate \\(P(| X - Y | &lt; 20)\\), we need to calculate the volume under the p.d.f. above the blue event. Since the blue event is nothing and the red support. This region is an irregular hexagon. But because the height of the p.d.f. is a constant \\(c = \\frac{1}{40000}\\), this volume is just \\[ (\\text{area of hexagon}) \\cdot (\\text{height of surface}) = (\\text{area of hexagon}) \\cdot \\frac{1}{40000}. \\] There are many ways to calculate the area of the hexagon, but the easiest is to take the area of the entire square, minus the area of the two triangles on either side. Each triangle has a base of 180 and a height of 180, so its area is \\(\\frac{1}{2} 180^2\\). \\[ (\\text{area of hexagon}) = (\\text{area of square}) - 2(\\text{area of triangle}) = 200^2 - 2(\\frac{1}{2} 180^2) = 7600. \\] So the probability is \\[ P(|X - Y| &lt; 20) = 7600 \\cdot \\frac{1}{40000} = .19. \\] The video below explains this problem. In general, if the joint p.d.f. is constant on its support, as in Example 41.2, then the it is easier to calculate probabilities using geometry rather than calculus. However, if the joint p.d.f. is not constant, as in Example 41.1, then calculus is necessary. Essential Practice Alice and Bob meet for lunch every day at a random time between noon and 1 P.M. Bob always arrives after Alice, but otherwise, they are equally likely to arrive at any time. The joint p.d.f. of \\(X\\), the time Alice arrives (in minutes after 12 P.M.), and \\(Y\\), the time Bob arrives (in minutes after 12 P.M.), is given by \\[ f(x, y) = \\begin{cases} c &amp; 0 \\leq x &lt; y \\leq 60 \\\\ 0 &amp; \\text{otherwise} \\end{cases}, \\] where \\(c\\) is a constant. Sketch a birds-eye view of the joint p.d.f. Because the p.d.f. is constant, you should be able to calculate all probabilities using geometry, rather than integration. Determine the value of \\(c\\) that makes this a valid joint p.d.f. Calculate the probability that Bob arrives more than 25% later than Alice. That is, what is \\(P(Y &gt; 1.25 X)\\)? (Sketch a picture of this region.) Suppose \\(X\\) and \\(Y\\) are continuous random variables with joint p.d.f. \\(f(x, y)\\). What is \\(P(X = Y)\\) and why? Additional Practice An ecologist selects a point inside a circular sampling region according to a uniform distribution. Let \\(X\\) be the \\(x\\)-coordinate of the point selected and \\(Y\\) be the \\(y\\)-coordinate of the point selected. If the circle is centered at \\((0, 0)\\) and has radius \\(r\\), then the joint pdf of \\(X\\) and \\(Y\\) is \\[ f(x, y) = \\begin{cases} c &amp; x^2 + y^2 \\leq r^2 \\\\ 0 &amp; \\text{otherwise} \\end{cases}. \\] Determine the value of \\(c\\) that makes this a valid joint p.d.f. What is the probability that the selected point is within \\(r/2\\) of the center of the circular region? (Hint: Use geometry.) What is the probability that both \\(X\\) and \\(Y\\) differ from 0 by at most \\(r/2\\)? A company produces cans of mixed nuts containing almonds, cashews, and peanuts. Each can is exactly 1 lb, but the amount of each type of nut is random. The joint p.d.f. of \\(X\\), the amount of almonds, and \\(Y\\), the amount of cashews, is \\[ f(x, y) = \\begin{cases} 24xy &amp; 0 \\leq x \\leq 1, 0 \\leq y \\leq 1, x + y \\leq 1 \\\\ 0 &amp; \\textrm{otherwise} \\end{cases}. \\] Show that the probability there are more almonds than cashews is \\(0.5\\). "],
["marginal-continuous.html", "Lesson 42 Marginal Continuous Distributions Motivating Example Theory Essential Practice", " Lesson 42 Marginal Continuous Distributions Motivating Example In Lesson 40 on the normal distribution, we saw that there is no closed-form expression for the antiderivative \\[ \\int ce^{-z^2/2}\\,dz, \\] where \\(c\\) is a constant. The definite integral must be computed numerically. This means that we can compute the integral to any precision we like, but exact values are, in general, impossible. How, then, can we be sure that the constant \\(c\\) must be \\(1 / \\sqrt{2\\pi}\\) for the total probability to be 1? That is, \\[\\begin{equation} \\int_{-\\infty}^\\infty \\frac{1}{\\sqrt{2\\pi}} e^{-z^2/2}\\,dz = 1. \\tag{42.1} \\end{equation}\\] Using numerical integration, we might be able to figure out that \\(c \\approx .3989423\\) (or as many decimal places as desired), but how do we know it is \\(1 / \\sqrt{2\\pi}\\) exactly? It turns out that the definite integral (42.1) can be evaluated exactly, but to see this, we need to use joint distributions. Theory The definition for the marginal p.d.f. mirrors the definition of the marginal p.m.f. for discrete distributions 19.1, except with sums replaced by integrals and the joint p.m.f. replaced by the joint p.d.f. Definition 42.1 (Marginal Distribution) Suppose we have the joint p.d.f. \\(f(x, y)\\) of two continuous random variables \\(X\\) and \\(Y\\). The marginal p.d.f. of \\(X\\) is the p.d.f. of \\(X\\) alone and is obtained by integrating the joint p.d.f. over all the values of \\(Y\\). \\[\\begin{equation} f_X(x) = \\int_{-\\infty}^\\infty f(x, y)\\,dy \\tag{42.2} \\end{equation}\\] Likewise, the marginal p.d.f. of \\(Y\\) is the p.d.f. of \\(Y\\) alone and is obtained by integrating the joint p.d.f. over all the values of \\(X\\). \\[\\begin{equation} f_Y(y) = \\int_{-\\infty}^\\infty f(x, y)\\,dx. \\tag{42.3} \\end{equation}\\] If \\(X\\) and \\(Y\\) are independent, then their joint p.d.f. is the product of their marginal p.d.f.s, just like it was for discrete random variables (Theorem 19.1): Theorem 42.1 (Joint Distribution of Independent Random Variables) If \\(X\\) and \\(Y\\) are independent, then \\[\\begin{equation} f(x, y) = f_X(x) \\cdot f_Y(y) \\end{equation}\\] for all values \\(x\\) and \\(y\\). But only if \\(X\\) and \\(Y\\) are independent! In the following examples, we construct the joint p.d.f. of two independent random variables \\(X\\) and \\(Y\\) using Theorem 42.1. Then, we integrate the joint p.d.f. to obtain probabilities, as usual. Example 42.1 (Symmetry of Continuous Random Variables) The lifetimes of two lightbulbs, \\(X\\) and \\(Y\\), are independent \\(\\text{Exponential}(\\lambda)\\) random variables. What is the probability the second lightbulb lasts longer than the first, \\(P(Y &gt; X)\\)? First, we write down the joint p.d.f. using Theorem 42.1: \\[ f(x, y) = \\begin{cases} \\lambda e^{-\\lambda x} \\cdot \\lambda e^{-\\lambda y} &amp; x, y \\geq 0 \\\\ 0 &amp; \\text{otherwise} \\end{cases}. \\] Now, we just need to integrate this p.d.f. over the region where \\(y &gt; x\\). We sketch a bird’s-eye view below. Now we integrate over the above region: \\[\\begin{align*} P(Y &gt; X) &amp;= \\int_0^\\infty \\int_x^\\infty \\lambda^2 e^{-\\lambda x - \\lambda y}\\,dy\\,dx \\\\ &amp;= \\int_0^\\infty \\lambda e^{-\\lambda x} \\underbrace{\\int_x^\\infty \\lambda e^{-\\lambda y}\\,dy}_{e^{-\\lambda x}}\\,dx \\\\ &amp;= \\int_0^\\infty \\lambda e^{-\\lambda x} e^{-\\lambda x}\\,dx \\\\ &amp;= \\int_0^\\infty \\lambda e^{-2\\lambda x}\\,dx \\\\ &amp;= \\frac{1}{2}. \\end{align*}\\] (One way to see the last equality is to recognize \\(f(x) = 2 \\lambda e^{-2\\lambda x}; x &gt; 0\\) as the p.d.f. of an \\(\\text{Exponential}(2\\lambda)\\) distribution, so we multiply and divide by \\(2\\) to make the integrand match this p.d.f., which then must integrate to 1.) In hindsight, the probability has to be \\(1/2\\) by symmetry. We know that either \\(X &gt; Y\\) or \\(X &lt; Y\\), since the probability that \\(X = Y\\) (i.e., the two lightbulbs have exactly the same lifetime) is zero. Because \\(X\\) and \\(Y\\) are independent with the same distribution, there is no reason for one to be preferred over another, so \\(P(X &gt; Y) = P(X &lt; Y) = \\frac{1}{2}\\). In fact, by the exact same argument, this is true for all independent and identically distributed (i.i.d.) continuous random variables with a joint p.d.f. ``` The last example answers the question posed at the beginning of this lesson. Example 42.2 (The Gaussian Integral) The p.d.f. of a standard normal random variable \\(Z\\) is \\[ f(z) = c e^{-z^2/2}, \\] where \\(c\\) is a constant to make the p.d.f. integrate to 1. Surprisingly, the easiest way to determine \\(c\\) is to define two independent standard normal random variables \\(X\\) and \\(Y\\), and use the fact that their joint p.d.f. must integrate to 1. By Theorem 42.1, the joint p.d.f. of \\(X\\) and \\(Y\\) is \\[ f(x, y) = ce^{-x^2 /2} \\cdot ce^{-y^2 / 2} = c^2 e^{-(x^2 + y^2) / 2}. \\] We know from Lesson 41 that the total volume under any joint p.d.f. must be 1: \\[ 1 = \\int_{-\\infty}^\\infty \\int_{-\\infty}^\\infty f(x, y)\\,dx\\,dy = \\int_{-\\infty}^\\infty \\int_{-\\infty}^\\infty c^2 e^{-(x^2 + y^2) / 2}\\,dx\\,dy. \\] Surprisingly, this double integral can be evaluated (even though the single integral could not). To evaluate the double integral, we convert to polar coordinates, using the substitutions \\(r^2 = x^2 + y^2\\) and \\(dx\\,dy = r\\,dr\\,d\\theta\\): \\[\\begin{align*} c^2 \\int_{-\\infty}^\\infty \\int_{-\\infty}^\\infty e^{-(x^2 + y^2) / 2}\\,dx\\,dy &amp;= c^2 \\int_{0}^{2\\pi} \\int_{0}^\\infty e^{-r^2 / 2} r\\,dr\\,d\\theta \\\\ &amp;= c^2 \\int_0^{2\\pi} \\underbrace{\\int_0^\\infty e^{-u}\\,du}_{1} \\,d\\theta &amp; \\text{(using $u=r^2/2$)} \\\\ &amp;= c^2 (2\\pi). \\end{align*}\\] Setting this equal to 1, we see that \\(c^2 = \\frac{1}{2\\pi}\\). In other words, \\(c = \\frac{1}{\\sqrt{2\\pi}}\\). Essential Practice Let \\(X\\) and \\(Y\\) be continuous random variables with joint p.d.f. \\[ f(x, y) = \\begin{cases} \\frac{1}{12} (1 + \\frac{1}{18}(x - 2)(2y - 3)) &amp; 0 &lt; x &lt; 4, 0 &lt; y &lt; 3 \\\\ 0 &amp; \\text{otherwise} \\end{cases}. \\] Find the marginal p.d.f.s of \\(X\\) and \\(Y\\). Are these named distributions? (Feel free to set up and the integral and use Wolfram Alpha to do the rest.) Are \\(X\\) and \\(Y\\) independent? (Hint: According to Theorem 42.1, what would their joint p.d.f. have to be if they were independent?) Harry and Sally independently go to Katz’s Deli for lunch on weekdays from their respective jobs. Let \\(H\\) be the time that Harry arrives and \\(S\\) be the time that Sally arrives (in minutes after 12 p.m.). \\(H\\) and \\(S\\) are independent \\(\\text{Uniform}(a=0, b=90)\\) random variables. What is the joint p.d.f. of \\(H\\) and \\(S\\)? Sketch a bird’s-eye view of the joint p.d.f. If they each take 20 minutes to eat their lunch after they arrive, what is the probability that Harry meets Sally…? (Hint: The two are able to meet if they arrive within 20 minutes of each other. Sketch the region of times that correspond to Harry and Sally meeting. You can calculate this probability by geometry, without using integration.) What is the probability that Harry arrives after Sally arrives? "],
["ev-joint-continuous.html", "Lesson 43 Expectations of Joint Continuous Distributions Theory Essential Practice", " Lesson 43 Expectations of Joint Continuous Distributions Theory This lesson collects a number of results about expected values of two (or more) continuous random variables. All of these results are directly analogous to the results for discrete random variables, except with sums replaced by integrals and the joint p.m.f. replaced by the joint p.d.f. Theorem 43.1 (2D LOTUS) Let \\(X\\) and \\(Y\\) be continuous random variables with joint p.d.f. \\(f(x, y)\\). Let \\(g\\) be some function. Then, \\[\\begin{equation} E[g(X, Y)] = \\int_{-\\infty}^\\infty \\int_{-\\infty}^\\infty g(x, y) \\cdot f(x, y)\\,dx\\,dy. \\tag{43.1} \\end{equation}\\] Compare this result with Theorem 25.1. Example 43.1 Two points are chosen uniformly and independently along a stick of length 1. What is the expected distance between those two points? Let \\(X\\) and \\(Y\\) be the two points that are chosen. The joint p.d.f. of \\(X\\) and \\(Y\\) is \\[ f(x, y) = \\begin{cases} 1 &amp; 0 &lt; x, y &lt; 1 \\\\ 0 &amp; \\text{otherwise} \\end{cases}. \\] We are interested in \\(E[|X - Y|]\\). By 2D LOTUS, this is \\[\\begin{align*} E[|X-Y|] &amp;= \\int_0^1 \\int_0^1 |x-y| \\cdot 1 \\,dx\\,dy \\\\ &amp;= \\iint_{x \\geq y} (x - y)\\,dx\\,dy + \\iint_{y &gt; x} (y - x)\\,dx\\,dy \\\\ &amp;= \\int_0^1 \\int_y^1 (x - y)\\,dx\\,dy + \\int_0^1 \\int_0^y (y - x)\\,dx\\,dy \\\\ &amp;= \\frac{1}{3}. \\end{align*}\\] Theorem 43.2 (Expected Value of a Product) If \\(X\\) and \\(Y\\) are independent random variables, then \\[\\begin{equation} E[XY] = E[X] E[Y]. \\end{equation}\\] In fact, if \\(X\\) and \\(Y\\) are independent, then for any functions \\(g\\) and \\(h\\), \\[\\begin{equation} E[g(X)h(Y)] = E[g(X)] E[h(Y)]. \\end{equation}\\] Compare this result with Theorem 27.1. Proof. \\[\\begin{align*} E[XY] &amp;= \\int_{-\\infty}^\\infty \\int_{-\\infty}^\\infty xy f(x, y)\\,dx\\,dy &amp; \\text{(by 2D LOTUS)} \\\\ &amp;= \\int_{-\\infty}^\\infty \\int_{-\\infty}^\\infty xy f_X(x) f_Y(y)\\,dx\\,dy &amp; \\text{(by independence)} \\\\ &amp;= \\int_{-\\infty}^\\infty y f_Y(y) \\underbrace{\\int_{-\\infty}^\\infty x f_X(x) \\,dx}_{E[X]}\\,dy \\\\ &amp;= E[X] E[Y]. \\end{align*}\\] Example 43.2 (Expected Power) Suppose a resistor is chosen uniformly at random from a box containing 1 ohm, 2 ohm, and 5 ohm resistor, and connected to live wire carrying a current (in Amperes) is an \\(\\text{Exponential}(\\lambda=0.5)\\) random variable, independent of the resistor. If \\(R\\) is the resistance of the chosen resistor and \\(I\\) is the current flowing through the circuit, then the power dissipated by the resitor is \\(P = I^2 R\\). What is the expected power? The expectation \\(E[P] = E[I^2 R]\\) involves two random variables, so in principle, we have to use 2D LOTUS. However, because \\(I\\) and \\(R\\) are independent, we can use Theorem 43.2 to simplify the expected value and avoid double sums and integrals. \\[\\begin{align*} E[P] &amp;= E[I^2 R] = E[I^2] E[R]. \\end{align*}\\] At this point, we cannot break up the expected value any further. However, \\(E[I^2]\\) and \\(E[R]\\) only involve one random variable. To calculate \\(E[I^2]\\), we can use LOTUS (38.1), or we can rearrange the shortcut formula for variance (39.2) to obtain \\[ E[I^2] = \\text{Var}[I] + E[I]^2 = \\frac{1}{0.5^2} + \\left(\\frac{1}{0.5} \\right)^2 = \\frac{2}{0.5^2} = 8. \\] (Note that we used the formulas for the expectation and variance of the exponential distribution.) To calculate \\(E[R]\\), we use the fact that the three resistors are equally likely to be chosen, so this is a discrete random variable: \\[ E[R] = 1 \\cdot \\frac{1}{3} + 2 \\cdot \\frac{1}{3} + 5 \\cdot \\frac{1}{3} = \\frac{8}{3} \\] Putting it all together, we see that \\[ E[P] = E[I^2] E[R] = 8 \\cdot \\frac{8}{3} = \\frac{64}{3}. \\] Theorem 43.3 (Linearity of Expectation) Let \\(X\\) and \\(Y\\) be continuous random variables. Then, no matter what their joint distribution is, \\[\\begin{equation} E[X+Y] = E[X] + E[Y]. \\end{equation}\\] Compare this result with Theorem 26.2. Proof. Since \\(E[X + Y]\\) involves two random variables, we have to evaluate the expectation using 2D LOTUS (43.1), with \\(g(x, y) = x + y\\). Suppose that the joint distribution of \\(X\\) and \\(Y\\) is \\(f(x, y)\\). Then: \\[\\begin{align*} E[X + Y] &amp;= \\int_{-\\infty}^\\infty \\int_{-\\infty}^\\infty(x + y) f(x, y)\\,dx\\,dy &amp; \\text{(2D LOTUS)} \\\\ &amp;= \\int_{-\\infty}^\\infty \\int_{-\\infty}^\\infty x f(x, y)\\,dy\\,dx + \\int_{-\\infty}^\\infty \\int_{-\\infty}^\\infty y f(x, y)\\,dx\\,dy &amp; \\text{(break $(x + y) f(x, y)$ into $x f(x, y) + y f(x, y)$)} \\\\ &amp;= \\int_{-\\infty}^\\infty x \\int_{-\\infty}^\\infty f(x, y)\\,dy\\,dx + \\int_{-\\infty}^\\infty y \\int_{-\\infty}^\\infty f(x, y)\\,dx\\,dy &amp; \\text{(move term outside the inner sum)} \\\\ &amp;= \\int_{-\\infty}^\\infty x f_X(x)\\,dx + \\int_{-\\infty}^\\infty y f_Y(y)\\,dy &amp; \\text{(definition of marginal distribution)} \\\\ &amp;= E[X] + E[Y] &amp; \\text{(definition of expected value)}. \\end{align*}\\] Example 43.3 (Expected Arrival Times) In San Luis Obispo, radioactive particles reach a Geiger counter according to a Poisson process at a rate of \\(\\lambda = 0.8\\) particles per second. What is the expected time that the \\(r\\)th particle hits the detector? Recall from Theorem 35.2 that the interarrival times (i.e., times between arrivals) are independent \\(\\text{Exponential}(\\lambda=0.8)\\) random variables, \\(T_i\\). Then, the time of the \\(r\\)th arrival is the sum of the first \\(r\\) interarrival times: \\[ S_r = T_1 + T_2 + \\ldots + T_r. \\] By linearity of expectation (and the formula for the expectation of the exponential distribution), the expected time of the \\(r\\)th arrival is \\[\\begin{align*} E[S_r] &amp;= E[T_1] + E[T_2] + \\ldots + E[T_r] \\\\ &amp;= \\frac{1}{0.8} + \\frac{1}{0.8} + \\ldots + \\frac{1}{0.8} \\\\ &amp;= \\frac{r}{0.8}. \\end{align*}\\] The expected value increases with \\(r\\), which makes intuitive sense. We should expect to wait longer for the 10th arrival than the 2nd arrival. Essential Practice The magnetizing force \\(H\\) at a point \\(P\\), which is \\(X\\) meters from a wire carrying a current \\(I\\) (in Amperes), is given by \\(H = 2I / X\\). (See the figure above. This follows from the Biot-Savart Law.) Suppose that the point \\(P\\) is chosen randomly so that \\(X\\) is a continuous random variable uniformly distributed over \\((3, 5)\\). Assume that the current \\(I\\) is also a continuous random variable, uniformly distributed over \\((10, 20)\\). Suppose, in addition, that the random variables \\(X\\) and \\(I\\) are independent. Find the expected magnetizing force \\(E[H]\\). (Hint: Use independence so that you do not have do any double integrals.) Let \\(A\\) be a \\(\\text{Exponential}(\\lambda=1.5)\\) random variable, and let \\(\\Theta\\) be a \\(\\text{Uniform}(a=-\\pi, b=\\pi)\\) random variable. Assume \\(A\\) and \\(\\Theta\\) are independent. Let \\(s, t\\) be constants, so your answers may depend on \\(s, t\\). Calculate: \\(E[A \\cos(\\Theta + 2\\pi t)]\\) \\(E[A^2 \\cos^2(\\Theta + 2\\pi t)]\\) \\(E[A^2 \\cos(\\Theta + 2\\pi s)\\cos(\\Theta + 2\\pi t)]\\) (Feel free to set up the integrals and use Wolfram Alpha.) (These calculations will come in handy later in the course.) In a standby system, a component is used until it wears out and is then immediately replaced by another, not necessarily identical, component. (The second component is said to be “in standby mode,” i.e., waiting to be used.) The overall lifetime of a standby system is just the sum of the lifetimes of its individual components. Let \\(X\\) and \\(Y\\) denote the lifetimes of the two components of a standby system, and suppose \\(X\\) and \\(Y\\) are independent exponentially distributed random variables with expected lifetimes 3 weeks and 4 weeks, respectively. Let \\(T = X + Y\\), the lifetime of the standby system. What is the expected lifetime of the system? "],
["cov-continuous.html", "Lesson 44 Covariance of Continuous Random Variables Theory Essential Practice", " Lesson 44 Covariance of Continuous Random Variables Theory This lesson summarizes results about the covariance of continuous random variables. The statements of these results are exactly the same as for discrete random variables, but keep in mind that the expected values are now computed using integrals and p.d.f.s, rather than sums and p.m.f.s. Definition 44.1 (Covariance) Let \\(X\\) and \\(Y\\) be random variables. Then, the covariance of \\(X\\) and \\(Y\\), symbolized \\(\\text{Cov}[X, Y]\\) is defined as \\[\\begin{equation} \\text{Cov}[X, Y] \\overset{\\text{def}}{=} E[(X - E[X])(Y - E[Y])]. \\end{equation}\\] Theorem 44.1 (Shortcut Formula for Covariance) The covariance can also be computed as: \\[\\begin{equation} \\text{Cov}[X, Y] = E[XY] - E[X]E[Y]. \\tag{44.1} \\end{equation}\\] Example 44.1 (Covariance Between the First and Second Arrival Times) In Example 41.1, we saw that the joint distribution of the first arrival time \\(X\\) and the second arrival time \\(Y\\) in a Poisson process of rate \\(\\lambda = 0.8\\) is \\[ f(x, y) = \\begin{cases} 0.64 e^{-0.8 y} &amp; 0 &lt; x &lt; y \\\\ 0 &amp; \\text{otherwise} \\end{cases}. \\] What is the covariance between \\(X\\) and \\(Y\\)? Intuitively, we expect the covariance to be positive. The longer it takes for the first arrival to happen, the longer we will have to wait for the second arrival, since the second arrival has to happen after the first arrival. Let’s calculate the exact value of the covariance using the shortcut formula (44.1). First, we need to calculate \\(E[XY]\\). We do this using 2D LOTUS (43.1). If \\(S = \\{ (x, y): 0 &lt; x &lt; y \\}\\) denotes the support of the distribution, then \\[\\begin{align*} E[XY] &amp;= \\iint_S xy \\cdot 0.64 e^{-0.8 y}\\,dx\\,dy \\\\ &amp;= \\int_0^\\infty \\int_0^y xy \\cdot 0.64 e^{-0.8 y}\\,dx\\,dy \\\\ &amp;= \\frac{75}{16}. \\end{align*}\\] What about \\(E[X]\\)? We know that the first arrival follows an \\(\\text{Exponential}(\\lambda=0.8)\\) distribution, so its expected value is \\(1/\\lambda = 1/0.8\\) seconds. What about \\(E[Y]\\)? We showed in Example 43.3 that the \\(r\\)th arrival is expected to happen at \\(r / 0.8\\) seconds (by linearity of expectation, since the \\(r\\)th arrival is the sum of the \\(r\\) \\(\\text{Exponential}(\\lambda=0.8)\\) interarrival times). Therefore, the secon arrival is expected to happen at \\(E[Y] = 2 / 0.8\\) seconds. Putting everything together, we have \\[ \\text{Cov}[X, Y] = E[XY] - E[X]E[Y] = \\frac{75}{16} - \\frac{1}{0.8} \\cdot \\frac{2}{0.8} = 1.5625. \\] Theorem 44.2 (Properties of Covariance) Let \\(X, Y, Z\\) be random variables, and let \\(c\\) be a constant. Then: Covariance-Variance Relationship: \\(\\displaystyle\\text{Var}[X] = \\text{Cov}[X, X]\\) (This was also Theorem 29.1.) Pulling Out Constants: \\(\\displaystyle\\text{Cov}[cX, Y] = c \\cdot \\text{Cov}[X, Y]\\) \\(\\displaystyle\\text{Cov}[X, cY] = c \\cdot \\text{Cov}[X, Y]\\) Distributive Property: \\(\\displaystyle\\text{Cov}[X + Y, Z] = \\text{Cov}[X, Z] + \\text{Cov}[Y, Z]\\) \\(\\displaystyle\\text{Cov}[X, Y + Z] = \\text{Cov}[X, Y] + \\text{Cov}[X, Z]\\) Symmetry: \\(\\displaystyle\\text{Cov}[X, Y] = \\text{Cov}[Y, X]\\) Constants cannot covary: \\(\\displaystyle\\text{Cov}[X, c] = 0\\). Example 44.2 Here is an easier way to do Example 44.1, using properties of covariance. Write \\(Y = X + Z\\), where \\(Z\\) is the time between the first and second arrivals. We know that \\(Z\\) is \\(\\text{Exponential}(\\lambda=0.8)\\) and independent of \\(X\\), so \\(\\text{Cov}[X, Z] = 0\\). Now, we have \\[\\begin{align*} \\text{Cov}[X, Y] &amp;= \\text{Cov}[X, X + Z] = \\underbrace{\\text{Cov}[X, X]}_{\\text{Var}[X]} + \\underbrace{\\text{Cov}[X, Z]}_0 = \\frac{1}{0.8^2} = 1.5625, \\end{align*}\\] where in the last step we used the fact that the variance of an \\(\\text{Exponential}(\\lambda)\\) random variable is \\(1/\\lambda^2\\). This matches the answer we got in Example 44.1, but it required much less calculation. Example 44.3 (Standard Deviation of Arrival Times) In Example 43.3, we saw that the expected value of the \\(r\\)th arrival time in a Poisson process of rate \\(\\lambda=0.8\\) is \\(r / 0.8\\). What is the standard deviation of the \\(r\\)th arrival time? The \\(r\\)th arrival time \\(S_r\\) is the sum of \\(r\\) independent \\(\\text{Exponential}(\\lambda=0.8)\\) random variables: \\[ S_r = T_1 + T_2 + \\ldots + T_r. \\] By properties of covariance: \\[\\begin{align*} \\text{Var}[S_r] &amp;= \\text{Cov}[S_r, S_r] \\\\ &amp;= \\text{Cov}[T_1 + T_2 + \\ldots + T_r, T_1 + T_2 + \\ldots + T_r] \\\\ &amp;= \\sum_{i=1}^r \\underbrace{\\text{Cov}[T_i, T_i]}_{\\text{Var}[T_i]} + \\sum_{i\\neq j} \\underbrace{\\text{Cov}[T_i, T_j]}_0 \\\\ &amp;= r \\text{Var}[T_1] \\\\ &amp;= r \\frac{1}{0.8^2}. \\end{align*}\\] Therefore, the standard deviation is \\[ \\text{SD}[S_r] = \\frac{\\sqrt{r}}{0.8}. \\] Essential Practice Let \\(A\\) be a \\(\\text{Exponential}(\\lambda=1.5)\\) random variable, and let \\(\\Theta\\) be a \\(\\text{Uniform}(a=-\\pi, b=\\pi)\\) random variable. What is \\(\\text{Cov}[A\\cos(\\Theta + 2\\pi s), A\\cos(\\Theta + 2\\pi t)]\\)? In a standby system, a component is used until it wears out and is then immediately replaced by another, not necessarily identical, component. (The second component is said to be “in standby mode,” i.e., waiting to be used.) The overall lifetime of a standby system is just the sum of the lifetimes of its individual components. Let \\(X\\) and \\(Y\\) denote the lifetimes of the two components of a standby system, and suppose \\(X\\) and \\(Y\\) are independent exponentially distributed random variables with expected lifetimes 3 weeks and 4 weeks, respectively. Let \\(T = X + Y\\), the lifetime of the standby system. What is the standard deviation of the lifetime of the system? Let \\(U_1, U_2, ..., U_n\\) be independent and identically distributed (i.i.d.) \\(\\text{Uniform}(a=0, b=1)\\) random variables. Let \\(S_n = U_1 + ... + U_n\\) denote their sum. Calculate \\(E[S_n]\\) and \\(\\text{SD}[S_n]\\) in terms of \\(n\\). "],
["sums-continuous.html", "Lesson 45 Sums of Continuous Random Variables Theory Essential Practice", " Lesson 45 Sums of Continuous Random Variables Theory Let \\(X\\) and \\(Y\\) be independent continuous random variables. What is the distribution of their sum— that is, the random variable \\(T = X + Y\\)? In Lesson 21, we saw that for discrete random variables, we convolve their p.m.f.s. In this lesson, we learn the analog of this result for continuous random variables. Theorem 45.1 (Sum of Independent Random Variables) Let \\(X\\) and \\(Y\\) be independent continuous random variables. Then, the p.d.f. of \\(T = X + Y\\) is the convolution of the p.d.f.s of \\(X\\) and \\(Y\\): \\[\\begin{equation} f_T = f_X * f_Y. \\tag{45.1} \\end{equation}\\] The convolution operator \\(*\\) in (45.1) is defined as follows: \\[ f_T(t) = \\int_{-\\infty}^\\infty f_X(x) \\cdot f_Y(t-x)\\,dx. \\] Note that the verb form of “convolution” is convolve, not “convolute”, even though many students find convolution quite convoluted! Comparing this with Theorem 21.1, we see once again that the only difference between the discrete case and the continuous case is that sums are replaced by integrals and p.m.f.s by p.d.f.s. Proof. Since \\(T\\) is a continuous random variable, we find its c.d.f. and take derivatives. Let \\(f\\) denote the joint distribution of \\(X\\) and \\(Y\\). We know that \\(f(x, y)\\) factors as \\(f_X(x)\\cdot f_Y(y)\\) by Theorem 42.1, since \\(X\\) and \\(Y\\) are independent. \\[\\begin{align*} F_T(t) = P(T \\leq t) &amp;= P(X + Y \\leq t) \\\\ &amp;= \\int_{-\\infty}^\\infty \\int_{-\\infty}^{t-x} f(x, y) \\,dy\\,dx \\\\ &amp;= \\int_{-\\infty}^\\infty \\int_{-\\infty}^{t-x} f_X(x) \\cdot f_Y(y) \\,dy\\,dx \\\\ &amp;= \\int_{-\\infty}^\\infty f_X(x) \\int_{-\\infty}^{t-x} f_Y(y) \\,dy\\,dx \\\\ &amp;= \\int_{-\\infty}^\\infty f_X(x) F_Y(t-x) \\,dx, \\end{align*}\\] where in the last step, we used the definition of the c.d.f. of \\(Y\\). (We are calculating the area under the p.d.f. of \\(Y\\) up to \\(t-x\\).) Now, we take the derivative with respect to \\(t\\). The integral behaves like a sum, so we can move the derivative inside the integral sign. Also, \\(f_X(x)\\) is a constant with respect to \\(t\\). \\[\\begin{align*} \\frac{d}{dt} F_T(t) &amp;= \\int_{-\\infty}^\\infty f_X(x) \\frac{d}{dt} F_Y(t-x) \\,dx \\\\ &amp;= \\int_{-\\infty}^\\infty f_X(x) f_Y(t-x) \\,dx, \\end{align*}\\] as we wanted to show. Example 45.1 (Sum of Independent Uniforms) Let \\(X\\) and \\(Y\\) be independent \\(\\text{Uniform}(a=0, b=1)\\) random variables. What is the p.d.f. of \\(T = X + Y\\)? We have to convolve the p.d.f. of \\(X\\) with the p.d.f. of \\(Y\\). The p.d.f.s of both \\(X\\) and \\(Y\\) are \\[ f(x) = \\begin{cases} 1 &amp; 0 &lt; x &lt; 1 \\\\ 0 &amp; \\text{otherwise} \\end{cases}. \\] This is a rectangle function. To calculate the convolution, we first flip \\(f_Y\\) about the \\(y\\)-axis. We then integrate the product of \\(f_X\\) and the flipped version of \\(f_Y\\) to obtain the convolution at \\(t=0\\). In this case, the two functions are never both non-zero, so the integral is 0. Now, to get the convolution at \\(t\\), we shift the flipped version of \\(f_Y\\) to the right by \\(t\\). This is why the convolution operation is often called “flip and shift”. To see why, consider the formula when we flip and shift \\(f_Y\\): \\[\\begin{align*} \\text{FLIP}[f_Y](x) &amp;= f_Y(-x) \\\\ \\text{SHIFT}_t[\\text{FLIP}[f_Y]](x) &amp;= \\text{FLIP}[f_Y](x - t) \\\\ &amp;= f_Y(-(x - t)) \\\\ &amp;= f_Y(t - x). \\\\ \\end{align*}\\] This is exactly the term that we multiply by \\(f_X(x)\\) in the convolution formula (45.1) before integrating. For the uniform distribution, there are two cases. If we shift (the flipped version of \\(f_Y\\)) by some amount \\(0 &lt; t &lt; 1\\), then the supports of the two distributions overlap between \\(0\\) and \\(t\\), so the result of the convolution is \\[ f_T(t) = \\int_0^t 1 \\cdot 1\\,dx = t. \\] On the other hand, if we shift by some amount \\(1 &lt; t &lt; 2\\), then the supports of the two distributions overlap between \\(t-1\\) and \\(1\\), so the result of the convolution is \\[ f_T(t) = \\int_{t-1}^1 1 \\cdot 1\\,dx = 2 - t. \\] Putting it all together, the formula for the p.d.f. is given by \\[ f_T(t) = \\begin{cases} t &amp; 0 &lt; t \\leq 1 \\\\ 2 - t &amp; 1 &lt; t &lt; 2 \\\\ 0 &amp; \\text{otherwise} \\end{cases}. \\] This is sometimes known as the triangular distribution, for obvious reasons. Example 45.2 (Distribution of the Arrival Times) In Examples 43.3 and 44.3, we derived the expectation and standard deviation of \\(S_r\\), the \\(r\\)th arrival time by writing \\(S_r\\) as a sum of the \\(\\text{Exponential}(\\lambda=0.8)\\) interarrival times: \\[ S_r = T_1 + T_2 + \\ldots + T_r. \\] In this example, we investigate the distribution of \\(S_r\\). We start with the case \\(r=2\\). Since \\(S_2\\) is the sum of \\(T_1\\) and \\(T_2\\), two independent exponential random variables, we can use Theorem 45.1 to derive its p.d.f. We convolve the \\(\\text{Exponential}(\\lambda=0.8)\\) p.d.f. with itself, since \\(T_1\\) and \\(T_2\\) have the same distribution. Plugging the p.d.f.s into (45.1), we obtain: \\[ f_{S_2}(t) = \\int_{?}^? 0.8 e^{-0.8 x} \\cdot 0.8 e^{-0.8 (t - x)}\\,dx, \\] where the limits of integration are TBD. To determine the limits of integration, there are several ways to think about it: Remember that the support of the exponential distribution is on the positive numbers. Therefore, the integrand will be 0, unless both \\(x\\) and \\((t-x)\\) are positive. This means that the limits of integration must be from \\(0\\) to \\(t\\). \\(f_{S_2}(t)\\) captures how likely it is for the second arrival to happen “near” \\(t\\) seconds. If \\(x &gt; t\\), then the first arrival happened after \\(t\\) seconds, so the second arrival could not have happened near \\(t\\) seconds. If we flip and shift one of the exponential distributions, then the supports of the two functions will only overlap between \\(0\\) and \\(t\\), as illustrated in the graph below. Now that we have the limits of integration, we obtain the following formula for the p.d.f. for \\(t &gt; 0\\). \\[\\begin{align*} f_{S_2}(t) &amp;= \\int_0^t 0.8 e^{-0.8 x} \\cdot 0.8 e^{-0.8 (t - x)}\\,dx \\\\ &amp;=\\int_0^t (0.8)^2 e^{-0.8 (x + (t - x))}\\,dx \\\\ &amp;= (0.8)^2 e^{-0.8 t} \\int_0^t 1\\,dx \\\\ &amp;= (0.8)^2 t e^{-0.8 t}; t &gt; 0 \\end{align*}\\] This p.d.f. is graphed in red, along with the exponential p.d.f. of the interarrival times in gray. From the figure above, we see that the second arrival tends to happen later than the first arrival, which makes intuitive sense. The p.d.f. also seems to be centered around \\(2 / 0.8 = 2.5\\), which is the expected value we calculated in Example 43.3. What about when \\(r=3\\)? The time of third arrival is the sum of the time of the second arrival, \\(S_2\\), and the time between the second and third arrivals, \\(T_3\\). Therefore, to obtain the p.d.f. of \\(S_3\\), we convolve the p.d.f. of \\(S_2\\) we derived above with the \\(\\text{Exponential}(\\lambda=0.8)\\) p.d.f. The right limits of integration are \\(0\\) to \\(t\\), by the same argument as above. \\[\\begin{align*} f_{S_3}(t) &amp;= \\int_0^t (0.8)^2 x e^{-0.8 x} \\cdot 0.8 e^{-0.8 (t - x)}\\,dx \\\\ &amp;=\\int_0^t (0.8)^3 x e^{-0.8 (x + (t - x))}\\,dx \\\\ &amp;= (0.8)^3 e^{-0.8 t} \\int_0^t x\\,dx \\\\ &amp;= \\frac{(0.8)^3}{2} t^2 e^{-0.8 t}; t &gt; 0 \\end{align*}\\] This p.d.f. is graphed in blue below. In general, we can continue in this way to obtain the following formula for the p.d.f. of the \\(r\\)th arrival time in this Poisson process. \\[\\begin{equation} f_{S_r}(t) = \\frac{(0.8)^r}{(r-1)!} t^{r-1} e^{-0.8 t}; t &gt; 0. \\tag{45.2} \\end{equation}\\] This family of distributions is known as the gamma distribution, with parameters \\(r\\) and \\(\\lambda =0.8\\). Essential Practice In this exercise, you will investigate the distribution of \\(S_n = U_1 + U_2 + \\ldots + U_n\\), where \\(U_i\\) are i.i.d. \\(\\text{Uniform}(a=0, b=1)\\) random variables. You already calculated \\(E[S_n]\\) and \\(\\text{SD}[S_n]\\) in Lesson 44. Now, you will calculate its distribution. Find the p.d.f. of \\(S_3 = U_1 + U_2 + U_3\\) and sketch its graph. Check that this p.d.f. agrees with the value of \\(E[S_3]\\) and \\(\\text{SD}[S_3]\\) that you calculated earlier. (Hint 1: We already worked out the distribution of \\(U_1 + U_2\\) in Example 45.1. Do another convolution.) (Hint 2: You should end up with a p.d.f. with 4 cases: \\(f_{S_3}(t) = \\begin{cases} ... &amp; 0 &lt; t \\leq 1 \\\\ ... &amp; 1 &lt; t \\leq 2 \\\\ ... &amp; 2 &lt; t &lt; 3 \\\\ 0 &amp; \\text{otherwise} \\end{cases}\\).) Find the p.d.f. of \\(S_4 = U_1 + U_2 + U_3 + U_4\\) and sketch its graph. Check that this p.d.f. agrees with the value of \\(E[S_4]\\) and \\(\\text{SD}[S_4]\\) that you calculated earlier. (Hint: I think the easiest way to do this is to convolve another uniform p.d.f. with the p.d.f. you got in part a. However, you could also do this by convolving two triangle functions together. You should get the same answer either way.) Neither \\(S_3\\) nor \\(S_4\\) are named distributions. However, if you sketch their p.d.f.s, they should remind you of one of the named distributions we learned. Which one? Let \\(X\\) and \\(Y\\) be independent standard normal—that is, \\(\\text{Normal}(\\mu=0, \\sigma=1)\\)—random variables. Let \\(T = X + Y\\). You should quickly be able to determine \\(E[T]\\) and \\(\\text{Var}[T]\\). But what is the distribution of \\(T\\)? Use convolution to answer this question. (I’m happy if you can just set up the integral and plug it into Wolfram Alpha. If you really want to solve it by hand, try “completing the square” in the exponent so that you end up with something that looks like a normal p.d.f., which you know must integrate to 1.) (This exercise is an application of the result that you found in the previous exercise. It is otherwise unrelated to this lesson.) Let \\(X_1\\), \\(X_2\\), and \\(X_3\\) represent the times (in minutes) necessary to perform three successive repair tasks at a service facility. They are independent, normal random variables with expected values 45, 50, and 75 and variances 10, 12, and 14, respectively. What is the probability that the service facility is able to finish all three tasks within 3 hours (that is, 180 minutes)? (Hint: Use the previous exercise to identify the distribution of \\(T = X_1 + X_2 + X_3\\). It is one of the named distributions we learned. Once you identify the distribution and its parameters, you can calculate the probability in the usual way. You should not need to do any convolutions to answer this question.) "],
["clt.html", "Lesson 46 Central Limit Theorem Motivation Theory Worked Examples Essential Practice Additional Practice", " Lesson 46 Central Limit Theorem Motivation In Lesson 45, we saw that calculating the exact distribution of a sum of i.i.d. random variables, \\(S_n = X_1 + X_2 + \\ldots + X_n\\) is a lot of work. Each time we add another random variable, we have to calculate a convolution, which requires calculating an integral. For arbitrary p.m.f.s and p.d.f.s, calculating many convolutions is impractical. However, we often work with the sum of hundreds or even thousands of random variables. Since getting the exact distribution of \\(S_n\\) is impractical, we need an approximation that is accurate and easy to use. The Central Limit Theorem provides that approximation. Theory Theorem 46.1 (Central Limit Theorem for Sums) Let \\(X_1, ..., X_n\\) be independent and identically distributed (i.i.d.) random variables. Then, for \\(n\\) large, their sum \\[ S_n = X_1 + ... + X_n \\] is approximately normally distributed. Therefore, to calculate a probability such as \\(P(S_n \\leq x)\\), we can use a normal distribution. Of course, we need the parameters of the normal distribution. That is, we need to specify \\(\\mu\\) and \\(\\sigma\\). We choose these parameters to match the expectation \\(E[S_n]\\) and the standard deviation \\(\\text{SD}[S_n]\\), which we can calculate using properties of expectation and covariance: \\[\\begin{align*} \\mu = E[S_n] &amp;= E[X_1 + X_2 + ... + X_n] \\\\ &amp;= E[X_1] + E[X_2] + ... + E[X_n] &amp; \\text{(linearity of expectation)} \\\\ &amp;= n E[X_1] &amp; \\text{($X_i$s are identically distributed)} \\\\ \\sigma^2 = \\text{Var}[S_n] &amp;= \\text{Cov}[S_n, S_n] \\\\ &amp;= \\text{Cov}[X_1 + ... + X_n, X_1 + ... + X_n] \\\\ &amp;= \\text{Cov}[X_1, X_1] + \\text{Cov}[X_1, X_2] + ... + \\text{Cov}[X_n, X_n] &amp; \\text{(properties of covariance)} \\\\ &amp;= \\text{Var}[X_1] + ... + \\text{Var}[X_n] &amp; \\text{($X_i$s are independent)} \\\\ &amp;= n\\text{Var}[X_1] &amp; \\text{($X_i$s are identically distributed)} \\\\ \\sigma = \\sqrt{\\sigma^2} &amp;= \\sqrt{n} \\text{SD}[X_1]. \\end{align*}\\] Since the mean of a list of numbers is just their sum divided by \\(n\\), the mean of \\(n\\) i.i.d. random variables is also approximately normal. (Scaling a normal random variable by a constant just produces another normal distribution.) Theorem 46.2 (Central Limit Theorem for Means) Let \\(X_1, ..., X_n\\) be independent and identically distributed (i.i.d.) random variables. Then, for \\(n\\) large, their (sample) mean \\[ \\bar X_n = \\frac{X_1 + ... + X_n}{n} \\] is approximately normally distributed. The parameters of this normal distribution are: \\[\\begin{align*} \\mu = E[\\bar X_n] &amp;= E[\\frac{S_n}{n}] \\\\ &amp;= \\frac{n E[X_1]}{n} \\\\ &amp;= E[X_1] \\\\ \\sigma^2 = \\text{Var}[\\bar X_n] &amp;= \\text{Var}[\\frac{S_n}{n}] \\\\ &amp;= \\frac{1}{n^2} \\text{Var}[S_n] \\\\ &amp;= \\frac{1}{n^2} n \\text{Var}[X_1] \\\\ &amp;= \\frac{\\text{Var}[X_1]}{n} \\\\ \\sigma = \\text{SD}[\\bar X_n] &amp;= \\frac{\\text{SD}[X_1]}{\\sqrt{n}}. \\end{align*}\\] The sample mean will hover around the expected value of each observation, and the uncertainty (as measured by the standard deviation) approaches 0 as \\(n \\to \\infty\\). This is the same calculation that we did in Lesson 32 to prove the Law of Large Numbers, which says that the sample mean converges to this expected value as \\(n \\to\\infty\\). For any finite number \\(n\\), the sample mean will be close to, but not exactly equal to, the expected value. The Central Limit Theorem says that the remaining variability can be approximated by a normal distribution. Worked Examples Example 46.1 (Trial of the Pyx) Since the 1200s, coins struck by the Royal Mint in England have been evaluated for their metal content in a ceremony called the Trial of the Pyx. This ceremony does not have much meaning today (see the video below), but in the 1700s, English coins were made of gold. The Master of the Mint had an incentive to make coins weigh less than the standard, because he could keep the shortfall himself (as long as he was not caught). In the Trial, 100 guineas (i.e., gold coins) would be chosen randomly and independently from all coins made at the Mint that year, put in the Pyx (a ceremonial box), and weighed. The Master of the Mint was allowed a margin of error, which was set according to the manufacturing tolerances of the time. If the actual weight of the coins in the Pyx differed from its target weight by more than this margin on either side, the Master of the Mint was exposed to serious penalties. In 1799, each guinea was supposed to weigh 128 grains. Due to manufacturing variability, the standard deviation of guinea weights was about 0.1 grains. To give the Master of the Mint some wiggle room, the allowable margin of error for each guinea was set at 0.32 grains. The British government reasoned that the total weight of 100 guineas should be 12,800 grains on average, with an allowable margin of 32 grains. Let’s suppose the Master of the Mint makes the guineas weigh \\(127.7\\) grains on average, skimming \\(0.1\\) grains from each coin. What is the probability he gets caught? Solution. Let \\(X_i\\) be the actual weight of a single guinea. Then, \\(E[X_i] = 127.7\\) and \\(\\text{Var}[X_i] = 0.1^2\\). The total weight of the 100 guineas is: \\[ S = X_1 + ... + X_{100}. \\] We know that \\[\\begin{align*} E[S] &amp;= 100 \\cdot 127.7 = 12770 &amp; \\text{Var}[S] &amp;= 100 \\cdot 0.1^2 \\\\ &amp; &amp; \\text{SD}[S] &amp;= \\sqrt{100} \\cdot 0.1 = 1 \\end{align*}\\] By the Central Limit Theorem, we can approximate the distribution of \\(S\\) by \\[ S \\approx \\textrm{Normal}(\\mu=12770, \\sigma=1). \\] Notice that we did not need to know how the weights of individual guineas are distributed! The weight of an individual guinea can follow any distribution, and the total weight of 100 independent guineas will still follow this normal distribution. Now, the Master of the Mint fails the Trial if the weight is off by 32 grains. That is, he fails if \\(S &lt; 12800 - 32\\). This probability is \\[ P(S &lt; 12768) = P(\\frac{S - 12770}{1} &lt; \\frac{12768 - 12770}{1}) = \\Phi(-2) \\approx .023. \\] (Technically, the Master also fails if the weight is off by 32 in the other direction, i.e., \\(S &gt; 12832\\), but this is probability is so tiny that we can ignore it.) Example 46.2 (Trial of the Pyx continued) Not satisfied with a 1-in-50 chance of being caught (and likely executed), the Master of the Mint wants to reduce his chances of getting caught to 0.1%? What should he make the guineas weigh on average? Solution. Let \\(X_i\\) denote the weight of a single guinea. Then, \\(E[X_i] = m\\) (we are trying to determine this) and \\(\\text{Var}[X_i] = 0.1^2\\). The total weight of the 100 guineas is: \\[ S = X_1 + ... +X_{100}. \\] By the same logic as in Example 46.1, \\(S \\approx \\textrm{Normal}(\\mu=100m, \\sigma=1)\\). Our goal is to solve for \\(m\\) so that \\[ P(S &lt; 12768) = .001. \\] To this end, we standardize both sides: \\[ .001 = P(\\frac{S - 100m}{1} &lt; \\frac{12768 - 100m}{1}) = \\Phi(12768 - 100m). \\] Using the quantile function, we find that \\[ 12768 - 100m \\approx -3.09, \\] so he would just need to target an average weight of \\(m \\approx 127.71\\) grains, which is only a smidge higher (and still quite far off from the target weight of 128 grains). Where did the government go wrong in setting up the Trial of the Pyx? They were much too lenient in allowing the Master of the Mint a margin of 32 grains. We know that the uncertainty in the sum of \\(n\\) independent random variables grows as \\(\\sqrt{n}\\), not \\(n\\). So if they wanted to allow the Master of the Mint a margin of 0.32 grains per coin, they should have only allowed him a margin of \\(\\sqrt{100} \\cdot 32 = 3.2\\) grains for 100 coins. Instead, they allowed him a margin that was 10 times larger. Here is an example where we use the Central Limit Theorem for Means (Theorem 46.2). Example 46.3 Suppose salaries at a very large corporation have a mean of $62,000 and a standard deviation of $32,000. If a single employee is randomly selected, what is the probability their salary exceeds $66,000? If 100 employees are randomly selected, what is the probability their average salary exceeds $66,000? Solution. The solution is explained in the following video. It is impossible to answer this question without knowing the distribution of salaries. By the Central Limit Theorem, even if salaries are not normally distributed, the average of 100 salaries, \\(\\bar X\\), will be. We just need to figure out the mean and the variance: \\[\\begin{align*} E[\\bar X] &amp;= E[X_1] = 62000 \\\\ \\text{SD}[\\bar X] &amp;= \\frac{\\text{SD}[X_1]}{\\sqrt{n}} = \\frac{32000}{\\sqrt{100}}. \\end{align*}\\] So \\(\\bar X\\) approximately follows a \\(\\text{Normal}(\\mu=62000, \\sigma=\\frac{32000}{\\sqrt{100}})\\) distribution. Therefore: \\[\\begin{align*} P(\\bar X &gt; 66000) &amp;= P\\Big(\\underbrace{\\frac{\\bar X - 62000}{32000 / \\sqrt{100}}}_Z &gt; \\underbrace{\\frac{66000 - 62000}{32000 / \\sqrt{100}}}_{1.25}\\Big) \\\\ &amp;\\approx 1 - \\Phi(1.25) \\\\ &amp;\\approx 0.106 \\end{align*}\\] Example 46.4 (Normal Approximation to the Binomial) The Central Limit Theorem works for discrete random variables as well. For example, suppose a casino suspects that one of its roulette wheels is defective. They notice that the ball has landed in the 0 or 00 pockets 22 times in the last 300 spins. Is this evidence that the roulette wheel is biased towards 0 and 00? We can set up a box model for the number of times that the ball lands in the 0 or 00 pockets. We can represent this as the number of \\(\\fbox{1}\\)s in \\(n=300\\) draws (with replacement) from the box \\[ \\fbox{$\\underbrace{\\fbox{1}\\ \\fbox{1}}_{N_1=2}\\ \\underbrace{\\fbox{0}\\ \\fbox{0}\\ \\ldots\\ \\fbox{0}\\ \\fbox{0}}_{N_0=36}$}. \\] This is the description of a \\(\\text{Binomial}(n=300, p=2/38)\\) random variable. Using a binomial distribution calculator, the (exact) probability of getting 22 or more is # Python code from symbulate import * 1 - Binomial(n=300, p=2/38).cdf(21) ## 0.0749780882223865 # R code 1 - pbinom(21, size=300, prob=2/38) ## [1] 0.07497809 We can also approximate this random variable—let’s call it \\(S\\)—by a normal distribution. To see this, write \\[ S = X_1 + X_2 + \\ldots + X_{300}, \\] where each \\(X_i\\) represents the outcome of one draw. Because the draws are made with replacement, the \\(X_i\\)s are independent. By the Central Limit Theorem, \\(S\\) is approximately normal. We approximate it by a normal distribution, choosing \\(\\mu\\) and \\(\\sigma\\) to match the expected value and standard deviation: \\[\\begin{align*} E[S] &amp;= np = 300 \\cdot \\frac{2}{38} \\approx 15.79 &amp; \\text{SD}[S] &amp;= \\sqrt{np(1-p)} = \\sqrt{300 \\cdot \\frac{2}{38} \\cdot (1 - \\frac{2}{38})} \\approx 3.87. \\end{align*}\\] So \\(S \\approx \\text{Normal}(\\mu=15.79, \\sigma=3.87)\\). Now we can calculate \\(P(S \\geq 22)\\) using a normal distribution calculator: # Python code 1 - Normal(mean=300 * 2/38, sd=sqrt(300 * 2/38 * (1 - 2/38))).cdf(22) ## 0.054161500900249515 # R 1 - pnorm(22, mean=300 * 2/38, sd=sqrt(300 * 2/38 * (1 - 2/38))) ## [1] 0.0541615 Notice that we plugged in 22 into the c.d.f. because the normal distribution is continuous. That is, \\[ P(S \\geq 22) = 1 - P(S &lt; 22) = 1 - P(S \\leq 22), \\] since the probability that \\(S\\) equals 22 exactly is zero. However, because we are using the normal distribution to approximate a discrete distribution, some people argue that we should plug in 21 or 21.5 instead. This is called a continuity correction, since it attempts to correct for the error in approximating a discrete distribution by a continuous one. Indeed, if you plug in 21.5, you get an approximation that is closer to the exact answer we obtained above. # R 1 - pnorm(21.5, mean=300 * 2/38, sd=sqrt(300 * 2/38 * (1 - 2/38))) ## [1] 0.06990513 In my opinion, worrying about continuity corrections is like rearranging the deck chairs on the Titanic. There is no point in trying to make the normal approximation slightly better when you can just use a binomial calculator and get the exact answer. The normal approximation to the binomial is primarily interesting as an application of the Central Limit Theorem, not as a practical way to calculate probabilities. Shown below is the normal approximation (in red) to the binomial p.m.f. (in black). The normal approximation is very good, but not perfect. Essential Practice There are 40 students in an elementary statistics class. From years of experience, the instructor knows that the time needed to grade a randomly chosen paper from an exam is a random variable with an expected value of 6 min and a standard deviation of 6 min. If grading times are independent and the instructor begins grading at 8:00 p.m. and grades continuously, what is the (approximate) probability that she is done grading before the late night shows begin at 11:30 p.m.? In roulette, a bet on a single number has a \\(1/38\\) probability of success and pays 35-to-1. Consider betting on a single number on each of \\(n\\) spins of a roulette wheel. Let \\(\\bar X_n\\) be your average net winnings per bet. For which of the following values of \\(n\\) is \\(\\bar X_n\\) close to normally distributed? Do a simulation to find out. (Copy the code below into a Colab and modify.) # Python code (Make sure Symbulate has been imported.) n = 10 P = BoxModel({35: 1, -1: 37}, size=n, replace=True) X = RV(P, mean) X.sim(9999) # You can use .plot() to make a histogram of these results. # R code n &lt;- 10 replicate(9999, mean(sample(c(35, rep(-1, 37)), size=n, replace=TRUE))) # You can use hist() to make a histogram of these results. \\(n=10\\) \\(n=100\\) \\(n=1000\\) \\(n=10000\\) For each \\(n\\), calculate the approximate probability that you come out ahead, i.e., \\(P(\\bar X_n &gt; 0)\\). I encourage you to use a combination of simulation and the Central Limit Theorem (but first double check that it works!). (Hint: We calculated the expected value and variance of this bet in previous lessons.) The casino wants to determine how many bets on a single number are needed before they have (at least) a 99% probability of making a profit. (Remember, the casino profits if you lose: \\(\\bar X_n &lt; 0\\).) Determine the minimum number of bets, keeping in mind that \\(n\\) must be an integer. In San Luis Obispo, radioactive particles reach a Geiger counter according to a Poisson process at a rate of \\(\\lambda = 0.8\\) particles per second. What is the probability that the 100th particle is detected between 90 and 120 seconds? Calculate this probability in two ways: Argue that the time the 100th particle is detected approximately follows a normal distribution. Use the normal approximation to calculate an approximate probability. We derived the exact p.d.f. of the \\(r\\)th arrival time in Example 45.2. Integrate this p.d.f. to get the exact probability. How good was the normal approximation? Additional Practice A randomly selected apple from the Cal Poly Orchard weighs 4.9 oz. on average, with a standard deviation of 0.3 oz. However, the distribution of the weights of apples is unknown. With the information given, is it possible to determine the probability that a randomly selected apple weighs more than 5.0 oz? If so, calculate it. The apples are packed into crates of 60 apples each. The apples are randomly and independently selected from the Cal Poly Orchard. With the information given, is it possible to determine the probability that the total weight of the apples in a crate exceeds 300 oz? If so, calculate it. "],
["random-process.html", "Lesson 47 Random Processes Motivation Theory Essential Practice", " Lesson 47 Random Processes Motivation A signal is a function of time, usually symbolized \\(x(t)\\) (or \\(x[n]\\), if the signal is discrete). In a noisy signal, the exact value of the signal is random. Therefore, we will model noisy signals as a random function \\(X(t)\\), where at each time \\(t\\), \\(X(t)\\) is a random variable. These “noisy signals” are formally called random processes or stochastic processes. Theory Definition 47.1 (Random Process) A random process is a collection of random variables \\(\\{ X_t \\}\\) indexed by time. Each realization of the process is a function of \\(t\\). For every fixed time \\(t\\), \\(X_t\\) is a random variable. Random processes are classified as continuous-time or discrete-time, depending on whether time is continuous or discrete. We typically notate continuous-time random processes as \\(\\{ X(t) \\}\\) and discrete-time processes as \\(\\{ X[n] \\}\\). We have actually encountered several random processes already. Example 47.1 (Poisson Process) The Poisson process, introduced in Lesson 17, is a continuous-time random process. Define \\(N(t)\\) to be the number of arrivals up to time \\(t\\). Then, \\(\\{ N(t); t \\geq 0 \\}\\) is a continuous-time random process. We can now restate the defining properties of a Poisson process (Definition 17.1) using \\(\\{ N(t) \\}\\). \\(N(0) = 0\\). \\(N(t_1) - N(t_0)\\), the number of arrivals on the interval \\((t_0, t_1)\\), follows a Poisson distribution with \\(\\mu = \\lambda (t_1 - t_0)\\) Independent increments: The number of arrivals on non-overlapping intervals are independent. The graph below shows how the arrivals (orange dots) can be translated into a continuous-time function \\(N(t)\\) (blue line). Shown below are 30 realizations of the Poisson process. At any time \\(t\\), the value of the process is a discrete random variable that takes on the values 0, 1, 2, …. Example 47.2 (White Noise) In several lessons (for example, Lesson 32 and 46), we have examined sequences of independent and identically distributed (i.i.d.) random variables. A sequence of independent and identically distributed random variables \\(.., Z[-2], Z[-1], Z[0], Z[1], Z[2], ...\\) is called white noise. White noise is an example of a discrete-time process. The graph below shows one realization of white noise, where \\(Z[n]\\) is a standard normal random variable. This process is only defined at integer times \\(n=-2, -1, 0, 1, 2, ...\\) (even though we have connected the dots). Shown below are 30 realizations of the white noise process. Notice how the distribution of \\(Z[n]\\) looks similar for every \\(n\\). This is because we constructed the process by simulating an independent standard normal random variable at every time \\(n\\). Example 47.3 (Random Walk) In Lesson 31, we studied the random walk. More precisely, we studied a special case called the simple random walk. In general, a (general) random walk \\(\\{ X[n]; n \\geq 0 \\}\\) is a discrete-time process, defined by \\[\\begin{align*} X[0] &amp;= 0 \\\\ X[n] &amp;= X[n-1] + Z[n] &amp; n \\geq 1, \\end{align*}\\] where \\(\\{ Z[n] \\}\\) is a white noise process. In other words, each step is a independent and random draw from the same distribution. Let’s work out an explicit formula for \\(X[n]\\) in terms of \\(Z[1], Z[2], ...\\). \\[\\begin{align*} X[0] &amp;= 0 \\\\ X[1] &amp;= \\underbrace{X[0]}_0 + Z[1] = Z[1] \\\\ X[2] &amp;= \\underbrace{X[1]}_{Z[1]} + Z[2] = Z[1] + Z[2] \\\\ X[3] &amp;= \\underbrace{X[2]}_{Z[1] + Z[2]} + Z[3] = Z[1] + Z[2] + Z[3] \\\\ &amp; \\vdots \\\\ X[n] &amp;= Z[1] + Z[2] + \\ldots + Z[n]. \\end{align*}\\] In a simple random walk, the steps are i.i.d. random variables with p.m.f. \\[ \\begin{array}{r|cc} z &amp; -1 &amp; 1 \\\\ \\hline f(z) &amp; 0.5 &amp; 0.5 \\end{array}. \\] See Lesson 31 for pictures of a simple random walk. Below, we show one realization of a random walk, where the steps \\(Z[n]\\) are i.i.d. standard normal random variables (i.e., the process considered in Example 47.2). Now, we show 30 realizations of the same random walk process. Notice how the distribution of \\(X[n]\\) is different for each \\(n\\). In the Essential Practice below, you will work out the distribution of each \\(X[n]\\). Essential Practice Radioactive particles hit a Geiger counter according to a Poisson process at a rate of \\(\\lambda=0.8\\) particles per second. Let \\(\\{ N(t); t \\geq 0 \\}\\) represent this Poisson process. What is the distribution of \\(N(1.2)\\)? (Hint: Translate this into a statement about the number of arrivals on some interval.) Calculate \\(P(N(1.2) &gt; 1)\\). What is \\(P(N(2.0) &gt; N(1.2))\\)? (Hint: Translate this into a statement about the number of arrivals on some interval.) Let \\(\\{Z[n]\\}\\) be white noise consisting of i.i.d. \\(\\text{Exponential}(\\lambda=0.5)\\) random variables. What is \\(P(Z[2] &gt; 1.0)\\)? What is \\(P(Z[3] &gt; Z[2])\\)? Let \\(\\{ X[n] \\}\\) be a random walk, where the steps are i.i.d. standard normal random variables. What is the distribution of \\(X[n]\\)? (Your answer should depend on \\(n\\).) What is \\(P(X[100] &gt; 20)\\)? (Hint: What do you know about the sum of independent normal random variables?) "],
["random-process-examples.html", "Lesson 48 Examples of Random Processes", " Lesson 48 Examples of Random Processes In this lesson, we cover a few more examples of random processes. Example 48.1 (Random Amplitude Process) Let \\(A\\) be a random variable. Let \\(f\\) be a constant. Then the continuous-time process \\[ X(t) = A\\cos(2\\pi f t) \\] is called a random amplitude process. Note that once the value of \\(A\\) is simulated, the random process \\(\\{ X(t) \\}\\) is completely specified for all times \\(t\\). Shown below are 30 realizations of the random amplitude process, where \\(A\\) is \\(\\text{Binomial}(n=5, p=0.5)\\). Here is a video that animates the random amplitude process. Example 48.2 (Moving Average Process) Let \\(\\{ Z[n] \\}\\) be a white noise process. Then, a moving average process (of order 1) \\(\\{ X[n] \\}\\) is a discrete-time process defined by \\[\\begin{equation} X[n] = b_0 Z[n] + b_1 Z[n-1]. \\tag{48.1} \\end{equation}\\] Below, we show one realization of a white noise process \\(\\{ Z[n] \\}\\) (in orange), along with the corresponding moving average process \\[ X[n] = 0.5 Z[n] + 0.5 Z[n-1]. \\] Notice that the moving average process is just the average of successive values of the white noise process. As a result, the moving average process is “smoother” than the white noise process. Now, we show 30 realizations of the same moving average process. Superficially, this might look like the white noise of Example 47.2, but if you look closely, you will see that each individual function fluctuates less. "],
["brownian-motion.html", "Lesson 49 Brownian Motion Essential Practice", " Lesson 49 Brownian Motion The videos above discussed Brownian motion of particles moving in two or three dimensions; for simplicity, we will only consider Brownian motion in one dimension. This can be used to model, among other things, a particle moving along a line. Shown below are 5 sample paths of Brownian motion. Definition 49.1 (Brownian Motion) Brownian motion \\(\\{ B(t); t \\geq 0 \\}\\) is a continuous-time process with the following properties: The “particle” starts at the origin at \\(t=0\\): \\(B(0) = 0\\). The displacement over any interval \\((t_0, t_1)\\), denoted by \\(B(t_1) - B(t_0)\\), follows a \\(\\text{Normal}(\\mu=0, \\sigma=\\sqrt{\\alpha(t_1 - t_0)})\\) distribution. Independent increments: The displacements over non-overlapping intervals are independent. The parameter \\(\\alpha\\) controls the scale of Brownian motion. These three properties allow us to calculate most probabilities of interest. Example 49.1 (Motion of a Pollen Grain) The horizontal position of a grain of pollen suspended in water can be modeled by Brownian motion with scale \\(\\alpha = 4 \\text{mm}^2/\\text{s}\\). What is the probability the pollen grain moves by more than 10 mm (in the horizontal direction) between 1 and 4 seconds? If the particle is more than 5 mm away from the origin after 1 second, what is the probability the pollen grain moves by more than 10 mm between 1 and 4 seconds? Solution. . The displacement of the particle between 1 and 4 seconds is represented by \\(B(4) - B(1)\\), which we know follows a \\(\\text{Normal}(\\mu=0, \\sigma=\\underbrace{\\sqrt{4(4-1)}}_{\\sqrt{12}})\\) distribution. Since the question does not indicate whether the displacement is positive or negative, we’re really interested in determining \\(P(|B(4) - B(1)| &gt; 10)\\). Because the distribution of \\(B(4) - B(1)\\) is symmetric about \\(0\\), this is the same as \\(2 P(B(4) - B(1) &gt; 10)\\) or \\(2 P(B(4) - B(1) &lt; -10)\\). \\[\\begin{align*} P(|B(4) - B(1)| &gt; 10) &amp;= 2 P(B(4) - B(1) &gt; 10) \\\\ &amp;= 2 P\\big(\\underbrace{\\frac{B(4) - B(1) - 0}{\\sqrt{12}}}_Z &gt; \\frac{10 - 0}{\\sqrt{12}}\\big) \\\\ &amp;= 2 (1 - \\Phi(\\frac{10}{\\sqrt{12}})) \\\\ &amp;\\approx .0039. \\end{align*}\\] b. The interval \\((0, 1)\\) does not overlap with the interval \\((1, 4)\\). Therefore, by the independent increments property, \\(B(1) = B(1) - B(0)\\) is independent of \\(B(4) - B(1)\\), and \\[ P\\Big(|B(4) - B(1)| &gt; 10\\ \\big|\\ |B(1)| &gt; 5\\Big) = P(|B(4) - B(1)| &gt; 10) = .0039. \\] Brownian Motion as the Limit of a Random Walk Brownian motion is the extension of a (discrete-time) random walk \\(\\{ X[n]; n \\geq 0 \\}\\) to a continuous-time process \\(\\{ B(t); t \\geq 0 \\}\\). The recipe is as follows: Suppose the steps of the random walk happens at intervals of \\(\\Delta t\\) seconds. That is, \\[ X(t) = X\\left[\\frac{t}{\\Delta t}\\right] \\] We let \\(\\Delta t \\to 0\\). Since each step happens so quickly, it does not make sense to take steps of the same size. We should also rescale the size of the steps to be commensurate with how quickly they happen. The right rescaling is: \\[ B(t) = \\sqrt{\\Delta t} X(t). \\] If we start with a discrete-time random walk and rescale time and step sizes in this way, we get Brownian motion. The animation below illustrates this. Essential Practice Brownian motion is used in finance to model short-term asset price fluctuation. Suppose the price (in dollars) of a barrel of crude oil varies according to a Brownian motion process; specifically, suppose the change in a barrel’s price \\(t\\) days from now is modeled by Brownian motion \\(B(t)\\) with \\(\\alpha = .15\\). Find the probability that the price of a barrel of crude oil has changed by more than $1, in either direction, after 5 days. Repeat (a) for a time interval of 10 days. Given that the price has increased by $1 after one week (7 days), what is the probability that the price has increased by at least $2 after two weeks (14 days)? "],
["mean-function.html", "Lesson 50 Mean Function Theory Essential Practice", " Lesson 50 Mean Function In the next few lessons, we discuss three functions that are commonly used to summarize random processes: the mean function, the variance function, and the autocovariance function. Theory Definition 50.1 (Mean Function) The mean function \\(\\mu_X(t)\\) of a random process \\(\\{ X(t) \\}\\) is a function that specifies the expected value at each time \\(t\\). That is, \\[\\begin{equation} \\mu_X(t) \\overset{\\text{def}}{=} E[X(t)]. \\tag{50.1} \\end{equation}\\] For a discrete-time process, we notate the mean function as \\[ \\mu_X[n] \\overset{\\text{def}}{=} E[X[n]]. \\] The following video explains how to think about a mean function intuitively. Let’s calculate the mean function of some random processes. Example 50.1 (Random Amplitude Process) Consider the random amplitude process \\[\\begin{equation} X(t) = A\\cos(2\\pi f t) \\tag{50.2} \\end{equation}\\] introduced in Example 48.1. To be concrete, suppose \\(A\\) is a \\(\\text{Binomial}(n=5, p=0.5)\\) random variable and \\(f = 1\\). To calculate the mean function, observe that the only thing that is random in (50.2) is \\(A\\). Everything else is a constant, so they can be pulled outside the expectation. \\[\\begin{align*} \\mu_X(t) = E[X(t)] &amp;= E[A\\cos(2\\pi ft)] \\\\ &amp;= E[A] \\cos(2\\pi ft) \\\\ &amp;= 2.5 \\cos(2\\pi ft), \\end{align*}\\] where in the last step, we used the formula for the expected value of a binomial random variable, \\(E[A] = np = 5 \\cdot 0.5 = 2.5\\). Shown below (in blue) are 30 realizations of this process, along with the mean function (in red). Notice how the mean function passes through the heart of the realizations. Example 50.2 (Poisson Process) Consider the Poisson process \\(\\{ N(t); t \\geq 0 \\}\\) of rate \\(\\lambda\\), defined in Example 47.1. Recall that \\(N(t)\\) represents the number of arrivals on the interval \\((0, t)\\), which we know (by properties of the Poisson process) follows a \\(\\text{Poisson}(\\mu=\\lambda t)\\) distribution. Since the expected value of a \\(\\text{Poisson}(\\mu)\\) random variable is \\(\\mu\\), we must have \\[ \\mu_N(t) = E[N(t)] = \\lambda t \\] Shown below (in blue) are 30 realizations of the Poisson process, with the mean function superimposed (in red). Example 50.3 (White Noise) Consider the white noise process \\(\\{ Z[n] \\}\\) defined in 47.2, which consists of i.i.d. random variables. Suppose the expected value of these random variables is \\(\\mu \\overset{\\text{def}}{=} E[Z[n]]\\). Then, the mean function is constant, equal to this expected value. \\[ \\mu_Z[n] = E[Z[n]] \\equiv \\mu. \\] Shown below (in blue) are 30 realizations of a white noise process consisting of i.i.d. standard normal random variables, along with the mean function (in red), which in this case is \\(\\mu_Z[n] \\equiv 0\\). Example 50.4 (Random Walk) Consider the random walk process \\(\\{ X[n]; n\\geq 0 \\}\\) of Example 47.3. Since \\[ X[n] = Z[1] + Z[2] + \\ldots + Z[n], \\] the mean function is \\[\\begin{align*} \\mu_X[n] = E[X[n]] &amp;= E[Z[1]] + E[Z[2]] + \\ldots + E[Z[n]] \\\\ &amp;= n E[Z[1]]. \\end{align*}\\] Shown below (in blue) are 30 realizations of the random walk process where the steps \\(Z[n]\\) are i.i.d. standard normal, so the mean function (shown in red) is \\(\\mu_X[n] = n \\cdot 0 \\equiv 0\\). Essential Practice Consider a grain of pollen suspended in water, whose horizontal position can be modeled by Brownian motion \\(\\{B(t)\\}\\) with parameter \\(\\alpha=4 \\text{mm}^2/\\text{s}\\), as in Example 49.1. Calculate the mean function of \\(\\{ B(t) \\}\\). Radioactive particles hit a Geiger counter according to a Poisson process at a rate of \\(\\lambda=0.8\\) particles per second. Let \\(\\{ N(t); t \\geq 0 \\}\\) represent this Poisson process. Define the new process \\(\\{ D(t); t \\geq 3 \\}\\) by \\[ D(t) = N(t) - N(t - 3). \\] This process represents the number of particles that hit the Geiger counter in the last 3 seconds. Calculate the mean function of \\(\\{ D(t); t \\geq 3 \\}\\). Consider the moving average process \\(\\{ X[n] \\}\\) of Example 48.2, defined by \\[ X[n] = 0.5 Z[n] + 0.5 Z[n-1], \\] where \\(\\{ Z[n] \\}\\) is a sequence of i.i.d. standard normal random variables. Calculate the mean function of \\(\\{ X[n] \\}\\). Let \\(\\Theta\\) be a \\(\\text{Uniform}(a=-\\pi, b=\\pi)\\) random variable, and let \\(f\\) be a constant. Define the random phase process \\(\\{ X(t) \\}\\) by \\[ X(t) = \\cos(2\\pi f t + \\Theta). \\] Calculate the mean function of \\(\\{ X(t) \\}\\). (Hint: LOTUS) "],
["var-function.html", "Lesson 51 Variance Function Theory Essential Practice", " Lesson 51 Variance Function Theory Definition 51.1 (Variance Function) The variance function \\(V(t)\\) of a random process \\(\\{ X(t) \\}\\) is a function that specifies the variance of the process at each time \\(t\\). That is, \\[ V(t) \\overset{\\text{def}}{=} \\text{Var}[X(t)]. \\] For a discrete-time process, we notate the variance function as \\[ V[n] \\overset{\\text{def}}{=} \\text{Var}[X[n]]. \\] The following video explains how to think about a variance function intuitively. Let’s calculate the variance function of some random processes. Example 51.1 (Random Amplitude Process) Consider the random amplitude process \\[\\begin{equation} X(t) = A\\cos(2\\pi f t) \\tag{50.2} \\end{equation}\\] introduced in Example 48.1. To be concrete, suppose \\(A\\) is a \\(\\text{Binomial}(n=5, p=0.5)\\) random variable and \\(f = 1\\). To calculate the variance function, observe that the only thing that is random in (50.2) is \\(A\\). Everything else is a constant, so they can be pulled outside the variance. (However, we have to remember to square anything we pull outside the variance.) \\[\\begin{align*} V(t) = \\text{Var}[X(t)] &amp;= \\text{Var}[A\\cos(2\\pi ft)] \\\\ &amp;= \\text{Var}[A] \\cos^2(2\\pi ft) \\\\ &amp;= 1.25 \\cos^2(2\\pi ft), \\end{align*}\\] where in the last step, we used the formula for the variance of a binomial random variable, \\(\\text{Var}[A] = np(1-p) = 5 \\cdot 0.5 \\cdot (1 - 0.5) = 1.25\\). Remember that the variance function \\(V(t)\\) measures the variability around the mean at time \\(t\\). Therefore, it makes sense to represent the variance function graphically as a band around the mean function. To construct this band, we do the following: Take the square root of the variance function so that it is in the same units as the mean function. (This is the same reason we defined the standard deviation as the square root of the variance.) Shade in a band of width \\(\\sqrt{V(t)}\\) around the mean function \\(\\mu(t)\\). That is, the band is lower-bounded by \\(\\mu(t) - \\sqrt{V(t)}\\) and upper-bounded by \\(\\mu(t) + \\sqrt{V(t)}\\). Example 51.2 (Poisson Process) Consider the Poisson process \\(\\{ N(t); t \\geq 0 \\}\\) of rate \\(\\lambda\\), defined in Example 47.1. Recall that \\(N(t)\\) represents the number of arrivals on the interval \\((0, t)\\), which we know (by properties of the Poisson process) follows a \\(\\text{Poisson}(\\mu=\\lambda t)\\) distribution. Since the variance of a \\(\\text{Poisson}(\\mu)\\) random variable is \\(\\mu\\), we must have \\[ V(t) = \\text{Var}[N(t)] = \\lambda t \\] We represent the variance function of the Poisson process below as a band of width \\(\\sqrt{V(t)} = \\sqrt{\\lambda t}\\) around the mean function \\(\\mu(t) = \\lambda t\\) (see Example 50.2). Example 51.3 (White Noise) Consider the white noise process \\(\\{ Z[n] \\}\\) defined in Example 47.2, which consists of i.i.d. random variables. Suppose the variance of these random variables is \\(\\sigma^2 \\overset{\\text{def}}{=} \\text{Var}[Z[n]]\\). Then, the variance function is constant, equal to this value. \\[ V[n] = \\text{Var}[Z[n]] \\equiv \\sigma^2. \\] Shown below (in blue) are 30 realizations of a white noise process where the \\(Z[n]\\)s are i.i.d. standard normal so that \\(\\sigma^2 = 1\\). The variance function of the white noise process is visualized below as a band of width \\(\\sqrt{V[n]} = 1\\) around the mean function \\(\\mu[n] \\equiv 0\\) (see Example 50.3). Example 51.4 (Random Walk) Consider the random walk process \\(\\{ X[n]; n\\geq 0 \\}\\) from Example 47.3. Since \\[ X[n] = Z[1] + Z[2] + \\ldots + Z[n], \\] the variance function is \\[\\begin{align*} V[n] = \\text{Var}[X[n]] &amp;= \\text{Cov}[X[n], X[n]] \\\\ &amp;= \\text{Cov}[Z[1] + \\ldots + Z[n], Z[1] + \\ldots + Z[n]] \\\\ &amp;= \\text{Var}[Z[1]] + \\text{Var}[Z[2]] + \\ldots + \\text{Var}[Z[n]] \\\\ &amp;= n \\text{Var}[Z[1]]. \\end{align*}\\] Shown below (in blue) are 30 realizations of the random walk process where the steps \\(Z[n]\\) are i.i.d. standard normal. In this case, the variance function (shown in red) is \\(V[n] = n \\cdot 1 \\equiv n\\). We visualize the variance function as a band of width \\(\\sqrt{V[n]} = \\sqrt{n}\\) around the mean function \\(\\mu[n] \\equiv 0\\) (see Example 50.4). Essential Practice Consider a grain of pollen suspended in water, whose horizontal position can be modeled by Brownian motion \\(\\{B(t)\\}\\) with parameter \\(\\alpha=4 \\text{mm}^2/\\text{s}\\), as in Example 49.1. Calculate the variance function of \\(\\{ B(t) \\}\\). Radioactive particles hit a Geiger counter according to a Poisson process at a rate of \\(\\lambda=0.8\\) particles per second. Let \\(\\{ N(t); t \\geq 0 \\}\\) represent this Poisson process. Define the new process \\(\\{ D(t); t \\geq 3 \\}\\) by \\[ D(t) = N(t) - N(t - 3). \\] This process represents the number of particles that hit the Geiger counter in the last 3 seconds. Calculate the variance function of \\(\\{ D(t); t \\geq 3 \\}\\). Consider the moving average process \\(\\{ X[n] \\}\\) of Example 48.2, defined by \\[ X[n] = 0.5 Z[n] + 0.5 Z[n-1], \\] where \\(\\{ Z[n] \\}\\) is a sequence of i.i.d. standard normal random variables. Calculate the variance function of \\(\\{ X[n] \\}\\). Let \\(\\Theta\\) be a \\(\\text{Uniform}(a=-\\pi, b=\\pi)\\) random variable, and let \\(f\\) be a constant. Define the random phase process \\(\\{ X(t) \\}\\) by \\[ X(t) = \\cos(2\\pi f t + \\Theta). \\] Calculate the variance function of \\(\\{ X(t) \\}\\). (Hint: LOTUS) "],
["cov-function.html", "Lesson 52 Autocovariance Function Theory Essential Practice", " Lesson 52 Autocovariance Function Theory Definition 52.1 (Autocovariance Function) The autocovariance function \\(C_X(s, t)\\) of a random process \\(\\{ X(t) \\}\\) is a function of two times \\(s\\) and \\(t\\). It is sometimes just called the “covariance function” for short. It specifies the covariance between the value of the process at time \\(s\\) and the value at time \\(t\\). That is, \\[\\begin{equation} C_X(s, t) \\overset{\\text{def}}{=} \\text{Cov}[X(s), X(t)]. \\tag{52.1} \\end{equation}\\] For a discrete-time process, we notate the autocovariance function as \\[ C_X[m, n] \\overset{\\text{def}}{=} \\text{Cov}[X[m], X[n]]. \\] Notice that the variance function can be obtained from the autocovariance function: \\[ V(t) = \\text{Var}[X(t)] = \\text{Cov}[X(t), X(t)] = C(t, t). \\] Let’s calculate the autocovariance function of some random processes. Unfortunately, the autocovariance function is difficult to visualize, since it is not just a function of time but a function of two times. However, the following video gives some intuition. Example 52.1 (Random Amplitude Process) Consider the random amplitude process \\[\\begin{equation} X(t) = A\\cos(2\\pi f t) \\tag{50.2} \\end{equation}\\] introduced in Example 48.1. To be concrete, suppose \\(A\\) is a \\(\\text{Binomial}(n=5, p=0.5)\\) random variable and \\(f = 1\\). To calculate the autocovariance function, observe that the only thing that is random in (50.2) is \\(A\\). Everything else is a constant, so they can be pulled outside the covariance. \\[\\begin{align*} C_X(s, t) = \\text{Cov}[X(s), X(t)] &amp;= \\text{Cov}[A\\cos(2\\pi fs), A\\cos(2\\pi ft)] \\\\ &amp;= \\underbrace{\\text{Cov}[A, A]}_{\\text{Var}[A]} \\cos(2\\pi fs)\\cos(2\\pi ft) \\\\ &amp;= 1.25 \\cos(2\\pi fs)\\cos(2\\pi ft), \\end{align*}\\] where in the last step, we used the formula for the variance of a binomial random variable, \\(\\text{Var}[A] = np(1-p) = 5 \\cdot 0.5 \\cdot (1 - 0.5) = 1.25\\). As a sanity check, we can derive the variance function from this autocovariance function: \\[ V_X(t) = C_X(t, t) = 1.25 \\cos(2\\pi ft)\\cos(2\\pi ft) = 1.25 \\cos^2(2\\pi f t). \\] This agrees with what we got in Example 51.1. Example 52.2 (Poisson Process) Consider the Poisson process \\(\\{ N(t); t \\geq 0 \\}\\) of rate \\(\\lambda\\), defined in Example 47.1. To calculate the autocovariance function, we first calculate \\(\\text{Cov}[N(s), N(t)]\\) assuming \\(s &lt; t\\). We can do this by breaking \\(N(t)\\) into \\(N(s)\\), the number of arrivals up to time \\(s\\), plus \\(N(t) - N(s)\\), the number of arrivals between time \\(s\\) and time \\(t\\). This allows us to use the independent increments property of the Poisson process (see Example 47.1). \\[\\begin{align*} \\text{Cov}[N(s), N(t)] &amp;= \\text{Cov}[N(s), N(s) + (N(t) - N(s))] \\\\ &amp;= \\text{Cov}[N(s), N(s)] + \\underbrace{\\text{Cov}[N(s), N(t) - N(s)]}_{\\text{0 by independent increments}} \\\\ &amp;= \\text{Var}[N(s)] \\\\ &amp;= \\lambda s. \\end{align*}\\] This is the covariance when \\(s &lt; t\\). If we repeat the argument for \\(s &gt; t\\), we will find that the covariance is \\(\\lambda t\\). In other words, the covariance always involves the smaller of the two times \\(s\\) and \\(t\\). Therefore, we can write the autocovariance function as \\[ C_N(s, t) = \\lambda \\min(s, t). \\] As a sanity check, we can derive the variance function from this autocovariance function: \\[ V_N(t) = C_N(t, t) = \\lambda \\min(t, t) = \\lambda t. \\] This agrees with what we got in Example 51.2. Example 52.3 (White Noise) Consider the white noise process \\(\\{ Z[n] \\}\\) defined in Example 47.2, which consists of i.i.d. random variables with variance \\(\\sigma^2 \\overset{\\text{def}}{=} \\text{Var}[Z[n]]\\). By independence, the covariance between \\(Z[m]\\) and \\(Z[n]\\) is zero, unless \\(m=n\\), in which case \\(\\text{Cov}[Z[n], Z[n]] = \\text{Var}[Z[n]] = \\sigma^2\\). That is, the autocovariance function is \\[ C_Z[m, n] = \\begin{cases} \\sigma^2 &amp; m = n \\\\ 0 &amp; m \\neq n \\end{cases}. \\] We can write the autocovariance function compactly using the discrete delta function \\(\\delta[k]\\), defined as \\[ \\delta[k] \\overset{def}{=} \\begin{cases} 1 &amp; k=0 \\\\ 0 &amp; k \\neq 0 \\end{cases}. \\] In terms of \\(\\delta[k]\\), the autocovariance function is simply \\[ C_Z[m, n] = \\sigma^2 \\delta[m - n]. \\] As a sanity check, we can derive the variance function from this autocovariance function: \\[ V_Z[n] = C_Z[n, n] = \\sigma^2 \\delta[n - n] = \\sigma^2 \\delta[0] = \\sigma^2. \\] This agrees with what we got in Example 51.3. Example 52.4 (Random Walk) Consider the random walk process \\(\\{ X[n]; n\\geq 0 \\}\\) from Example 47.3. To calculate the autocovariance function, we first calculate \\(\\text{Cov}[X[m], X[n]]\\) assuming \\(m &lt; n\\). Since \\[ X[n] = Z[1] + Z[2] + \\ldots + Z[n], \\] we can write this as \\[\\begin{align*} \\text{Cov}[X[m], X[n]] = \\text{Cov}[&amp;Z[1] + \\ldots + Z[m], \\\\ &amp;Z[1] + \\ldots + Z[m] + \\ldots + Z[n]]. \\end{align*}\\] I find it helpful to write the covariance in two lines, aligning like terms, since the \\(Z[i]\\)s are independent. When we expand the covariance, it reduces to \\[ \\text{Var}[Z[1]] + \\ldots + \\text{Var}[Z[m]] = m \\text{Var}[Z[1]]. \\] This is the covariance when \\(m &lt; n\\). If we repeat the argument for \\(m &gt; n\\), we will find that the covariance is \\(n \\text{Var}[Z[1]]\\). In other words, the covariance always involves the smaller of the two times \\(m\\) and \\(n\\). Therefore, we can write the autocovariance function as \\[ C_X[m, n] = \\min(m, n) \\text{Var}[Z[1]]. \\] As a sanity check, we can derive the variance function from this autocovariance function: \\[ V_X[n] = C_X[n, n] = n \\text{Var}[Z[1]]. \\] This agrees with what we got in Example 51.4. Essential Practice Consider a grain of pollen suspended in water, whose horizontal position can be modeled by Brownian motion \\(\\{B(t)\\}\\) with parameter \\(\\alpha=4 \\text{mm}^2/\\text{s}\\), as in Example 49.1. Calculate the autocovariance function of \\(\\{ B(t) \\}\\). Check that this autocovariance function agrees with the variance function you derived in Lesson 51. Radioactive particles hit a Geiger counter according to a Poisson process at a rate of \\(\\lambda=0.8\\) particles per second. Let \\(\\{ N(t); t \\geq 0 \\}\\) represent this Poisson process. Define the new process \\(\\{ D(t); t \\geq 3 \\}\\) by \\[ D(t) = N(t) - N(t - 3). \\] This process represents the number of particles that hit the Geiger counter in the last 3 seconds. Calculate the autocovariance function of \\(\\{ D(t); t \\geq 3 \\}\\). Check that this autocovariance function agrees with the variance function you derived in Lesson 51. (Hint: Start by calculating \\(\\text{Cov}[D(s), D(t)]\\) when \\(s &gt; t\\). What happens when \\(s &gt; t + 3\\)? What happens when \\(t &lt; s &lt; t + 3\\)? Once you’ve worked this out, it should be straightforward to extend this to the case \\(s &lt; t\\).) Consider the moving average process \\(\\{ X[n] \\}\\) of Example 48.2, defined by \\[ X[n] = 0.5 Z[n] + 0.5 Z[n-1], \\] where \\(\\{ Z[n] \\}\\) is a sequence of i.i.d. standard normal random variables. Calculate the autocovariance function of \\(\\{ X[n] \\}\\). Check that this autocovariance function agrees with the variance function you derived in Lesson 51. (Hint: Consider the following cases: (1) \\(m = n\\), (2) \\(m = n+1\\), (3) \\(m = n-1\\), (4) \\(m &gt; n+1\\), (5) \\(m &lt; n-1\\).) Let \\(\\Theta\\) be a \\(\\text{Uniform}(a=-\\pi, b=\\pi)\\) random variable, and let \\(f\\) be a constant. Define the random phase process \\(\\{ X(t) \\}\\) by \\[ X(t) = \\cos(2\\pi f t + \\Theta). \\] Calculate the autocovariance function of \\(\\{ X(t) \\}\\). Check that this autocovariance function agrees with the variance function you derived in Lesson 51. (Hint: Use the shortcut formula for covariance. Calculate \\(E[X(s) X(t)]\\) by LOTUS.) "],
["stationary.html", "Lesson 53 Stationary Processes Motivation Theory Essential Practice", " Lesson 53 Stationary Processes Motivation What does it mean for a random process to remain the “same” over time? Obviously, the exact values will be different, since the process is random. The notion of a “stationary process” makes this notion precise. Theory Definition 53.1 (Stationary Process) A process \\(\\{ X(t) \\}\\) is called strict-sense stationary if the process is completely invariant under time shifts. That is, the distribution of \\[ (X(t_1), X(t_2), ..., X(t_n)) \\] matches the distribution of \\[ (X(t_1 + \\tau), X(t_2 + \\tau), ..., X(t_n + \\tau)) \\] for any times \\(t_1, ..., t_n\\) and any time shift \\(\\tau\\). However, we will mostly be concerned with wide-sense stationary processes, which is less restrictive. A random process \\(\\{ X(t) \\}\\) is wide-sense stationary if its mean and autocovariance function are invariant under time shifts. That is: The mean function \\(\\mu_X(t)\\) is constant. In this case, we will write the mean function as \\(\\mu_X(t) \\equiv \\mu_X\\). The autocovariance function \\(C_X(s, t)\\) only depends on \\(s - t\\), the difference between the times. In this case, we will write the autocovariance function as \\(C_X(s, t) = C_X(s - t)\\). (For a discrete-time process, we require the autocovariance function \\(C_X[m, n]\\) to only depend on \\(m - n\\), and we write \\(C_X[m, n] = C_X[m - n]\\).) Let’s determine whether some random processes are wide-sense stationary. Example 53.1 (Random Amplitude Process) Consider the random amplitude process \\[\\begin{equation} X(t) = A\\cos(2\\pi f t) \\tag{50.2} \\end{equation}\\] introduced in Example 48.1. In Example 50.1, we showed that its mean function is \\[ \\mu_X(t) = 2.5 \\cos(2\\pi f t). \\] This is not constant in \\(t\\), so this process cannot be wide-sense stationary. We do not even need to check the autocovariance function. If we look at a graph of the process, it is clearly not stationary. If we shift the process by any amount that is less than a full period, then the process looks different. Shown on the graph below are 20 realizations of the original process \\(\\{ X(t) \\}\\) in blue, as well as 20 realizations of the time-shifted process \\(\\{ X(t - 0.3) \\}\\). The peaks and troughs are in different places. Example 53.2 (Poisson Process) Consider the Poisson process \\(\\{ N(t); t \\geq 0 \\}\\) of rate \\(\\lambda\\), defined in Example 47.1. In Example 50.2, we showed that its mean function is \\[ \\mu_N(t) = \\lambda t. \\] This is not constant in \\(t\\), so we know that this process cannot be wide-sense stationary. We do not even need to check the autocovariance function. Again, the fact that the Poisson process is not stationary is immediately apparent from a graph of the process. Shown below are 20 realizations of the original process \\(\\{ N(t) \\}\\) in blue, as well as 20 realizations of the time-shifted process \\(\\{ N(t - 1) \\}\\) in red. The time-shifted process may not even start at 0 at time 0! Example 53.3 (White Noise) Consider the white noise process \\(\\{ Z[n] \\}\\) defined in Example 47.2, which consists of i.i.d. random variables with mean \\(\\mu = E[Z[n]]\\) and variance \\(\\sigma^2 \\overset{\\text{def}}{=} \\text{Var}[Z[n]]\\). In Example 50.3, we showed that its mean function is \\[ \\mu_Z[n] \\equiv \\mu, \\] which is constant, so the process could be wide-sense stationary. We need to check its autocovariance function. In Example 52.3, we showed that its autocovariance function is \\[ C_Z[m, n] = \\begin{cases} \\sigma^2 &amp; m = n \\\\ 0 &amp; m \\neq n \\end{cases}. \\] To see that this is a function of \\(m - n\\), we rewrite \\(m = n\\) as \\(m - n = 0\\): \\[ C_Z[m, n] = \\begin{cases} \\sigma^2 &amp; m - n = 0 \\\\ 0 &amp; m - n \\neq 0 \\end{cases}. \\] This can be written more compactly using the discrete delta function \\(\\delta[k]\\), defined as \\[ \\delta[k] \\overset{def}{=} \\begin{cases} 1 &amp; k=0 \\\\ 0 &amp; k \\neq 0 \\end{cases}. \\] In terms of \\(\\delta[k]\\), the autocovariance function is simply \\[ C_Z[m, n] = \\sigma^2 \\delta[m - n]. \\] The graph below shows white noise \\(\\{ Z[n] \\}\\) in blue and time-shifted white noise \\(\\{ Z[n-1] \\}\\) in red. Visually, it is hard to tell the difference between the two, which is intutively why the process is stationary. Example 53.4 (Random Walk) Consider the random walk process \\(\\{ X[n]; n\\geq 0 \\}\\) from Example 47.3. In Example 50.4, we calculated the mean function to be \\[ \\mu[n] = 0. \\] This is constant, so the process might be wide-sense stationary. But we also need to check the autocovariance function. In Example 52.4, we calculated the autocovariance function to be \\[ C[m, n] = \\min(m, n) \\text{Var}[Z[1]]. \\] This is not just a function of \\(m - n\\), so the process is not wide-sense stationary. You might ask, “How can we be sure that there isn’t some way to manipulate \\(\\min(m, n)\\) so that it is a function of \\(m-n\\)?” We can prove that it is impossible by testing a few pairs of values. For example, \\((m, n) = (3, 2)\\) and \\((m, n) = (6, 5)\\) are two pairs of values that are both separated in time by \\(m - n = 1\\) samples. If it were possible to reduce \\(C[m, n]\\) to a function \\(C[m - n]\\) of the difference only, then \\(C[3, 2]\\) would have to equal \\(C[6, 5]\\). However, they are not equal: \\(C[3, 2] = 2 \\text{Var}[Z[1]]\\), while \\(C[6, 5] = 5 \\text{Var}[Z[1]]\\). Example 53.5 Let \\(\\{ X(t) \\}\\) be a continuous-time random process with \\(E[X(t)] = 2\\) for all \\(t\\), and \\(\\text{Cov}[X(s), X(t)] = 5e^{-3(s - t)^2}\\) for all \\(s\\) and \\(t\\). The mean function \\(\\mu_X(t) = E[X(t)]\\) is constant and the autocovariance function \\(C_X(s, t) = 5e^{-3(s - t)^2}\\) is a function of \\(\\tau = s - t\\) only, so the process is stationary. Since the process is stationary, we can write the mean and autocovariance functions as \\[\\begin{align*} \\mu_X &amp;= 2 &amp; C_X(\\tau) &amp;= 5e^{-3\\tau^2}. \\end{align*}\\] Essential Practice For these practice questions, you may want to refer to the mean and autocovariance functions you calculated in Lessons 50 and 52. Consider a grain of pollen suspended in water, whose horizontal position can be modeled by Brownian motion \\(\\{B(t); t \\geq 0\\}\\) with parameter \\(\\alpha=4 \\text{mm}^2/\\text{s}\\), as in Example 49.1. Is \\(\\{ B(t); t \\geq 0 \\}\\) wide-sense stationary? Radioactive particles hit a Geiger counter according to a Poisson process at a rate of \\(\\lambda=0.8\\) particles per second. Let \\(\\{ N(t); t \\geq 0 \\}\\) represent this Poisson process. Define the new process \\(\\{ D(t); t \\geq 3 \\}\\) by \\[ D(t) = N(t) - N(t - 3). \\] This process represents the number of particles that hit the Geiger counter in the last 3 seconds. Is \\(\\{ D(t); t \\geq 3 \\}\\) wide-sense stationary? Consider the moving average process \\(\\{ X[n] \\}\\) of Example 48.2, defined by \\[ X[n] = 0.5 Z[n] + 0.5 Z[n-1], \\] where \\(\\{ Z[n] \\}\\) is a sequence of i.i.d. standard normal random variables. Is \\(\\{ X[n] \\}\\) wide-sense stationary? (Hint: You can write \\(m = n + 1\\) as \\(m - n = 1\\).) Let \\(\\Theta\\) be a \\(\\text{Uniform}(a=-\\pi, b=\\pi)\\) random variable, and let \\(f\\) be a constant. Define the random phase process \\(\\{ X(t) \\}\\) by \\[ X(t) = \\cos(2\\pi f t + \\Theta). \\] Is \\(\\{ X(t) \\}\\) wide-sense stationary? "],
["autocorrelation.html", "Lesson 54 Autocorrelation Function Theory Essential Practice", " Lesson 54 Autocorrelation Function Theory In this lesson, we introduce a summary of a random process that is closely related to the mean and autocovariance functions. This function plays a crucial role in signal processing. Definition 54.1 (Autocorrelation Function) The autocorrelation function \\(R_X(s, t)\\) of a random process \\(\\{ X(t) \\}\\) is a function of two times \\(s\\) and \\(t\\). It specifies \\[\\begin{equation} R_X(s, t) \\overset{\\text{def}}{=} E[X(s)X(t)]. \\tag{54.1} \\end{equation}\\] By the shortcut formula for covariance (29.2), \\(E[X(s) X(t)] = \\text{Cov}[X(s), X(t)] + E[X(s)] E[X(t)]\\), so the autocorrelation function can be related to the mean function (50.1) and autocovariance function \\[ R_X(s, t) = C_X(s, t) + \\mu_X(s) \\mu_X(t). \\] For a stationary process (Definition 53), the autocorrelation function only depends on the difference between the times \\(\\tau = s - t\\): \\[ R_X(\\tau) = C_X(\\tau) + \\mu_X^2 \\] For a discrete-time process, we notate the autocorrelation function as \\[ R_X[m, n] \\overset{\\text{def}}{=} C_X[m, n] + \\mu_X[m] \\mu_X[n]. \\] Let’s calculate the autocorrelation function of some random processes. Example 54.1 (Random Amplitude Process) Consider the random amplitude process \\[\\begin{equation} X(t) = A\\cos(2\\pi f t) \\tag{50.2} \\end{equation}\\] introduced in Example 48.1. Its autocorrelation function is \\[\\begin{equation} R_X(s, t) = C_X(s, t) + \\mu_X(s) \\mu_X(t) = (1.25 + 2.5^2) \\cos(2\\pi f s) \\cos(2\\pi f t). \\tag{54.2} \\end{equation}\\] Example 54.2 (Poisson Process) Consider the Poisson process \\(\\{ N(t); t \\geq 0 \\}\\) of rate \\(\\lambda\\), defined in Example 47.1. Its autocorrelation function is \\[\\begin{equation} R_X(s, t) = C_X(s, t) + \\mu_X(s) \\mu_X(t) = \\lambda\\min(s, t) + \\lambda^2 s t. \\tag{54.3} \\end{equation}\\] Example 54.3 (White Noise) Consider the white noise process \\(\\{ Z[n] \\}\\) defined in Example 47.2, which consists of i.i.d. random variables with mean \\(\\mu = E[Z[n]]\\) and variance \\(\\sigma^2 \\overset{\\text{def}}{=} \\text{Var}[Z[n]]\\). We showed in Example 53.3 that this process is stationary, so its autocorrelation function depends only on \\(k = m - n\\): \\[\\begin{equation} R_Z[k] = C_Z[k] + \\mu_Z^2 = \\sigma^2\\delta[k] + \\mu^2. \\tag{54.4} \\end{equation}\\] Example 54.4 (Random Walk) Consider the random walk process \\(\\{ X[n]; n\\geq 0 \\}\\) from Example 47.3. Its autocorrelation function is: \\[\\begin{equation} R_X[m, n] = C_X[m, n] + \\underbrace{\\mu_X[m]}_{0} \\mu_Y[n] = \\sigma^2 \\min(m, n). \\tag{54.5} \\end{equation}\\] Example 54.5 Consider the stationary process \\(\\{X(t)\\}\\) from Example 53.5, whose mean and autocovariance functions are \\[\\begin{align*} \\mu_X &amp;= 2 &amp; C_X(\\tau) &amp;= 5e^{-3\\tau^2}. \\end{align*}\\] Its autocorrelation function likewise depends on \\(\\tau = s - t\\) only: \\[\\begin{equation} R_X(\\tau) = C_X(\\tau) + \\mu_X^2 = 5 e^{-3\\tau^2} + 4. \\tag{54.6} \\end{equation}\\] Essential Practice For these questions, you may want to refer to the mean and autocovariance functions you calculated in Lessons 50 and 52. Consider a grain of pollen suspended in water, whose horizontal position can be modeled by Brownian motion \\(\\{B(t); t \\geq 0\\}\\) with parameter \\(\\alpha=4 \\text{mm}^2/\\text{s}\\), as in Example 49.1. Calculate the autocorrelation function of \\(\\{ B(t); t \\geq 0 \\}\\). Radioactive particles hit a Geiger counter according to a Poisson process at a rate of \\(\\lambda=0.8\\) particles per second. Let \\(\\{ N(t); t \\geq 0 \\}\\) represent this Poisson process. Define the new process \\(\\{ D(t); t \\geq 3 \\}\\) by \\[ D(t) = N(t) - N(t - 3). \\] This process represents the number of particles that hit the Geiger counter in the last 3 seconds. Calculate the autocorrelation function of \\(\\{ D(t); t \\geq 3 \\}\\). Consider the moving average process \\(\\{ X[n] \\}\\) of Example 48.2, defined by \\[ X[n] = 0.5 Z[n] + 0.5 Z[n-1], \\] where \\(\\{ Z[n] \\}\\) is a sequence of i.i.d. standard normal random variables. Calculate the autocorrelation function of \\(\\{ X[n] \\}\\). Let \\(\\Theta\\) be a \\(\\text{Uniform}(a=-\\pi, b=\\pi)\\) random variable, and let \\(f\\) be a constant. Define the random phase process \\(\\{ X(t) \\}\\) by \\[ X(t) = \\cos(2\\pi f t + \\Theta). \\] Calculate the autocorrelation function of \\(\\{ X(t) \\}\\). Let \\(\\{ X(t) \\}\\) be a continuous-time random process with mean function \\(\\mu_X(t) = -1\\) and autocovariance function \\(C_X(s, t) = 2e^{-|s - t|/3}\\). Calculate the autocorrelation function of \\(\\{ X(t) \\}\\). "],
["power.html", "Lesson 55 Power of a Stationary Process Motivation Theory Essential Practice", " Lesson 55 Power of a Stationary Process Motivation This lesson is the first in a series of lessons about the processing of random signals. The two most common kinds of random signals that are studied in electrical engineering are voltage signals \\(\\{ V(t) \\}\\) and current signals \\(I(t)\\). These signals are often modulated while the other aspects of the circuit (e.g., the resistance) are held constant. The (instantaneous) power dissipated by the circuit is then \\[ \\text{Power}(t) = I(t)^2 R = \\frac{V(t)^2}{R}. \\] In other words, the power is proportional to the square of the signal. Theory For this reason, the (instantaneous) power of a general signal \\(\\{ X(t) \\}\\) is defined as \\[ \\text{Power}_X(t) = X(t)^2. \\] When the signal is random, it makes sense to report its expected value, rather than its Definition 55.1 (Expected Power) The expected power of a random process \\(\\{ X(t) \\}\\) is defined as \\[ E[X(t)^2]. \\] Notice that the expected power is related to the autocorrelation function (54.1) by \\[ E[X(t)^2] = R_X(t, t). \\] For a stationary process, the autocorrelation function only depends on the difference between the times, \\(R_X(\\tau)\\), so the expected power of a stationary process is \\[ E[X(t)^2] = R_X(0). \\] Since most noise signals are stationary, we will only calculate expected power for stationary signals. Example 55.1 (White Noise) Consider the white noise process \\(\\{ Z[n] \\}\\) defined in Example 47.2, which consists of i.i.d. random variables with mean \\(\\mu = E[Z[n]]\\) and variance \\(\\sigma^2 \\overset{\\text{def}}{=} \\text{Var}[Z[n]]\\). This process is stationary, with autocorrelation function \\[ R_Z[k] = \\sigma^2\\delta[k] + \\mu^2, \\] so its expected power is \\[ R_Z[0] = \\sigma^2\\delta[0] + \\mu^2 = \\sigma^2 + \\mu^2. \\] Example 55.2 Consider the process \\(\\{X(t)\\}\\) from Example 53.5. This process is stationary, with autocorrelation function \\[ R_X(\\tau) = 5 e^{-3\\tau^2} + 4, \\] so its expected power is \\[ R_X(0) = 5 e^{-3 \\cdot 0^2} + 4 = 9. \\] Essential Practice For these questions, you may want to refer to the autocorrelation function you calculated in Lesson 54. Radioactive particles hit a Geiger counter according to a Poisson process at a rate of \\(\\lambda=0.8\\) particles per second. Let \\(\\{ N(t); t \\geq 0 \\}\\) represent this Poisson process. Define the new process \\(\\{ D(t); t \\geq 3 \\}\\) by \\[ D(t) = N(t) - N(t - 3). \\] This process represents the number of particles that hit the Geiger counter in the last 3 seconds. Calculate the expected power in \\(\\{ D(t); t \\geq 3 \\}\\). Consider the moving average process \\(\\{ X[n] \\}\\) of Example 48.2, defined by \\[ X[n] = 0.5 Z[n] + 0.5 Z[n-1], \\] where \\(\\{ Z[n] \\}\\) is a sequence of i.i.d. standard normal random variables. Calculate the expected power in \\(\\{ X[n] \\}\\). Let \\(\\Theta\\) be a \\(\\text{Uniform}(a=-\\pi, b=\\pi)\\) random variable, and let \\(f\\) be a constant. Define the random phase process \\(\\{ X(t) \\}\\) by \\[ X(t) = \\cos(2\\pi f t + \\Theta). \\] Calculate the expected power in \\(\\{ X(t) \\}\\). Let \\(\\{ X(t) \\}\\) be a continuous-time random process with mean function \\(\\mu_X(t) = -1\\) and autocovariance function \\(C_X(s, t) = 2e^{-|s - t|/3}\\). Calculate the expected power of \\(\\{ X(t) \\}\\). "],
["psd.html", "Lesson 56 Power Spectral Density Motivation Theory Essential Practice", " Lesson 56 Power Spectral Density Motivation In Lesson 55, we saw that the expected power of a stationary random signal \\(\\{ X(t) \\}\\) could be calculated by evaluating the autocorrelation function \\(R_X(\\tau)\\) at a difference of \\(\\tau = 0\\). But how is this expected power distributed across different frequencies? The answer also involves the autocorrelation function. Theory Definition 56.1 (Power Spectral Density) The power spectral density (or PSD, for short) \\(S_X(f)\\) of a stationary random process \\(\\{ X(t) \\}\\) is the Fourier transform of the autocorrelation function \\(R_X(\\tau)\\). (Note: Because the process is stationary, the autocorrelation only depends on the difference \\(\\tau = s - t\\).) That is, the autocorrelation function and the power spectral density are Fourier pairs. \\[\\begin{equation} R_X(\\tau) \\overset{\\mathscr{F}}{\\longleftrightarrow} S_X(f). \\tag{56.1} \\end{equation}\\] Because the autocorrelation function \\(R_X(\\tau)\\) is symmetric and real-valued, its Fourier transform is guaranteed to also be symmetric and real-valued. See the Essential Practice exercise in Appendix C. The term “power spectral density” suggests that \\(S_X(f)\\) satisfies two properties: the integral of \\(S_X(f)\\) over all frequencies equals the expected power the integral of \\(S_X(f)\\) over any frequency band equals the expected power in that frequency band. For now, we will only prove the first property, deferring the proof of the second property to Lesson 58. Theorem 56.1 (Power Spectral Density and Expected Power) The integral of the PSD \\(S_X(f)\\) over “all” frequencies equals the expected power in \\(\\{ X(t) \\}\\). For continuous-time processes, this result can be stated as: \\[\\begin{equation} \\int_{-\\infty}^\\infty S_X(f)\\,df = R_X(0) = E[X(t)^2]. \\end{equation}\\] For discrete-time processes, this result can be stated as: \\[\\begin{equation} \\int_{-0.5}^{0.5} S_X(f)\\,df = R_X[0] = E[X[n]^2]. \\end{equation}\\] Proof. We will prove the result for continuous-time processes. The proof for discrete-time processes is similar. By the “DC offset” property of Fourier transforms (Appendix D.3), the total integral of a signal in the time domain equals the value of the signal at 0 in the frequency domain, and vice versa. To prove this, observe that \\[ G(0) \\overset{\\text{def}}{=} \\int_{-\\infty}^\\infty g(t) e^{-j2\\pi \\cdot 0 t}\\,dt = \\int_{-\\infty}^\\infty g(t)\\,dt. \\] Since \\(S_X\\) and \\(R_X\\) are Fourier pairs, we have \\[ \\int_{-\\infty}^\\infty S_X(f)\\,df = R_X(0), \\] as we wanted to show. Example 56.1 (White Noise) Consider the white noise process \\(\\{ Z[n] \\}\\) defined in Example 47.2, which consists of i.i.d. random variables with mean \\(\\mu = E[Z[n]]\\) and variance \\(\\sigma^2 \\overset{\\text{def}}{=} \\text{Var}[Z[n]]\\). This process is stationary, with autocorrelation function \\[ R_Z[k] = \\sigma^2\\delta[k] + \\mu^2. \\] The power spectral density is its Fourier transform. Using linearity and the Discrete-Time Fourier Transform table in Appendix D.2, we see that \\[ S_Z(f) = \\sigma^2 + \\mu^2 \\delta(f). \\] This PSD is graphed below for \\(\\mu=-1.5\\) and \\(\\sigma^2 = 1.7\\). Note that this power spectral density is only defined for frequencies below the Nyquist limit: \\(|f| &lt; 0.5\\). We see that white noise has equal power at all frequencies, except at 0 Hz (DC). To check that we calculated the PSD correctly, we can integrate it over “all” frequencies and make sure that it matches the expected power that we obtain by evaluating the autocorrelation function at 0 (see Lesson 55). Because this is a discrete-time signal, we only integrate over frequencies below the Nyquist limit, \\(|f| &lt; 0.5\\). \\[ \\int_{-0.5}^{0.5} S_Z(f)\\,df = \\int_{-0.5}^{0.5} \\sigma^2\\,df + \\mu^2 \\int_{-0.5}^{0.5} \\delta(f)\\,df = \\sigma^2 + \\mu^2 \\] This matches \\(R_Z[0] = \\sigma^2 \\delta[0] + \\mu^2 = \\sigma^2 + \\mu^2\\). The power in this signal below 0.2 cycles/sample can be calculated by integrating the PSD over that frequency range, remembering to include both positive and negative frequencies. \\[ \\int_{-0.2}^{0.2} S_Z(f)\\,df = \\int_{-0.2}^{0.2} \\sigma^2\\,df + \\mu^2 \\int_{-0.2}^{0.2} \\delta(f)\\,df = 0.4\\sigma^2 + \\mu^2. \\] Example 56.2 Consider the process \\(\\{X(t)\\}\\) from Example 53.5. This process is stationary, with autocorrelation function \\[ R_X(\\tau) = 5 e^{-\\tau^2 / 3} + 4. \\] The power spectral density is its Fourier transform. Using linearity, scaling, and the Continuous-Time Fourier Transform table in Appendix D.1, we see that \\[\\begin{align*} S_X(f) &amp;= \\mathscr{F}[5 e^{-3 \\tau^2} + 4] \\\\ &amp;= 5 \\mathscr{F}[\\underbrace{e^{-3 \\tau^2}}_{e^{-\\pi \\left(\\sqrt{\\frac{3}{\\pi}}\\tau\\right)^2}}] + 4 \\mathscr{F}[1] &amp; \\text{(linearity)} \\\\ &amp;= 5 \\sqrt{\\frac{\\pi}{3}} e^{-\\pi (\\sqrt{\\frac{\\pi}{3}} f)^2} + 4 \\delta(f) &amp; \\text{(scaling by $a = \\sqrt{\\frac{3}{\\pi}}$)} \\end{align*}\\] Notice how we massaged \\(e^{-3\\tau^2}\\) into the form \\(e^{-\\pi (a\\tau)^2}\\), which is a scale transform of one of the functions in Appendix D.1. This power spectral density is graphed below. We see that this process has more power at the lower frequencies than at the higher frequencies. One way to check that we calculated the PSD correctly is to integrate it over all frequencies and making sure it matches the expected power we calculated in Lesson 55. \\[ \\int_{-\\infty}^{\\infty} S_X(f)\\,df = \\int_{-\\infty}^{\\infty} 5 \\sqrt{\\frac{\\pi}{3}} e^{-\\pi^2 f^2 / 3}\\,df + 4 \\int_{-\\infty}^{\\infty} \\delta(f)\\,df = 5 + 4 = 9. \\] The power in this signal below above 1 Hz can be calculated by integrating the PSD, remembering to include both positive and negative frequencies. Since the PSD is symmetric, the easiest way to do this is to double the integral over \\(1 &lt; f &lt; \\infty\\). \\[ 2 \\int_{1}^{\\infty} S_X(f)\\,df = 2 \\int_1^{\\infty} 5 \\sqrt{\\frac{\\pi}{3}} e^{-\\pi^2 f^2 / 3}\\,df = .0515. \\] Essential Practice For these questions, you may want to refer to the autocorrelation function you calculated in Lesson 54. Radioactive particles hit a Geiger counter according to a Poisson process at a rate of \\(\\lambda=0.8\\) particles per second. Let \\(\\{ N(t); t \\geq 0 \\}\\) represent this Poisson process. Define the new process \\(\\{ D(t); t \\geq 3 \\}\\) by \\[ D(t) = N(t) - N(t - 3). \\] This process represents the number of particles that hit the Geiger counter in the last 3 seconds. Calculate the PSD of \\(\\{ D(t); t \\geq 3 \\}\\). What is the expected power above 1 Hz? Consider the moving average process \\(\\{ X[n] \\}\\) of Example 48.2, defined by \\[ X[n] = 0.5 Z[n] + 0.5 Z[n-1], \\] where \\(\\{ Z[n] \\}\\) is a sequence of i.i.d. standard normal random variables. Calculate the PSD of \\(\\{ X[n] \\}\\). What is the expected power below 0.1 cycles per sample? Let \\(\\Theta\\) be a \\(\\text{Uniform}(a=-\\pi, b=\\pi)\\) random variable, and let \\(f\\) be a constant. Define the random phase process \\(\\{ X(t) \\}\\) by \\[ X(t) = \\cos(2\\pi f t + \\Theta). \\] Calculate the PSD of \\(\\{ X(t) \\}\\). Let \\(\\{ X(t) \\}\\) be a continuous-time random process with mean function \\(\\mu_X(t) = -1\\) and autocovariance function \\(C_X(s, t) = 2e^{-|s - t|/3}\\). Calculate the PSD of \\(\\{ X(t) \\}\\). What is the expected power below 3 Hz? "],
["lti-time.html", "Lesson 57 LTI Filters in the Time Domain Motivation Review Theory Essential Practice", " Lesson 57 LTI Filters in the Time Domain Motivation What happens when we pass a stationary random signal \\(\\{ X(t) \\}\\) into a filter \\(\\mathcal{L}\\)? This lesson studies the properties of the output signal \\(\\{ Y(t) \\}\\), which is also a random process. Figure 57.1: Filtering a Signal Review We begin this lesson by recalling a few basic facts about linear time-invariant filters. This material can be found in any signals and systems textbook. Definition 57.1 (Linear Time-Invariant Filter) A filter \\(\\mathcal{L}\\) takes an input signal \\(x(t)\\) and produces an output signal \\(y(t)\\). In general, a filter can do anything to a signal. We will restrict our attention to a specific class of filters called linear time-invariant (or LTI, for short) filters. An LTI filter satisfies the following properties: linearity: \\(\\mathcal{L}[a_1x_1 + a_2x_2] = a_1\\mathcal{L}[x_1] + a_2\\mathcal{L}[x_2]\\) for any constants \\(a_1, a_2\\) and signals \\(x_1, x_2\\). time-invariance: \\(\\mathcal{L}[x(t - \\tau)](t) = \\mathcal{L}[x](t - \\tau)\\) for any shift \\(\\tau\\). In other words, if the input signal \\(x(t)\\) is delayed by \\(\\tau\\) seconds, then the output signal \\(y(t)\\) is also delayed by \\(\\tau\\) seconds, without any other modifications. Theorem 57.1 (Impulse Response) Let \\(h(t)\\) denote the impulse response of an LTI filter \\(\\mathcal{L}\\). That is, \\(h \\overset{\\text{def}}{=} \\mathcal{L}[\\delta]\\) is the output signal when the input signal is an impulse \\(\\delta(t)\\). Then, \\(\\mathcal{L}\\) acts by convolving \\(h\\) with the input signal \\(x\\). That is, \\[ y(t) = (h * x)(t). \\] Proof. We will prove this result for discrete-time signals, although the proof for continuous-time signals is similar. First, write \\(x = x * \\delta\\). Any signal convolved with a delta function is itself. This is called the sifting property of the delta function. To see why this is true, write out the definition of convolution: \\[ x[n] = \\sum_{m=-\\infty}^\\infty x[m] \\delta[n-m]. \\] All terms in this sum will be zero, except when \\(m=n\\), when the term is \\(x[n] \\delta[0] = x[n]\\). From here, we just apply linearity and time-invariance. \\[\\begin{align*} y[n] = \\mathcal{L}\\big[x[n]\\big][n] &amp;= \\mathcal{L}\\Big[\\sum_{m=-\\infty}^\\infty x[m] \\delta[n - m]\\Big][n] &amp; \\text{(sifting property)} \\\\ &amp;= \\sum_{m=-\\infty}^\\infty x[m] \\mathcal{L}\\big[\\delta[n-m]\\big][n] &amp; \\text{(linearity)} \\\\ &amp;= \\sum_{m=-\\infty}^\\infty x[m] h[n-m] &amp; \\text{(time-invariance)}. \\end{align*}\\] This is just the definition of convolution: \\(h * x\\). Because the impulse response uniquely describes any LTI filter, it is common to redraw Figure 57.1, using \\(h\\) to symbolize the filter. Figure 57.2: Linear Time-Invariant Filter, represented by its impulse response \\(h\\) Example 57.1 (Infinite Impulse Response (IIR) Filter) Consider the discrete-time filter defined by \\[ y[n] = a_1 y[n-1] + x[n]. \\] Find the impulse response of this filter. Solution. The impulse response \\(h[n]\\) is the output of the filter when the input is the unit impulse \\(\\delta[n]\\). That is, if \\(x[n] = \\delta[n]\\), then \\(y[n] = h[n]\\). Therefore, we have the relation \\[ h[n] = a_1 h[n-1] + \\delta[n] \\] for all \\(n\\). First, we observe that \\(h[n] = 0\\) for all \\(n &lt; 0\\). For \\(n \\geq 0\\), we can calculate \\(h[n]\\) recursively: \\[\\begin{align*} h[0] &amp;= a_1 h[-1] + \\delta[0] = a_1 \\cdot 0 + 1 = 1 \\\\ h[1] &amp;= a_1 h[0] + \\delta[1] = a_1 \\cdot 1 + 0 = a_1 \\\\ h[2] &amp;= a_1 h[1] + \\delta[2] = a_1 \\cdot a_1 + 0 = a_1^2 \\\\ h[3] &amp;= a_1 h[2] + \\delta[3] = a_1 \\cdot a_1^2 + 0 = a_1^3 \\\\ &amp;\\vdots \\end{align*}\\] At this point, the pattern is hopefully clear. We can write the impulse response as \\[ h[n] = \\begin{cases} a_1^n &amp; n \\geq 0 \\\\ 0 &amp; n &lt; 0 \\end{cases} = a_1^n u[n], \\] where \\(u[n]\\) is the unit step function, defined to be 1 when \\(n \\geq 0\\) and 0 otherwise. This impulse response is graphed below for \\(a_1 = 0.7\\). Theory We are now ready to apply linear filters to stationary random processes. Theorem 57.2 (Filtering Stationary Processes) Let \\(\\{ X(t) \\}\\) be a stationary random process and \\(h(t)\\) be the impulse response of a linear time-invariant filter. If \\(\\{ X(t) \\}\\) is passed into a linear time-invariant filter with impulse response \\(h(t)\\), then the output process \\(\\{ Y(t) \\}\\) is also stationary, with mean function \\(\\mu_Y = \\mu_X \\cdot \\int_{-\\infty}^\\infty h(t)\\,dt\\), and autocovariance function \\(C_Y(\\tau) = (h(-t) * h * C_X)(\\tau)\\). For discrete-time signals, we have: mean function \\(\\mu_Y = \\mu_X \\cdot \\sum_{k=-\\infty}^\\infty h[k]\\), and autocovariance function \\(C_Y[k] = (h[-n] * h * C_X)[k]\\). Proof. We will prove the theorem for discrete-time signal, but the proof for continuous-time signals is similar. The mean function is \\[\\begin{align*} \\mu_Y[n] = E[Y[n]] &amp;= E\\left[\\sum_{k=-\\infty}^\\infty h[k] X[n-k] \\right] \\\\ &amp;= \\sum_{k=-\\infty}^\\infty h[k] \\underbrace{E[X[n-k]]}_{\\mu_X} \\\\ &amp;= \\mu_X \\sum_{k=-\\infty}^\\infty h[k]. \\end{align*}\\] The autocovariance function is \\[\\begin{align*} C_Y[m, n] = \\text{Cov}[Y[m], Y[n]] &amp;= \\text{Cov}\\left[\\sum_{k=-\\infty}^\\infty h[k] X[m-k], \\sum_{\\ell=-\\infty}^\\infty h[\\ell] X[n - \\ell] \\right] \\\\ &amp;= \\sum_{k=-\\infty}^\\infty \\sum_{\\ell=-\\infty}^\\infty h[k] h[\\ell] \\text{Cov}[X[m-k], X[n-\\ell]] \\\\ &amp;= \\sum_{\\ell=-\\infty}^\\infty h[\\ell] \\sum_{k=-\\infty}^\\infty h[k] C_X[(m-n) + \\ell - k] \\\\ &amp;= \\sum_{\\ell=-\\infty}^\\infty h[\\ell] (h * C_X)[(m-n) + \\ell] \\\\ &amp;= \\sum_{\\ell=-\\infty}^\\infty h[-\\ell] (h * C_X)[(m-n) - \\ell] \\\\ &amp;= (h[-n] * h * C_X)[m-n] \\end{align*}\\] Since the mean function is constant and the autocovariance function only depends on \\(m-n\\), \\(\\{ Y[n]\\}\\) is also stationary. Example 57.2 (Autoregressive Process) Let \\(\\{ Z[n] \\}\\) be white noise, consisting of i.i.d. random variables with mean \\(0\\) and variance \\(\\sigma^2\\). Then, the process \\[ X[n] = a_1 X[n-1] + Z[n] \\] is called an autoregressive process (of order 1). We will derive the autocovariance function of \\(\\{ X[n] \\}\\) using Theorem 57.2. Notice that \\(\\{ X[n] \\}\\) is the output signal when white noise \\(\\{ Z[n] \\}\\) is passed into the LTI filter from Example 57.1. That is, \\(\\{ X[n] \\}\\) is the output when a stationary process is passed into a filter with impulse response \\[ h[n] = (0.8)^n u[n]. \\] Therefore, we know that \\(\\{ X[n] \\}\\) is also stationary. Its mean function is \\(\\displaystyle \\mu_X = \\mu_Z \\sum_k h[k] = 0\\), since we assumed that \\(\\{ Z[n] \\}\\) was mean 0. Its autocovariance function, as a function of the difference \\(k=m-n\\), is \\[ C_X = h[-n] * h * C_Z. \\] We calculated the autocovariance function of white noise in Example 52.3: \\[ C_Z[k] = \\sigma^2 \\delta[k]. \\] Now, applying the sifting property of the delta function, we see that \\[ C_X = h[-n] * h * C_Z = \\sigma^2 (h[-n] * h). \\] So we just need to convolve the impulse response \\(h[n]\\) with a time-reversed version \\(h[-n]\\). \\[\\begin{align*} (h[-n] * h)[k] &amp;= \\sum_{m=-\\infty}^\\infty h[m] h[-(k-m)] &amp; \\text{(definition of convolution)} \\\\ &amp;= \\sum_{m=-\\infty}^\\infty a_1^{m} u[m] a_1^{m-k} u[m-k] &amp; \\text{(definition of $h$)} \\\\ &amp;= \\sum_{m=-\\infty}^\\infty a_1^{2m-k} u[m] u[m-k] &amp; \\text{(combining terms)} \\end{align*}\\] Notice that the unit step function \\(u\\) will be zero unless both \\(m \\geq 0\\) and \\(m \\geq k\\). If \\(k\\) is non-negative, then the second condition implies the first. So \\(u[m] u[m-k]\\) has the effect of changing the limits of the sum: \\[\\begin{align*} &amp;= \\sum_{m=k}^\\infty a_1^{2m-k}; k \\geq 0 \\\\ &amp;= \\frac{a_1^k}{1 - a_1^2}; k \\geq 0 &amp; \\text{(infinite geometric series)} \\end{align*}\\] Putting it all together, when \\(k\\) is non-negative, the autocovariance function of \\(\\{ X[n] \\}\\) is \\[ C_X[k] = \\sigma^2 \\frac{a_1^k}{1 - a_1^2}; k \\geq 0. \\] But covariance is symmetric, so \\(C_X[k] = C_X[-k]\\). Therefore, we can say in general that \\[ C_X[k] = \\sigma^2 \\frac{a_1^{|k|}}{1 - a_1^2}. \\] This example illustrates the power of Theorem 57.2. Although the derivation of the autocovariance function was quite involved, this derivation is still more straightforward than any of the alternatives. Essential Practice Find the power spectral density of the autoregressive process, in terms of \\(a_1\\) and \\(\\sigma\\). (Hint: Use the mean function and autocovariance function that we derived in Example 57.2.) Graph the power spectral density for \\(a_1 = 0.8\\) and \\(\\sigma = 2\\). Consider the moving average process \\(\\{ X[n] \\}\\) of Example 48.2, defined by \\[ X[n] = 0.5 Z[n] + 0.5 Z[n-1], \\] where \\(\\{ Z[n] \\}\\) is a sequence of i.i.d. standard normal random variables. Express \\(\\{ X[n] \\}\\) as white noise passed through an LTI filter. What is the impulse response of this filter? Then, use Theorem 57.2 to calculate the mean and autocovariance functions of \\(\\{ X[n] \\}\\). Check that your answers agree with the ones you obtained in Lessons 50 and 52. "],
["lti-frequency.html", "Lesson 58 LTI Filters in the Frequency Domain Motivation Theory Essential Practice", " Lesson 58 LTI Filters in the Frequency Domain Motivation In Lesson 57, we studied what LTI filters do to stationary signals in the time domain. However, it is usually easier to analyze and understand LTI filters in the frequency domain, as we explore in this lesson. Theory Theorem 58.1 (Filter Theorem) Let \\(\\{ X(t) \\}\\) be a stationary random process with power spectral density \\(S_X(f)\\). If \\(\\{ X(t) \\}\\) is passed into a linear time-invariant filter with impulse response \\(h(t)\\), then the output process \\(\\{ Y(t) \\}\\) has power spectral density \\[\\begin{equation} S_Y(f) = |H(f)|^2 \\cdot S_X(f), \\tag{58.1} \\end{equation}\\] where \\(H(f)\\) is the frequency response of the filter (i.e., the Fourier transform of the impulse response). Show/Hide Proof Proof. Theorem 57.2 provides the mean and autocovariance functions of \\(\\{ Y(t) \\}\\). We can use these to obtain the autocorrelation function of \\(\\{ Y(t) \\}\\): \\[\\begin{align*} R_Y(\\tau) &amp;= C_Y(\\tau) + \\mu_Y^2 \\\\ &amp;= (h(-t) * h * C_X)(\\tau) + \\left(\\mu_X \\int_{-\\infty}^\\infty h(t)\\,dt\\right)^2 \\\\ &amp;= (h(-t) * h * C_X)(\\tau) + (h(-t) * h * \\mu_X^2) \\\\ &amp;= (h(-t) * h * R_X)(\\tau). \\end{align*}\\] The second-to-last equality follows from the fact that the convolution of any function with a constant function (\\(\\mu_X^2\\)) is itself a constant function. So \\(h * \\mu_X^2\\) is the constant \\(\\int_{-\\infty}^\\infty h(t)\\,dt \\mu_X^2\\), and convolving this constant function with \\(h(-t)\\) gives another factor of \\(\\int_{-\\infty}^\\infty h(t)\\,dt\\). Now, we know that \\(S_Y\\), the power spectral density of \\(\\{ Y(t) \\}\\), is just the Fourier transform of the autocorrelation function \\(R_Y\\). Combining the representation of \\(R_Y\\) above with the Fourier properties from Appendix D.3, we obtain: \\[\\begin{align*} S_Y(f) &amp;= \\mathscr{F}[R_Y](f) \\\\ &amp;= \\mathscr{F}[h(-t) * h * R_X](f) \\\\ &amp;= \\mathscr{F}[h(-t)](f) \\cdot \\mathscr{F}[h](f) \\cdot \\mathscr{F}[R_X](f) &amp; \\text{(convolution property)} \\\\ &amp;= H(-f) \\cdot H(f) \\cdot S_Y(f) &amp; \\text{(definitions of $H$ and $S_Y$, reversal property)} \\\\ &amp;= H^*(f) \\cdot H(f) \\cdot S_X(f) &amp; \\text{($h$ is real, so $H$ is conjugate symmetric)} \\\\ &amp;= |H(f)|^2 \\cdot S_X(f), \\end{align*}\\] as we wanted to show. Example 58.1 (White Noise) Consider the white noise process \\(\\{ Z[n] \\}\\) defined in Example 47.2, which consists of i.i.d. random variables with mean \\(\\mu = E[Z[n]]\\) and variance \\(\\sigma^2 \\overset{\\text{def}}{=} \\text{Var}[Z[n]]\\). We showed in Example 56.1 that its PSD is \\[ S_Z(f) = \\sigma^2 + \\mu^2 \\delta(f). \\] Let’s pass \\(\\{ Z[n] \\}\\) through a filter with impulse response \\[ h[n] = (-0.4)^n u[n]. \\] What is the PSD of the output \\(\\{ Y[n] \\}\\)? Solution. By the Filter Theorem (Theorem 58.1), we know that \\[ S_Y(f) = |H(f)|^2 \\cdot S_Z(f). \\] So all we need to do is find \\(|H(f)|^2\\). By Table D.2, the frequency response of the filter is \\[ H(f) = \\frac{1}{1 + 0.4e^{-j2\\pi f}} \\] so \\[\\begin{align*} |H(f)|^2 &amp;= H(f) \\cdot H^*(f) \\\\ &amp;= \\frac{1}{1 + 0.4e^{-j2\\pi f}} \\cdot \\frac{1}{1 + 0.4e^{j2\\pi f}} \\\\ &amp;= \\frac{1}{1 + 0.4 (e^{j2\\pi f} + e^{-j2\\pi f}) + (0.4)^2} \\\\ &amp;= \\frac{1}{1.16 + 0.8\\cos(2\\pi f)}. \\end{align*}\\] Now, \\(S_Y(f)\\) is just the product of this and \\(S_Z(f)\\). \\[\\begin{align*} S_Y(f) &amp;= \\frac{1}{1.16 + 0.8\\cos(2\\pi f)} \\cdot (\\sigma^2 + \\mu^2 \\delta(f)) \\\\ &amp;= \\frac{\\sigma^2}{1.16 + 0.8\\cos(2\\pi f)} + \\frac{\\mu^2}{1.16 + 0.8\\cos(2\\pi \\cdot 0)} \\delta(f). \\end{align*}\\] The last equality follows from the fact that \\(\\delta(f) = 0\\) everywhere except \\(f=0\\), so we can substitute \\(f=0\\) into the coefficient. The graphs below show: the PSD of the input \\(S_Z(f)\\) (in red), the squared magnitude of the frequency response \\(|H(f)|^2\\) (in blue), and the PSD of the output \\(S_Y(f)\\) (in orange), for \\(\\mu=-1.5\\) and \\(\\sigma^2 = 1.7\\). Notice that the filter \\(h\\) is a highpass filter, passing high frequencies (i.e., near the Nyquist limit of 0.5) and attenuating low frequencies. We can calculate the expected power in the output signal \\(\\{ Y[n] \\}\\) by integrating the PSD over “all” frequencies. (This is the easiest way, since the autocorrelation function \\(R_Y[k]\\) is not available.) Because this is a discrete-time signal, we only integrate over frequencies below the Nyquist limit, \\(|f| &lt; 0.5\\). \\[\\begin{align*} \\int_{-0.5}^{0.5} S_Y(f)\\,df &amp;= \\int_{-0.5}^{0.5} \\frac{\\sigma^2}{1.16 + 0.8\\cos(2\\pi f)} \\,df + \\int_{-0.5}^{0.5} \\frac{\\mu^2}{1.96} \\delta(f)\\,df \\\\ &amp;\\approx 1.1905 \\sigma^2 + \\frac{\\mu^2}{1.96}. \\end{align*}\\] Example 58.2 Consider the process \\(\\{X(t)\\}\\) from Example 53.5 with autocorrelation function \\[ R_X(\\tau) = 5 e^{-\\tau^2 / 3} + 4. \\] We showed in Example 56.2 that its power spectral density is \\[\\begin{align*} S_X(f) &amp;= 5 \\sqrt{\\frac{\\pi}{3}} e^{-\\pi^2 f^2 / 3} + 4 \\delta(f) \\end{align*}\\] Now, suppose we pass \\(\\{ X(t) \\}\\) through an LTI filter with impulse response \\[ h(t) = 1.8\\text{sinc}(1.2t). \\] Using the table in Appendix D.1, along with the scaling property, we see that the frequency response is \\[ H(f) = 1.8\\frac{1}{1.2} \\text{rect}(\\frac{f}{1.2}) = \\begin{cases} 1.5 &amp; |f| &lt; 0.6 \\\\ 0 &amp; \\text{otherwise} \\end{cases}. \\] The filter \\(h\\) is an ideal lowpass filter because it perfectly passes frequencies below \\(0.6\\) Hz and perfectly rejects frequencies above \\(0.6\\) Hz. It is “ideal” because the impulse response \\(h(t)\\) is not implementable in practice. (The \\(\\text{sinc}\\) function extends infinitely far into the past and into the future.) Now, we have to calculate the squared magnitude of the impulse response for the filter theorem: \\[ |H(f)|^2 = \\begin{cases} 1.5^2 &amp; |f| &lt; 0.6 \\\\ 0 &amp; \\text{otherwise} \\end{cases}. \\] \\(S_X(f)\\) and \\(|H(f)|^2\\) are graphed below. By the Filter Theorem (Theorem 58.1), the PSD of the output is \\[ S_Y(f) = |H(f)|^2 \\cdot S_X(f) = \\begin{cases} 1.5^2 \\cdot 5 \\sqrt{\\frac{\\pi}{3}} e^{-\\pi^2 f^2 / 3} + 1.5^2 \\cdot 4 \\delta(f) &amp; |f| &lt; 0.6 \\\\ 0 &amp; \\text{otherwise} \\end{cases} \\] The formula for \\(S_Y(f)\\) is quite messy; it is easier to understand what is going on by just graphing the function. Frequencies below 0.6 Hz are passed (with a gain of \\(1.5^2 = 2.25\\)), while frequencies above 0.6 Hz are rejected. The Filter Theorem allows us to prove a fact about power spectral densities that we have assumed in many of our calculations. Combined with Theorem 56.1, the next theorem justifies the name “power spectral density” for \\(S_X(f)\\). Theorem 58.2 (Expected Power in a Frequency Band) The integral of the PSD \\(S_X(f)\\) over any frequency band \\(a &lt; |f| &lt; b\\) equals the expected power in that frequency band. Proof. To measure the expected power in a signal \\(\\{ X(t) \\}\\) over the frequency band \\(a &lt; |f| &lt; b\\), we imagine passing \\(\\{ X(t) \\}\\) through the ideal bandpass filter \\[ H(f) = \\begin{cases} 1 &amp; a &lt; |f| &lt; b \\\\ 0 &amp; \\text{otherwise} \\end{cases}. \\] The output signal \\(\\{ Y(t) \\}\\) is then just \\(\\{ X(t) \\}\\) with frequency content outside \\(a &lt; |f| &lt; b\\) removed. Now, to obtain the expected power in \\(\\{ X(t) \\}\\) this frequency band, we can integrate the PSD of \\(\\{ Y(t) \\}\\) over all frequencies (by Theorem 56.1): \\[ \\text{Expected power between $a$ and $b$} = \\int_{-\\infty}^\\infty S_Y(f)\\,df. \\] (This is for a continuous-time process. For a discrete-time process, the limits of the integral would be \\(-0.5\\) to \\(0.5\\).) But by the Filter Theorem (Theorem 58.1), we have \\[ \\int_{-\\infty}^\\infty S_Y(f)\\,df = \\int_{-\\infty}^\\infty |H(f)|^2 S_X(f)\\,df = \\int_{a &lt; |f| &lt; b} S_X(f)\\,df, \\] since \\(|H(f)|^2\\) is 0 outside \\(a &lt; |f| &lt; b\\). This shows that we can obtain the expected power in ${X(t)} over any frequency band by integrating its PSD \\(S_X(f)\\) over the appropriate frequencies. Essential Practice For these questions, you may want to refer to the power spectral densities that you calculated in Lesson 56. Radioactive particles hit a Geiger counter according to a Poisson process at a rate of \\(\\lambda=0.8\\) particles per second. Let \\(\\{ N(t); t \\geq 0 \\}\\) represent this Poisson process. Define the new process \\(\\{ D(t); t \\geq 3 \\}\\) by \\[ D(t) = N(t) - N(t - 3). \\] This process represents the number of particles that hit the Geiger counter in the last 3 seconds. Suppose \\(\\{ D(t) \\}\\) is passed through an LTI filter with impulse response \\[ h(t) = 3\\text{sinc}(2t). \\] What is the power spectral density of the output? What is the expected power in the output? Consider the moving average process \\(\\{ X[n] \\}\\) of Example 48.2, defined by \\[ X[n] = 0.5 Z[n] + 0.5 Z[n-1], \\] where \\(\\{ Z[n] \\}\\) is a sequence of i.i.d. standard normal random variables. In Lesson 57, you expressed \\(\\{ X[n] \\}\\) as white noise passed through an LTI filter and calculated the impulse response of this filter. Use this impulse response and the PSD of white noise to calculate the PSD of this moving average process. Check that your answer agrees with the one you obtained in Lesson 56. Let \\(\\{ X(t) \\}\\) be a continuous-time random process with mean function \\(\\mu_X(t) = -1\\) and autocovariance function \\(C_X(s, t) = 2e^{-|s - t|/3}\\). If \\(\\{X(t)\\}\\) is passed through an LTI filter with impulse response \\[ h(t) = \\begin{cases} 4e^{-2t} &amp; t \\geq 0 \\\\ 0 &amp; \\text{otherwise} \\end{cases}, \\] what is the expected power in the output? "],
["distribution-table.html", "A Distribution Tables A.1 Discrete Distributions A.2 Continuous Distributions", " A Distribution Tables A.1 Discrete Distributions Distribution of \\(X\\) \\(f(x)\\) Support \\(E[X]\\) \\(\\text{Var}[X]\\) Hypergeometric\\((n, N_1, N_0)\\) \\(\\displaystyle \\frac{\\binom{N_1}{x} \\binom{N_0}{n-x}}{\\binom{N}{n}}\\) \\(x=0, 1, \\ldots, n\\) \\(n \\frac{N_1}{N}\\) \\(n \\frac{N_1}{N} \\frac{N_0}{N} \\left(1 - \\frac{n-1}{N-1}\\right)\\) Binomial\\((n, N_1, N_0)\\) \\(\\displaystyle \\frac{\\binom{n}{x} N_1^x N_0^{n-x}}{N^n}\\) \\(x=0, 1, \\ldots, n\\) \\(n \\frac{N_1}{N}\\) \\(n \\frac{N_1}{N} \\frac{N_0}{N}\\) Binomial\\((n, p)\\) \\(\\binom{n}{x} p^x (1-p)^{n-x}\\) \\(x=0, 1, \\ldots, n\\) \\(np\\) \\(np(1-p)\\) Geometric\\((p)\\) \\((1-p)^{x-1} p\\) \\(x=1, 2, \\ldots\\) \\(\\frac{1}{p}\\) \\(\\frac{1-p}{p^2}\\) NegativeBinomial\\((r, p)\\) \\(\\binom{x-1}{r-1} (1-p)^{x-r} p^r\\) \\(x=r, r+1, \\ldots\\) \\(\\frac{r}{p}\\) \\(\\frac{r(1-p)}{p^2}\\) Poisson\\((\\mu)\\) \\(e^{-\\mu} \\frac{\\mu^x}{x!}\\) \\(x=0, 1, 2, \\ldots\\) \\(\\mu\\) \\(\\mu\\) A.2 Continuous Distributions Distribution of \\(X\\) \\(f(x)\\) Support \\(E[X]\\) \\(\\text{Var}[X]\\) Uniform\\((a, b)\\) \\(\\frac{1}{b-a}\\) \\(a &lt; x &lt; b\\) \\(\\frac{a+b}{2}\\) \\(\\frac{(b-a)^2}{12}\\) Exponential\\((\\lambda)\\) \\(\\lambda e^{-\\lambda x}\\) \\(0 &lt; x &lt; \\infty\\) \\(\\frac{1}{\\lambda}\\) \\(\\frac{1}{\\lambda^2}\\) Gamma\\((r, \\lambda)\\) \\(\\frac{\\lambda^r}{(r-1)!}x^{r-1} e^{-\\lambda x}\\) \\(0 &lt; x &lt; \\infty\\) \\(\\frac{r}{\\lambda}\\) \\(\\frac{r}{\\lambda^2}\\) Normal\\((\\mu, \\sigma)\\) \\(\\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}}\\) \\(-\\infty &lt; x &lt; \\infty\\) \\(\\mu\\) \\(\\sigma^2\\) "],
["complex.html", "B Complex Numbers Motivation Theory Essential Practice", " B Complex Numbers Motivation The following videos explain why imaginary numbers are necessary in mathematics. Note that these videos use \\(i\\) to denote the imaginary number \\(\\sqrt{-1}\\), whereas we use \\(j\\) (which is common in electrical engineering, to avoid confusion with current). Theory The following videos explain the core concepts: the complex plane and the geometric interpretations of complex addition and multiplication. Be sure to try the calculations suggested at the end of the previous video before moving on to the next video: \\((4 + 3j) \\cdot j\\) \\((4 + 3j) \\cdot 2j\\) \\((4 + 3j) \\cdot (4 + 3j)\\) \\((2 + j) \\cdot (1 + 2j)\\) Definition B.1 (Magnitude of a Complex Number) The magnitude of a complex number \\(z = a + jb\\) is \\[ |z| \\overset{\\text{def}}{=} \\sqrt{a^2 + b^2}. \\] This follows from the Pythagorean Theorem. Definition B.2 (Complex Conjugate) The complex conjugate of a complex number \\(z = a + jb\\) is \\[ z^* \\overset{\\text{def}}{=} a - jb. \\] To conjugate a complex number, we simply flip the sign in front of any \\(j\\)s in the expression. For example: \\[ \\left(\\frac{1 + 2j}{2 - j} \\right)^* = \\frac{1 - 2j}{2 + j}. \\] Because it is so easy to calculate the complex conjugate, conjugation is often the preferred way to calculate magnitudes. Theorem B.1 (Calculating Magnitude) The squared magnitude of a complex number \\(z\\) is the product of the number and its complex conjugate: \\[ |z|^2 = z z^*. \\] This means that the magnitude of a complex number can be calculated as \\[ |z| = \\sqrt{z z^*}. \\] Proof. If \\(z = a + jb\\), then \\(z^* = a - jb\\), and \\[ z z^* = (a + jb)(a - jb) = a^2 - j^2 b^2 = a^2 + b^2 = |z|^2. \\] For example, the magnitude of the number above is: \\[ \\left|\\frac{1 + 2j}{2 - j} \\right| = \\sqrt{\\frac{1 + 2j}{2 - j} \\cdot \\frac{1 - 2j}{2 + j}} = \\sqrt{\\frac{1 + 4}{4 + 1}} = 1. \\] It would have been much more tedious to calculate this magnitude by finding \\(a\\) and \\(b\\) such that \\(\\frac{1 + 2j}{2 - j} = a + jb\\) and using Definition B.1. Theorem B.2 (Euler’s Identity) Euler’s identity relates the complex exponential \\(e^{j\\theta}\\) to the trigonometric functions: \\[ e^{j\\theta} = \\cos \\theta + j \\sin\\theta \\] Two immediate corollaries of Euler’s identity are: \\[\\begin{align*} \\cos\\theta &amp;= \\frac{e^{j\\theta} + e^{-j\\theta}}{2} \\\\ \\sin\\theta &amp;= \\frac{e^{j\\theta} - e^{-j\\theta}}{2j}. \\end{align*}\\] Essential Practice Express the complex number \\(\\frac{1 - j}{1 + j}\\) in \\(a + jb\\) form, where \\(a\\) and \\(b\\) are real numbers. Calculate \\(e^{j\\pi/4} + e^{-j\\pi/4}\\). Your answer should be a real number. Calculate \\(\\left| \\frac{1 - j}{1 + e^{j\\pi/4}} \\right|\\). "],
["fourier.html", "C Fourier Transforms Continuous-Time Fourier Transforms Discrete-Time Fourier Transforms Essential Practice", " C Fourier Transforms Continuous-Time Fourier Transforms The Fourier transform is an alternative representation of a signal. It describes the frequency content of the signal. It is defined as \\[\\begin{equation} G(f) \\overset{\\text{def}}{=} \\int_{-\\infty}^\\infty g(t)e^{-j2\\pi f t}\\,dt. \\tag{C.1} \\end{equation}\\] Notice that it is a function of frequency \\(f\\), rather than time \\(t\\). Notice also that it is complex-valued, since its definition involves the imaginary number \\(j \\overset{\\text{def}}{=} \\sqrt{-1}\\). The following video explains the visual intuition behind the Fourier transform. Note that this video uses \\(i\\) to denote the imaginary number \\(\\sqrt{-1}\\), whereas we use \\(j\\) (which is common in electrical engineering, to avoid confusion with current). To calculate the Fourier transform of a signal, we will rarely use (C.1). Instead, we will look up the Fourier transform of the signal in a table like Appendix D.1 and use properties of the Fourier transform (as shown in Appendix D.3). Example C.1 Calculate the Fourier transform of \\(g(t) = 80e^{-20t} u(t)\\). Solution. This signal is most similar to \\(e^{-t} u(t)\\) in Appendix D.1, whose Fourier transform is \\(\\frac{1}{1 + j2\\pi f}\\). The only differences are: Our signal has an extra factor of 80 in front. This factor comes along for the ride by linearity of the Fourier transform. Our signal is time-scaled by a factor of 20, so we have to apply the scaling property. Since we multiplied by 20 in the time domain, we have to divide by 20 in the frequency domain, on both the inside and the outside. Putting everything together, we see that the Fourier transform is: \\[ G(f) = 80 \\frac{1}{20} \\frac{1}{1 + j 2\\pi \\frac{f}{20}}. \\] This is a complex-valued function. That is, at each frequency \\(f\\), \\(G(f)\\) is a complex number, with a real and an imaginary component. To make it easier to visualize, we calculate its magnitude using Theorem B.1. \\[\\begin{align*} |G(f)| = \\sqrt{|G(f)|^2} &amp;= \\sqrt{G(f) \\cdot G^*(f)} \\\\ &amp;= \\sqrt{\\frac{4}{1 + j2\\pi \\frac{f}{20}} \\cdot \\frac{4}{1 - j2\\pi \\frac{f}{20}}} \\\\ &amp;= \\sqrt{\\frac{4}{1 + (2\\pi \\frac{f}{20})^2}} \\end{align*}\\] Now, the magnitude of the Fourier transform is a function we can easily visualize. From the graph, we see that the signal has more low-frequency content than high-frequency content. Discrete-Time Fourier Transforms Discrete-time signals are obtained by sampling a continuous-time signal at regular time intervals. The sampling rate \\(f_s\\) (in Hz) specifies the number of samples per second. The signal below is sampled at a rate of \\(f_s = 16\\) Hz. We write \\(x[n] = x(t_n)\\) for the \\(n\\)th time sample, where \\(t_n = \\frac{n}{f_s}\\). It’s possible to choose a sampling rate \\(f_s\\) that is too low. In the graph below, the underlying continuous-time signal (in black) is a sinusoid with a frequency of 14 Hz. However, because the discrete-time signal (in red) was sampled at a rate of 16 Hz, the sinusoid appears to have a frequency of 2 Hz. We say that the higher frequency is aliased by the lower one. At a sampling rate of \\(f_s\\), any frequencies outside the range \\[ (-f_s / 2, f_s / 2) \\] will be aliased by a frequency inside this range. This “maximum frequency” of \\(f_s / 2\\) is known as the Nyquist limit. Therefore, the Fourier transform of a discrete-time signal is effectively only defined for frequencies from \\(-f_s/2\\) to \\(f_s/2\\). Contrast this with the Fourier transform of a continuous-time signal, which is defined on all frequencies from \\(-\\infty\\) to \\(\\infty\\). Aliasing is not just a theoretical problem. For example, if helicopter blades are spinning too fast for the frame rate of a video, then they can look like they are not spinning at all! When calculating the Fourier transform of a discrete-time signal, we typically work with normalized frequencies. That is, the frequencies are in units of “cycles per sample” instead of “cycles per second”. (Another way to think about this is that we assume all discrete-time signals are sampled at 1 Hz.) As a result, the Nyquist limit is \\(1/2\\), so the Discrete-Time Fourier Transform is defined only for \\(|f| &lt; 0.5\\). \\[\\begin{align} G(f) &amp;\\overset{\\text{def}}{=} \\sum_{n=-\\infty}^\\infty g[n] e^{-j2\\pi f t}\\,dt &amp; -0.5 &lt; f &lt; 0.5 \\tag{C.2} \\end{align}\\] To calculate the Fourier transform of a signal, we will rarely use (C.2). Instead, we will look up the Fourier transform of the signal in a table like Appendix D.2 and use properties of the Fourier transform (as shown in Appendix D.3). Essential Practice Calculate the Fourier transform \\(G(f)\\) of the continuous-time signal \\[ g(t) = \\begin{cases} 1/3 &amp; 0 &lt; t &lt; 3 \\\\ 0 &amp; \\text{otherwise} \\end{cases}. \\] Graph its magnitude \\(|G(f)|\\) as a function of frequency. Calculate the Fourier transform \\(G(f)\\) of the discrete-time signal \\[ g[n] = \\delta[n] + 0.4 \\delta[n-1] + 0.4 \\delta[n+1]. \\] Graph \\(G(f)\\). (The Fourier transform should be a real-valued function, so you do not need to take its magnitude.) Which of the following terms fill in the blank? The Fourier transform \\(G(f)\\) of a real-valued time signal \\(g(t)\\) is necessarily …. real-valued: \\(G(f) \\in \\mathbb{R}\\) positive-valued: \\(G(f) &gt; 0\\) symmetric: \\(G(-f) = G(f)\\) conjugate symmetric: \\(G(-f) = G^*(f)\\) (Hint: Write out \\(G(f)\\) and \\(G(-f)\\) according to the definition (C.1), and use Euler’s identity (Theorem B.2). Simplify as much as possible, using the facts that \\(\\cos(-\\theta) = \\cos(\\theta)\\) and \\(\\sin(-\\theta) = -\\sin(\\theta)\\).) Which of the following terms fill in the blank? The Fourier transform \\(G(f)\\) of a real-valued and symmetric time signal \\(g(t)\\) is necessarily …. real-valued: \\(G(f) \\in \\mathbb{R}\\) positive-valued: \\(G(f) &gt; 0\\) symmetric: \\(G(-f) = G(f)\\) conjugate symmetric: \\(G(-f) = G^*(f)\\) "],
["fourier-table.html", "D Fourier Tables D.1 Continuous-Time Fourier Transforms D.2 Discrete-Time Fourier Transforms D.3 Fourier Properties", " D Fourier Tables D.1 Continuous-Time Fourier Transforms \\[ G(f) = \\int_{-\\infty}^\\infty g(t) e^{-j2\\pi f t}\\,dt,\\ \\ -\\infty &lt; f &lt; \\infty \\] Time-Domain \\(g(t)\\) Frequency-Domain \\(G(f) = \\mathscr{F}[g(t)]\\) \\(1\\) \\(\\delta(f)\\) \\(u(t) \\overset{\\text{def}}{=} \\begin{cases} 1 &amp; t \\geq 0 \\\\ 0 &amp; t &lt; 0 \\end{cases}\\) \\(\\displaystyle\\frac{1}{2}\\delta(f) + \\frac{1}{j2\\pi f}\\) \\(\\cos(2\\pi f_0 t)\\) \\(\\frac{1}{2}(\\delta(f - f_0) + \\delta(f + f_0))\\) \\(\\sin(2\\pi f_0 t)\\) \\(\\frac{1}{2j}(\\delta(f - f_0) - \\delta(f + f_0))\\) \\(e^{-t}u(t)\\) \\(\\displaystyle\\frac{1}{1 + j2\\pi f}\\) \\(e^{-|t|}\\) \\(\\displaystyle\\frac{2}{1 + (2\\pi f)^2}\\) \\(e^{-\\pi t^2}\\) \\(e^{-\\pi f^2}\\) \\(\\text{rect}(t) \\overset{\\text{def}}{=} \\begin{cases} 1 &amp; |t| \\leq 0.5 \\\\ 0 &amp; |t| &gt; 0.5 \\end{cases}\\) \\(\\displaystyle\\text{sinc}(f) \\overset{\\text{def}}{=} \\frac{\\sin(\\pi f)}{\\pi f}\\) \\(\\text{tri}(t) \\overset{\\text{def}}{=} \\begin{cases} 1 - |t| &amp; |t| \\leq 1 \\\\ 0 &amp; |t| &gt; 1 \\end{cases}\\) \\(\\text{sinc}^2(f)\\) D.2 Discrete-Time Fourier Transforms Note that \\(f\\) here denotes normalized frequency (cycles/sample). \\[ G(f) = \\sum_{n=-\\infty}^\\infty g[n] e^{-j2\\pi f n},\\ \\ -0.5 &lt; f &lt; 0.5 \\] Time-Domain \\(g[n]\\) Frequency-Domain \\(G(f) = \\mathscr{F}[g[n]]\\) Restrictions \\(1\\) \\(\\delta(f)\\) \\(\\delta[n]\\) \\(1\\) \\(\\cos(2\\pi f_0 n)\\) \\(\\frac{1}{2}(\\delta(f - f_0) + \\delta(f + f_0))\\) \\(-0.5 &lt; f &lt; 0.5\\) \\(\\sin(2\\pi f_0 n)\\) \\(\\frac{1}{2j}(\\delta(f - f_0) - \\delta(f + f_0))\\) \\(-0.5 &lt; f &lt; 0.5\\) \\(\\alpha^{|n|}\\) \\(\\displaystyle\\frac{1 - \\alpha^{2}}{1 + \\alpha^{2} - 2\\alpha \\cos(2\\pi f)}\\) \\(|\\alpha| &lt; 1\\) \\(\\alpha^{n} u[n]\\) \\(\\displaystyle\\frac{1}{1 - \\alpha e^{-j2\\pi f}}\\) \\(|\\alpha| &lt; 1\\) D.3 Fourier Properties Suppose \\(g\\), \\(g_1\\), and \\(g_2\\) are time-domain signals with Fourier transforms \\(G\\), \\(G_1\\), and \\(G_2\\), respectively. Property When It Applies Time-Domain Frequency-Domain Linearity continuous-time, discrete-time \\(a g_1(t) + b g_2(t)\\) \\(\\overset{\\mathscr{F}}{\\longleftrightarrow}\\) \\(a G_1(f) + b G_2(f)\\) Scaling continuous-time only \\(g(at)\\) \\(\\overset{\\mathscr{F}}{\\longleftrightarrow}\\) \\(\\frac{1}{a} G\\left(\\frac{f}{a}\\right)\\) Shifting continuous-time, discrete-time \\(g(t + b)\\) \\(\\overset{\\mathscr{F}}{\\longleftrightarrow}\\) \\(G(f) e^{j2\\pi b f}\\) Convolution continuous-time, discrete-time \\((g_1 * g_2)(t)\\) \\(\\overset{\\mathscr{F}}{\\longleftrightarrow}\\) \\(G_1(f) \\cdot G_2(f)\\) Reversal continuous-time, discrete-time \\(g(-t)\\) \\(\\overset{\\mathscr{F}}{\\longleftrightarrow}\\) \\(G(-f)\\) DC Offset continuous-time, discrete-time \\(\\int_{-\\infty}^\\infty g(t)\\,dt\\) \\(\\overset{\\mathscr{F}}{\\longleftrightarrow}\\) \\(G(0)\\) "]
]
