[
["index.html", "Introduction to Probability Preface", " Introduction to Probability Dennis Sun 2020-07-07 Preface "],
["counting.html", "Lesson 1 Probability and Counting Motivating Example Theory Examples Additional Exercises", " Lesson 1 Probability and Counting Motivating Example In 1620, the Grand Duke of Tuscany asked the astronomer and mathematician Galileo to determine whether the numbers on three fair dice are more likely to add up to 9 or 10. Theory Definition 1.1 (Definition of Probability) If all possible outcomes are equally likely, then the probability of an event \\(A\\) is \\[ P(A) = \\frac{\\text{number of outcomes where $A$ occurs}}{\\text{number of possible outcomes}}. \\] For example, suppose we want to know the probability of getting an even number when we roll a fair die. There are \\(6\\) equally likely possible outcomes, ⚀ ⚁ ⚂ ⚃ ⚄ ⚅, of which 3 are even. Therefore, the probability of rolling an even number is \\[ P(\\text{even number}) = \\frac{\\text{number of outcomes that are even}}{\\text{number of possible outcomes}} = \\frac{3}{6}. \\] Next, suppose we want to know the probability of rolling a 7 when we roll two fair dice. There are 36 equally likely outcomes, ⚀⚀ ⚁⚀ ⚂⚀ ⚃⚀ ⚄⚀ ⚅⚀ ⚀⚁ ⚁⚁ ⚂⚁ ⚃⚁ ⚄⚁ ⚅⚁ ⚀⚂ ⚁⚂ ⚂⚂ ⚃⚂ ⚄⚂ ⚅⚂ ⚀⚃ ⚁⚃ ⚂⚃ ⚃⚃ ⚄⚃ ⚅⚃ ⚀⚄ ⚁⚄ ⚂⚄ ⚃⚄ ⚄⚄ ⚅⚄ ⚀⚅ ⚁⚅ ⚂⚅ ⚃⚅ ⚄⚅ ⚅⚅ of which 6 outcomes add up to 7. (Check this for yourself!) Therefore, the probability of rolling a 7 is \\[ P(\\text{sum is 7}) = \\frac{\\text{number of outcomes where the sum is 7}}{\\text{number of possible outcomes}} = \\frac{6}{36}. \\] Galileo needed to consider the possible outcomes when three dice are rolled. At this point, listing all of the possible outcomes is impractical. We need to find a way to count the number of outcomes without listing all of them. Here is a way to see that there are 36 ways to roll two dice, without listing them out. There are 6 possible outcomes for the first die, and each of these 6 outcomes can be paired with 6 possible outcomes for the second die. Therefore, there must be \\(6 \\cdot 6 = 36\\) ways to roll two dice. The following theorem generalizes this principle. Theorem 1.1 (Multiplication Principle of Counting) If a task can be performed in \\(n_1\\) ways, and for each of these ways, a second task can be performed in \\(n_2\\) ways, then the two tasks can be performed together in a total of \\(n_1 \\cdot n_2\\) ways. Proof. List the outcomes in a table, with \\(n_1\\) columns and \\(n_2\\) rows (like we did above for the possible outcomes of two dice, where \\(n_1 = n_2 = 6\\)). Each column corresponds to one of the \\(n_1\\) possible outcomes of the first task, each row to one of the \\(n_2\\) possible outcomes of the second. There are \\(n_1 \\cdot n_2\\) cells in the table. Using the multiplication principle, we can count the total number of ways of rolling three dice. We already know that there are 36 ways that the first two dice can come out. Each of these 36 ways can be matched with each of the 6 ways that the third dice can come out. Therefore, by Theorem @ref{thm:multiplication-principle}, there are \\[ 36 \\cdot 6 = 216 \\] ways the three dice could come out. Using the multiplication principle, we can calculate the probability that no sixes are rolled among the three dice. In order for there to be no sixes, each of the three dice must have shown one of the other 5 numbers. The number of ways for this to happen is \\[ 5 \\cdot 5 \\cdot 5 = 125, \\] so the probability is \\[ P(\\text{no sixes}) = \\frac{125}{216} \\approx 57.8\\%. \\] Now, Galileo was interested in the event that the numbers add up to 9, which is much trickier to count. We will come back to his question in a future lesson, once we have more counting tools under our belt. Examples In the casino game craps, two dice are rolled by a player, called the “shooter”. The first roll is called the “come-out roll”. The shooter wins on the come-out roll if they roll a 7 or a 11. On the other hand, they lose if the come-out roll is a 2, 3, or 12. Otherwise, the game continues. What is the probability that the shooter wins on the come-out roll? What is the probability that the shooter loses on the come-out roll? What is the probability that the game continues? If you add up the three probabilities you just calculated, what do you get? Why does this make sense? Many examples in this book will be based on a standard deck of 52 playing cards, consisting of 13 cards of each suit. Familiarize yourself with the terminology. Suppose you draw one card from a shuffled deck of cards. What is the probability that the card is a heart? What is the probability that the card is an ace? What is the probability that the card is a face card (also known as a “court card”)? Many examples in this book will be based on the casino game roulette. Familiarize yourself with the roulette wheel. (Click the wheel to spin it.) You win if the ball lands in a pocket that matches your bet. What is the probability that you win if you bet on red? What is the probability that you win if you bet on the number 10? What is the probability that you win if you bet on odd (i.e., that the number is odd)? In standard poker, each player is dealt 5 cards off the top of a (shuffled) deck of cards. The hand is called a “flush” if all 5 cards are the same suit. What is the probability that you get a flush of hearts (i.e., all 5 cards are hearts)? Additional Exercises "],
["factorial.html", "Lesson 2 The Factorial Motivating Example Theory Examples Additional Exercises", " Lesson 2 The Factorial Motivating Example How many ways are there to arrange a deck of 52 cards? Theory We can use the multiplication rule to determine the number of ways to arrange the deck. The first card can be any one of 52 cards. No matter which one it is, the second card can be any one of the remaining 51 cards. So there are \\(52 \\cdot 51\\) ways to choose the first 2 cards. For every one of these \\(52 \\cdot 51\\) ways, there are \\(50\\) remaining cards to choose as the third card, which makes \\(52 \\cdot 51 \\cdot 50\\) ways to choose the first 3 cards. And so on. By the time we get to the last card in the deck, there is only \\(1\\) card left. So there are \\[ 52 \\cdot 51 \\cdot 50 \\cdot \\ldots \\cdot 2 \\cdot 1 \\] ways to arrange the 52 cards in a deck. This is such an important quantity in probability and counting that it has been given a special name. Definition 2.1 (Factorial) The quantity \\(n!\\) (pronounced: “n factorial”) is defined as \\[ n! = n \\cdot (n-1) \\cdot \\ldots \\cdot 1. \\] It represents the number of ways to arrange \\(n\\) objects. So the number of ways to arrange a deck of cards can be expressed as \\(52!\\). Using Wolfram Alpha, we can calculate this to be about \\(8 \\times 10^{67}\\), an astronomical number. In particular, it is greater than: the number of seconds since the universe began. the number of atoms on Earth. So the next time you hold a shuffled deck of cards in your hands, spend a moment appreciating the fact that you are holding an arrangement that has likely never before existed in the history of the universe. Examples Each year, as part of a “Secret Santa” tradition, a group of 4 friends write their names on slips of papers and place the slips into a hat. Each member of the group draws a name at random from the hat and must by a gift for that person. Of course, it is possible that they draw their own name, in which case they buy a gift for themselves. What is the probability that everyone in the group ends up buying a gift for themselves? (Note that the names are not placed back in the hat once they are drawn, so each person receives exactly one gift.) A deck of 52 cards is shuffled thoroughly. What is the probability that the four aces are all next to each other? (Hint: First, count the number of positions that the block of four aces can go, then multiply this by the number of ways of ordering the four aces.) If a five-letter word is formed at random (meaning that all sequences of five letters are equally likely), what is the probability that no letter occurs more than once? The “bootstrap” is a statistical method for generating a new data set that is like an existing one. Suppose we have a data set consisting of \\(6\\) observations: \\(x_1, x_2, x_3, x_4, x_5, x_6\\). To generate a “bootstrap” data set, we sample from the original data set with replacement, meaning that it is possible for each observation to be sampled more than once. Examples of bootstrap data sets include: \\[\\begin{align*} x_4, x_2, x_4, x_3, x_2, x_4 \\\\ x_3, x_1, x_6, x_1, x_1, x_2 \\\\ x_2, x_1, x_4, x_3, x_6, x_5 \\end{align*}\\] Notice that in the last example, each observation appears exactly once. What is the probability that the bootstrap data set contains each observation exactly once? Additional Exercises "],
["box-models.html", "Lesson 3 Box Models and Combinations Motivating Example Theory Examples", " Lesson 3 Box Models and Combinations Motivating Example One of the most coveted hands in poker is a four-of-a-kind, which is when the hand contains all four cards of a particular rank. For example, the hand below is an example of a four-of-a-kind, since it contains all four 7s in the deck. (The last card, called the “kicker”, can be any other card.) In this lesson, we will calculate the probability of a four-of-a-kind in two ways: (1) using methods that we have already learned and (2) using combinations, which is a new method that will be introduced in this lesson. Theory Many counting and probability problems can be reduced to a box model. In a box model, there are \\(N\\) tickets in a box, and we draw \\(n\\) tickets from the box. For example, three rolls of a fair die can be modeled as \\(n=3\\) draws from the box \\[ \\fbox{$\\fbox{1}\\ \\fbox{2}\\ \\fbox{3}\\ \\fbox{4}\\ \\fbox{5}\\ \\fbox{6}$}. \\] In order to accurately model how dice behave (i.e., the outcome of one die roll does not affect the outcome of another), we have to place the ticket back in the box after each draw. In other words, the \\(n=3\\) draws are made with replacement. In other situations, the draws are made without replacement. For example, consider four friends who draw names from a hat to determine whom each person’s Secret Santa is. If we call the four friends “1”, “2”, “3”, and “4” (their actual names are unimportant, as far as probability is concerned), then we can model the Secret Santa game as \\(n=4\\) draws from the box \\[ \\fbox{$\\fbox{1}\\ \\fbox{2}\\ \\fbox{3}\\ \\fbox{4}$}. \\] Since every person has exactly one Secret Santa, the draws must be made without replacement. Once a Secret Santa has been chosen for person 3, we remove \\(\\fbox{3}\\) from the box so that they do not end up with two Secret Santas. Using the multiplication principle (Theorem 1.1), we can count the number of ways to draw \\(n\\) tickets from the box \\[ \\fbox{$\\fbox{1}\\ \\fbox{2}\\ \\ldots\\ \\fbox{\\(N\\)}$}. \\] If drawing with replacement, the number of possible ways is \\[ \\underbrace{N \\cdot N \\cdot N \\cdot \\ldots \\cdot N}_{\\text{$n$ terms}} = N^n, \\] since we have \\(N\\) tickets to choose from on each draw. If drawing without replacement, the number of possible ways is \\[ \\underbrace{N \\cdot (N-1) \\cdot (N-2) \\cdot \\ldots \\cdot (N-n+1)}_{\\text{$n$ terms}} = \\frac{N!}{(N-n)!}, \\] since the number of tickets remaining in the box decreases by 1 on each draw. For example, if we assign a number 1 to 52 to each card in a standard playing deck, then a poker hand can be modeled as \\(n=5\\) draws, without replacement, from the box \\[ \\fbox{$\\fbox{1}\\ \\fbox{2}\\ \\ldots\\ \\fbox{52}$}. \\] The number of possible poker hands is \\[ \\frac{52!}{(52-5)!} = 52 \\cdot 51 \\cdot 50 \\cdot 49 \\cdot 48 = 311,875,200. \\] How many of these possible outcomes result in a four-of-a-kind? Here is the reasoning: Let’s start by assuming that the first four cards in the hand are the four-of-a-kind and the last card is the kicker. The first card can be any one of the 52 cards. Once we have chosen the first card, the rank of the four-of-a-kind is determined. The second card must be one of the 3 remaining cards of the same rank. The third card must be one of the 2 remaining cards of that rank. The fourth card must be the 1 remaining card of that rank. The last card, the kicker, is one of the other 48 cards in the deck. We assumed that the kicker was the last card in the hand. But the kicker could just as well have been the first card in the hand. In fact, the kicker could have been in any one of 5 positions. So we need to multiply everything by 5 in the end. So the probability of a four-of-a-kind is \\[ \\frac{(52 \\cdot 3 \\cdot 2 \\cdot 1 \\cdot 48) \\cdot 5}{52 \\cdot 51 \\cdot 50 \\cdot 49 \\cdot 48} \\approx .00024. \\] This calculation was complicated because we had to consider the different orders in which the cards might be drawn. It is often easier to ignore the order when counting outcomes. That is, we treat \\(\\fbox{1}\\ \\fbox{3}\\ \\fbox{4}\\ \\fbox{5}\\ \\fbox{8}\\) as the same outcome as \\(\\fbox{3}\\ \\fbox{5}\\ \\fbox{4}\\ \\fbox{1}\\ \\fbox{8}\\); we do not double count different reorderings of the same draws. Fortunately, when the draws are made without replacement, the unordered outcomes are also equally likely, so it is equally valid to count unordered outcomes as ordered ones for the purposes of calculating probabilities. If we ignore order when counting, we say that “order doesn’t matter”. Theorem 3.1 (Combinations) The number of ways to draw \\(n\\) tickets from the box \\[ \\fbox{$\\fbox{1}\\ \\fbox{2}\\ \\ldots\\ \\fbox{\\(N\\)}$}, \\] when order doesn’t matter, is symbolized \\(\\binom{N}{n}\\) (pronounced: “\\(N\\) choose \\(n\\)”) and is equal to \\[ \\binom{N}{n} = \\frac{N!}{n! (N-n)!}. \\] Proof. We know that any set of \\(n\\) distinct objects can be reordered in \\(n!\\) ways. So when we count different reorderings of the same set of \\(n\\) tickets, we end up counting each set of distinct tickets \\(n!\\) times. By the multiplication principle (Theorem 1.1): \\[\\begin{align*} \\left(\\text{# ways when order matters}\\right) &amp;= \\left(\\text{# ways when order doesn&#39;t matter}\\right) \\cdot n!. \\end{align*}\\] But we already know the left-hand side of this equation, the number of ways to draw \\(n\\) tickets without replacement when order matters: it is \\(\\frac{N!}{(N-n)!}\\). Solving for the unknown in this equation, we end up with: \\[\\begin{align*} \\binom{N}{n} \\overset{\\text{def}}{=} \\left(\\text{# ways when order doesn&#39;t matter}\\right) &amp;= \\frac{\\left(\\text{# ways when order matters}\\right)}{n!} \\\\ &amp;= \\frac{N!}{n! (N-n)!} \\end{align*}\\] Now, let’s revisit the probability of a four-of-a-kind using combinations. If we ignore the order of the cards in the hand, there are \\[ \\binom{52}{5} = 2,598,960. \\] possible poker hands. (Binomial coefficients can be calculated using Wolfram Alpha.) Notice how much smaller this number is than the 300+ million ordered poker hands. That is because when order matters, each distinct (unordered) poker hand gets counted \\(5! = 120\\) times, once for each possible way of reordering the 5 cards in the hand. How many “unordered” four-of-a-kind hands are there? Here is how to count them: There are 13 ranks (Ace through King). Any one of these ranks could be the rank for the four-of-a-kind. Once we have chosen the rank, that completely determines 4 of the 5 cards in the four-of-a-kind hand. There is only one way to include all 4 cards of a given rank, since we are no longer concerned with the order in which they are drawn or their position in the hand. So all that’s left is to choose the kicker, which can be any one of the remaining 48 cards. So when we ignore order, there are \\[ 13 \\cdot 48 = 624 \\] ways to get a four-of-a-kind. The probability is therefore \\[ \\frac{13 \\times 48}{\\binom{52}{5}} = \\frac{624}{2,598,960} \\approx .00024, \\] which matches the answer from before. Notice how much simpler \\(13 \\cdot 48\\) is, compared with the mental gymnastics needed to account for the order. Examples In Lesson 1, you calculated the probability of a “flush of hearts” in poker by counting the possible hands. There, you took order into account. Repeat the calculation by counting the possible hands where order does not matter. How many different 8-letter “words” can be formed by rearranging the letters in LALALAAA? (Hint: Model this situation using \\(n=3\\) draws from the box \\(\\fbox{\\(\\fbox{1}\\ \\fbox{2}\\ \\ldots\\ \\fbox{8}\\)}\\). The tickets that you draw correspond to the positions of the three Ls. So, for example, drawing \\(\\fbox{3}, \\fbox{1}, \\fbox{5}\\) corresponds to the word LALALAAA. You still need to figure out whether the draws should be made with replacement and whether you should count different orderings of the same 3 tickets.) You toss a coin 60 times. Each toss results in two equally likely outcomes, heads or tails. What is the probability that you get exactly 30 heads in the 60 tosses? (Hint: To count the number of ways of getting exactly 30 heads, you need to count the number of ways of arranging 30 H and 30 Ts. The general strategy from the previous question may be helpful here.) "],
["replacement.html", "Lesson 4 Sampling With Replacement Motivating Example Discussion Examples Bonus Material", " Lesson 4 Sampling With Replacement Motivating Example Recall Galileo’s problem from Lesson 1. He wanted to know whether a sum of 9 or a sum of 10 was more likely when 3 dice are rolled. In fact, Galileo’s peers reasoned that the two events should be equally likely, since there are six ways to get a sum of 9 \\[\\begin{align*} 3 + 3 + 3 &amp; &amp; 2 + 3 + 4 &amp; &amp; 2 + 2 + 5 &amp; &amp; 1 + 4 + 4 &amp; &amp; 1 + 3 + 5 &amp; &amp; 1 + 2 + 6 \\end{align*}\\] and also six ways to get a sum of 10: \\[\\begin{align*} 3 + 3 + 4 &amp; &amp; 2 + 4 + 4 &amp; &amp; 2 + 3 + 5 &amp; &amp; 2 + 2 + 6 &amp; &amp; 1 + 4 + 5 &amp; &amp; 1 + 3 + 6 \\end{align*}\\] But gamblers of the day knew better. From experience, they knew that a sum of 10 was more likely than a sum of 9. But where did Galileo’s peers go wrong in their reasoning? Discussion Recall from Lesson 3 that the three rolls of a die can be modeled as \\(n=3\\) draws with replacement from the box \\[ \\fbox{$\\fbox{1}\\ \\fbox{2}\\ \\fbox{3}\\ \\fbox{4}\\ \\fbox{5}\\ \\fbox{6}$}. \\] Galileo’s peers showed that there are 6 ways to get a sum of 9 if you ignore the order in which the tickets were drawn. (Notice that they included 2 + 3 + 5, but not 3 + 5 + 2 and other orderings of the same three rolls.) They also showed that there are 6 ways to get a sum of 10. Why does this not guarantee the probabilities of the two events are the same? Notice that this case (draws with replacement, order doesn’t matter) is one that we have not studied yet. with replacement without replacement order matters \\(N^n\\) \\(\\frac{N!}{(N-n)!}\\) order doesn’t matter ??? \\(\\binom{N}{n} = \\frac{N!}{n!(N-n)!}\\) To settle the question, let’s go back to counting ordered outcomes. The outcome \\(2 + 3 + 4\\) corresponds to \\(3! = 6\\) outcomes, when you account for the possible orderings: \\(2 + 3 + 4\\) \\(2 + 4 + 3\\) \\(3 + 2 + 4\\) \\(3 + 4 + 2\\) \\(4 + 2 + 3\\) \\(4 + 3 + 2\\) On the other hand, the outcome \\(2 + 2 + 5\\) can only be reordered \\(3\\) different ways: \\(2 + 2 + 5\\) \\(2 + 5 + 2\\) \\(5 + 2 + 2\\) And the outcome \\(3 + 3 + 3\\) only has one possible ordering. In other words, when we draw with replacement, the same ticket can be drawn more than once, and repetitions reduce the number of ways that tickets can be reordered. The problem with simply counting the number of outcomes is that the 6 outcomes \\[\\begin{align*} 3 + 3 + 3 &amp; &amp; 2 + 3 + 4 &amp; &amp; 2 + 2 + 5 &amp; &amp; 1 + 4 + 4 &amp; &amp; 1 + 3 + 5 &amp; &amp; 1 + 2 + 6 \\end{align*}\\] are not all equally likely. \\(2 + 3 + 4\\) is twice as likely as \\(2 + 2 + 5\\) and six times as likely as \\(3 + 3 + 3\\). When draws are made with replacement, only ordered outcomes are equally likely. This was Galileo’s insight. When he took into account the number of possible orderings associated with each unordered outcome: \\[\\begin{array}{rr} \\hline \\text{Unordered Outcome} &amp; \\text{Possible Orderings} \\\\ \\hline 3 + 3 + 3 &amp; \\text{1 way}\\ \\\\ 2 + 3 + 4 &amp; \\text{6 ways} \\\\ 2 + 2 + 5 &amp; \\text{3 ways} \\\\ 1 + 4 + 4 &amp; \\text{3 ways} \\\\ 1 + 3 + 5 &amp; \\text{6 ways} \\\\ 1 + 2 + 6 &amp; + \\text{6 ways} \\\\ \\hline &amp; \\text{25 ways} \\end{array}\\] he found that the probability of a 9 was actually \\[ \\frac{25}{216}. \\] (Remember that there are \\(6^3 = 216\\) equally likely outcomes when order matters.) Repeating the calculation for the probability of a 10, Galileo showed that the two probabilities were indeed different. Examples Here’s a different illustration of the fact that not all unordered outcomes are equally likely when draws are made with replacement. In the Pick 3 Lotto, a winning number is chosen between 000 to 999. Contestants win if the digits in their chosen number matches the winning number, in any order. What is your chance of winning if you bet on 053? What is your chance of winning if you bet on 055? What is your chance of winning if you bet on 555? Complete the solution to Galileo’s problem. What is the probability that the sum is 10 when 3 fair dice are rolled? How does this compare with the probability that the sum is 9? Bonus Material You will rarely need to count the unordered ways that \\(n\\) tickets can be drawn with replacement, since the unordered outcomes are not equally likely. However, in case you are curious how this can be calculated, the following video explains how. This video is completely optional! "],
["double-counting.html", "Lesson 5 Double Counting Motivating Example Theory Examples", " Lesson 5 Double Counting Motivating Example The French nobleman (and avid gambler) Chevalier de Méré knew that betting on at least one six (⚅) in 4 rolls of a die was a favorable bet for him. Once other gamblers caught on, he devised a new bet: at least one double-six (⚅⚅) in 24 rolls of two dice. Although he did not know how to calculate the probabilities, he reasoned that the two bets should be equivalent, since double-sixes are \\(1/6\\) as likely as a single six, but there are \\(6\\) times as many rolls to compensate Are the two bets equivalent? Theory Here is a common (but wrong) way of calculating the probability of getting at least one six in 4 rolls of a die. \\[\\begin{align*} P(\\text{at least one ⚅}) &amp;= P(\\text{⚅ on 1st roll, or ⚅ on 2nd roll, or ⚅ on 3rd roll or ⚅ on 4th roll}) \\\\ &amp;= P(\\text{⚅ on 1st roll}) + P(\\text{⚅ on 2nd roll}) + P(\\text{⚅ on 3nd roll}) + P(\\text{⚅ on 4th roll}) \\\\ &amp;= \\frac{1}{6} + \\frac{1}{6} + \\frac{1}{6} + \\frac{1}{6} \\\\ &amp;= \\frac{4}{6} ? \\end{align*}\\] What’s wrong with the above reasoning? The problem is that \\[ P(A \\text{ or } B) \\neq P(A) + P(B) \\] in general. The reason is that \\(P(A) + P(B)\\) double counts outcomes where \\(A\\) and \\(B\\) both happen. For example, suppose \\(A\\) is “⚅ on 1st roll” and \\(B\\) is “⚅ on 2nd roll”. Then, it is not hard to see that the event \\(A \\text{ or } B\\) happens on 11 out of 36 outcomes, so \\[ P(A \\text{ or } B) = \\frac{11}{36} \\neq \\frac{12}{36} = \\frac{1}{6} + \\frac{1}{6} = P(A) + P(B). \\] \\(P(A) + P(B)\\) double counts the outcome where both rolls were ⚅s. Figure 5.1: Double Counting Dice Rolls One way to avoid double counting is to subtract the cases that are double counted. Theorem 5.1 (Inclusion-Exclusion Principle) \\[ P(A \\text{ or } B) = P(A) + P(B) - P(A \\text{ and } B) \\] Figure 5.2: Intuition for the Inclusion-Exclusion Principle So, for example: \\[\\begin{align*} P(\\text{at least one ⚅ in 2 rolls}) &amp;= P(\\text{⚅ on 1st roll}) + P(\\text{⚅ on 2nd roll}) - P(\\text{⚅ on both rolls}) \\\\ &amp;= \\frac{1}{6} + \\frac{1}{6} - \\frac{1}{36} \\\\ &amp;= \\frac{11}{36} \\end{align*}\\] However, this approach does not scale well to calculating the probability of at least one ⚅ in 4 rolls. In many situations, it is easier to calculate the probability that an event does not happen, also known as the complement of the event. Because the total probability has to be 1, the two probabilities are related by the following formula. Theorem 5.2 (Complement Rule) \\[ P(\\text{not } A) = 1 - P(A). \\] Let’s apply the Complement Rule to the Chevalier de Méré’s problem. To calculate the probability of getting at least one ⚅ in 4 rolls, we can calculate the probability of the complement. If we did not get at least one ⚅, that must mean that we got no ⚅s. This means that every roll was one of the other 5 outcomes. This probability is much easier to calculate using the counting tricks we have learned. \\[\\begin{align*} P(\\text{at least one ⚅}) &amp;= 1 - P(\\text{no ⚅s}) \\\\ &amp;= 1 - \\frac{5^4}{6^4} \\\\ &amp;\\approx 0.5177. \\end{align*}\\] Examples In poker, a “two pair” hand has 2 cards of one rank, 2 cards of another rank, and 1 card of a third rank. For example, the hand 2, 2, Q, Q, J is a “two pair”. Your friend calculates the probability of “two pair” as follows: There are \\(\\binom{52}{5}\\) equally likely hands (where order does not matter). We count the number of ways to choose the first pair. There are \\(13\\) choices for the rank and \\(\\binom{4}{2}\\) choices for the two cards within the rank, so there are \\(13 \\times \\binom{4}{2}\\) ways. Next, we count the ways to choose the second pair. Since one rank has already been chosen, there are \\(12 \\times \\binom{4}{2}\\) ways to do this. Finally, we choose the remaining card. There are \\(11 \\times \\binom{4}{1} = 44\\) ways to do this. Your friend calculates the probability as \\[ \\frac{13 \\times \\binom{4}{2} \\times 12 \\times \\binom{4}{2} \\times 44}{\\binom{52}{5}} \\approx .095, \\] but then finds online that the actual probability of “two pair” is only \\(.0475\\). This number is exactly half the probability that your friend got, so he suspects that he double-counted. But where? Complete the calculation for the Chevalier de Méré. Calculate the probability of getting at least one ⚅⚅ in 24 rolls of two dice. "],
["conditional.html", "Lesson 6 Conditional Probability Motivating Example Theory Examples Additional Exercises", " Lesson 6 Conditional Probability Motivating Example You know that your coworker has two children. Absent any other information, the probability that both are boys is \\(P(\\text{both boys}) = \\frac{1}{4}\\). One day, she mentions to you, “I need to stop by St. Joseph’s after work for a PTA meeting.” St. Joseph’s is a local all-boys school. So now you know that at least one of her children is a boy. What is the probability now that both her children are boys? Most people assume that the answer is \\(\\frac{1}{2}\\), since the other child is equally likely to be a boy or a girl, and the gender of one child does not affect the gender of another. The actual answer may surprise you…. Theory To quantify how probabilities change in light of new information, we calculate the conditional probability. \\[ P(\\text{both boys}\\ |\\ \\text{at least one boy}) \\] The \\(|\\) symbol is read “given” and the event after the \\(|\\) symbol represents information that we know. In general, to calculate a conditional probability, we use the following formula. Definition 6.1 (Conditional Probability) \\[ P(B | A) = \\frac{P(A \\textbf{ and } B)}{P(A)}. \\] The probability \\(P(A \\textbf{ and } B)\\) is called the joint probability of the two events \\(A\\) and \\(B\\). So the conditional probability above is \\[\\begin{align*} P(\\text{both boys}\\ |\\ \\text{at least one boy}) &amp;= \\frac{P(\\text{both boys} \\textbf{ and } \\text{at least one boy})}{P(\\text{at least one boy})} \\\\ &amp;= \\frac{P(\\text{both boys})}{P(\\text{at least one boy})} \\\\ &amp;= \\frac{1/4}{3/4} \\\\ &amp;= \\frac{1}{3}. \\end{align*}\\] In the above example, the joint probability \\(P(\\text{both boys} \\textbf{ and } \\text{at least one boy})\\) is easy to calculate because the two events are redundant. If we know that both are boys, then we automatically know that at least one is a boy. The information that at least one of her children attends St. Joseph’s (and, thus, is a boy) increases the probability that she has two boys from \\(1/4\\) to \\(1/3\\). If this result was counterintuitive to you, the video below gives some intuition. We can rearrange the conditional probability formula to get a formula that is useful for calculating the joint probability when the conditional probability is known. Theorem 6.1 (Multiplication Rule) \\[ P(A \\textbf{ and } B) = P(A) \\cdot P(B | A). \\] Example 6.1 Two cards are dealt off the top of a shuffled deck of cards. What is the probability that both are queens? Solution. In this case, we want to calculate the joint probability \\[ P(\\text{1st card is Q} \\textbf{ and } \\text{2nd card is Q}), \\] and the conditional probability \\[ P(\\text{2nd card is Q} | \\text{1st card is Q}) \\] is simple. If it is known that the 1st card was a queen, then there are only 51 cards remaining in the deck, of which 3 are queens, so \\[ P(\\text{2nd card is Q} | \\text{1st card is Q}) = \\frac{3}{51}. \\] By the Multiplication Rule (6.1), \\[\\begin{align*} P(\\text{1st card is Q} \\textbf{ and } \\text{2nd card is Q}) &amp;= P(\\text{1st card is Q}) \\cdot P(\\text{2nd card is Q} | \\text{1st card is Q}) \\\\ &amp;= \\frac{4}{52} \\cdot \\frac{3}{51} \\end{align*}\\] Let’s compare this with a solution based on counting the outcomes directly. There are \\(52 \\cdot 51\\) equally likely (ordered) outcomes, of which \\(4 \\cdot 3\\) are both queens. Therefore, the probability is \\[ P(\\text{1st card is queen} \\textbf{ and } \\text{2nd card is queen}) = \\frac{4 \\cdot 3}{52 \\cdot 51}. \\] We get the same answer; the only thing that changes is the order of operations: In counting, we first multiply to get the number of outcomes, then divide to get probabilities. In the multiplication rule, we first divide to get probabilities, then multiply the probabilities. Examples You and your friend Amy are each dealt two cards: hers face up and yours face down. In which of the following scenarios are you more likely to have a pair: when she has a pair of queens when she has a queen and a 5? Dr. No has captured James Bond and forces him to play a game of Russian roulette. (Note: Russian roulette is very different from the casino game roulette!) Dr. No shows him an revolver with 6 chambers, all initially empty. He places 2 bullets into adjacent chambers. He makes Bond spin the cylinder, place the muzzle against his head, and pull the trigger. He survives! Luckily for Bond, the cylinder stopped on one of the empty chambers. Now Dr. No gives Bond two options: he can re-spin the cylinder before firing again or he can fire with the gun in its current state. (Keep in mind that the cylinder rotates to the next chamber each time the gun is fired.) What option should Bond choose to maximize his chance of surviving? Clearly write out the conditional probability of interest using \\(P(B|A)\\) notation. Find the probability. (Hint: You should not need to do any calculations. You should be able to find the probability just by thinking carefully about the information you have. Make sure you explain your reasoning carefully.) Additional Exercises "],
["independence.html", "Lesson 7 Independence Motivating Example Theory Examples Additional Exercises", " Lesson 7 Independence Motivating Example Many gamblers believe that after a string of losses, they are “due” for a win. Consider a gambler who repeatedly bets on reds in roulette, an event with probability \\(18 / 38 \\approx 0.474\\). The ball has not landed in a red pocket on any of the last 4 spins of the wheel. Does this make it more likely that he will win on the next spin? This is really a conditional probability question in disguise. We want to know the probability that the ball will land in a red pocket on the 5th spin, given that it did not land in a red pocket on any of the first 4 spins: \\[ P(\\text{red on 5th spin}\\ |\\ \\text{not red on first 4 spins}). \\] Theory To verify that the two probabilities are exactly the same, we do the calculation: \\[\\begin{align*} P(\\text{red on 5th spin}\\ |\\ \\text{not red on first 4 spins}) &amp;= \\frac{P(\\text{not red on first 4 spins} \\textbf{ and } \\text{red on 5th spin}) }{P(\\text{not red on first 4 spins})} \\\\ &amp;= \\frac{ 20^4 \\cdot 18 \\big/ 38^5 }{20^4 \\big/ 38^4} \\\\ &amp;= \\frac{18}{38}. \\end{align*}\\] We see that the conditional probability is \\(18 / 38\\), which is the same as the probability that the 5th spin is red if we did not know the outcome of the first 4 spins. In mathematical notation, \\[\\begin{align*} P(\\text{red on 5th spin}\\ |\\ \\text{not red on first 4 spins}) &amp;= P(\\text{red on 5th spin}) \\end{align*}\\] When conditioning on one event (e.g., “not red on first 4 spins”) does not change the probability of another event (e.g., “red on 5th spin”), we say that the two events are independent. In this case, whether the gambler wins on the 5th spin is independent of the fact that he has lost each of the last 4 spins. The folk belief that one is “due” for a win after a series of losses is plain wrong and is known as the gambler’s fallacy. Definition 7.1 (Independence) Two events \\(A\\) and \\(B\\) are said to be independent if the \\[\\begin{equation} P(B | A) = P(B). \\tag{7.1} \\end{equation}\\] The next result follows by applying the Multiplication Rule (6.1) to the definition of independence. Theorem 7.1 Two events \\(A\\) and \\(B\\) are independent if and only if their probabilities multiply: \\[\\begin{equation} P(A \\textbf{ and } B) = P(A) P(B). \\tag{7.2} \\end{equation}\\] Proof. First, we assume (7.1) and show that (7.2) holds: \\[\\begin{align*} P(A \\textbf{ and } B) &amp;= P(A) P(B | A) &amp; \\text{by the Multiplication Rule} \\\\ &amp;= P(A) P(B) &amp; \\text{by assumption}. \\end{align*}\\] Conversely, we assume (7.2) and show that (7.1) holds: \\[\\begin{align*} P(B | A) &amp;= \\frac{P(A \\textbf{ and } B)}{P(A)} &amp; \\text{by the definition of conditional probability} \\\\ &amp;= \\frac{P(A) P(B)}{P(A)} &amp; \\text{by assumption} \\\\ &amp;= P(B). \\end{align*}\\] Here is an example that combines several concepts from the past few lessons. Example 7.1 You and a fellow castaway are stranded on a desert island, playing dice for the last banana. Two dice will be rolled. If the biggest number is 1, 2, 3, or 4, then Player 1 wins. If the biggest number is 5 or 6, then Player 2 wins. Would you rather be Player 1 or Player 2? Solution. Player 2 has a \\(20/36 = 0.5556\\) chance of winning. Here’s why: \\[\\begin{align*} P(\\text{biggest number is 5, 6}) &amp;= 1 - P(\\text{biggest number is 1, 2, 3, 4}) \\\\ &amp;= 1 - P(\\text{1st die is 1, 2, 3, 4} \\textbf{ and } \\text{2nd die is 1, 2, 3, 4}) \\\\ &amp;= 1 - \\frac{4}{6} \\cdot \\frac{4}{6}\\ \\ \\text{(by independence)} \\\\ &amp;= 1 - \\frac{16}{36} \\\\ &amp;= \\frac{20}{36} \\end{align*}\\] Examples One card is dealt off the top of a well-shuffled deck of cards. Is the event that the card is a heart independent of the event that the card is an ace? Two cards are dealt off the top of a well-shuffled deck of cards. Is the event that the first card is a heart independent of the event that the second card is a heart? In the dice game Yahtzee, five dice are rolled. The outcomes of the five dice are independent. What is the probability of rolling a “Yahtzee” (i.e., when all five dice show the same number)? Additional Exercises "],
["ltp.html", "Lesson 8 Law of Total Probability Motivating Example Theory Examples", " Lesson 8 Law of Total Probability Motivating Example You watch a magician place 4 ordinary quarters and 1 double-headed quarter into a box. If you select a coin from the box at random and toss it, what is the probability that it lands heads? Theory In some situations, calculating the probability of an event is easy, once you condition on the right information. For example, in the example above, if we knew that the coin we chose was ordinary, then: \\[ P(\\text{heads} | \\text{ordinary}) = \\frac{1}{2}. \\] On the other hand, if the coin we chose was double-headed, then \\[ P(\\text{heads} | \\text{double-headed}) = 1. \\] How do we combine these conditional probabilities to come up with \\(P(\\text{heads})\\), the overall probability that the coin lands heads? Theorem 8.1 (Law of Total Probability) Let \\(A_1, ..., A_n\\) be a partition of the possible outcomes. Then: \\[ P(B) = \\sum_{i=1}^n P(A_i) P(B | A_i). \\] A partition is a collection of non-overlapping events that cover all the possible outcomes. For example, in the example above, \\(A_1 = \\{ \\text{ordinary}\\}\\) and \\(A_2 = \\{ \\text{double-headed} \\}\\) is a partition, since the coin that we selected has to be one of the two and cannot be both. Applying the Law of Total Probability to this problem, we have \\[\\begin{align*} P(\\text{heads}) &amp;= P(\\text{ordinary}) P(\\text{heads} | \\text{ordinary}) + P(\\text{double-headed}) P(\\text{heads} | \\text{double-headed}) \\\\ &amp;= 0.8 \\cdot \\frac{1}{2} + 0.2 \\cdot 1 \\\\ &amp;= 0.6 \\end{align*}\\] So the overall probability \\(P(B)\\) is just a weighted average of the conditional probabilities \\(P(B | A_i)\\), where the “weights” are \\(P(A_i)\\). (Note that these “weights” have to add up to 1, since \\(A_1, ..., A_n\\) are a partition of all the possible outcomes, whose total probability is \\(1.0\\).) This means that the overall probability \\(P(B)\\) will always lie somewhere between the conditional probabilities \\(P(B | A_i)\\), with more weight given to the more probable scenarios. For example, we could have predicted that \\(P(\\text{heads})\\) would lie somewhere between \\(\\frac{1}{2}\\) and \\(1\\); the fact that it is much closer to the former is because choosing the ordinary coin was more probable. Examples Here are some things we already know about a deck of cards: The top card in a shuffled deck of cards has a \\(13/52\\) chance of being a diamond. If the top card is a diamond, then the second card has a \\(12/51\\) chance of being a diamond. If the top card is not a diamond, then the second card has a \\(13/51\\) chance of being a diamond. Now, suppose we “burn” (i.e., discard) the top card without looking at it. What is the probability that the second card is a diamond? Use the Law of Total Probability, conditioning on the top card. Does burning cards affect probabilities? Anny is a fan of chess competitor Hikaru Nakamura, and tomorrow is the World Chess Championship. She is superstitious and believes that the weather influences how he will perform. Hikaru has a 60% chance of winning if it rains, a 25% chance if it is cloudy, and a 10% chance if it is sunny. Anny checks the weather the night before, and the forecast says that the chance of rain tomorrow is 40%; otherwise, it is equally likely to be cloudy as sunny. What is the probability that Hikaru wins the World Chess Championship? "],
["bayes.html", "Lesson 9 Bayes’ Theorem 9.1 Motivating Example 9.2 Theory 9.3 Examples", " Lesson 9 Bayes’ Theorem 9.1 Motivating Example The ELISA test is used to screen blood for HIV. When the blood contains HIV, it gives a positive result 98% of the time. When the blood does not contain HIV, it gives a negative result 94% of the time. The prevalence of HIV is about 1% in the adult male population. A patient has just tested positive and wants to know the probability that he has HIV. What would you tell him? The solution to this problem involves an important theorem in probability and statistics called Bayes’ Theorem. This video covers some of the intuition and the history behind Bayes’ Theorem. Don’t worry about the details for now. This video is meant to be more inspiring than informative. 9.2 Theory The conditional probabilities \\(P(A | B)\\) and \\(P(B | A)\\) are not the same. For example, let \\(A\\) be “currently a Cal Poly student” and \\(B\\) be “went to high school in California”. \\(P(B | A)\\) is very high, about \\(0.85\\), since most Cal Poly students are in-state. \\(P(A | B)\\) is very low, as only a very small fraction of people who went to high school in CA are currently in college, much less at Cal Poly. Bayes’ Theorem is a way to convert probabilities of the form \\(P(B | A)\\) into probabilities of the form \\(P(A | B)\\). This switcheroo is surprisingly common in probability and statistics. For example, Doctors know the probability that a patient tests positive (\\(B\\)) given that they have the disease (\\(A\\)), but a patient is more interested in the probability that he has the disease (\\(A\\)) given that he tested positive (\\(B\\)). E-mail providers can collect data on the probability that an e-mail contains a certain word (\\(B\\)) given that it is spam (\\(A\\)), but a spam filter needs the probability that the e-mail is spam (\\(A\\)) given that it contains the word (\\(B\\)). Don’t be deceived by its simplicity; Bayes’ Theorem is one of the most important and powerful results in all of probability and statistics. Theorem 9.1 (Bayes’ Theorem) \\[ P(A | B) = \\frac{P(A) P(B | A)}{P(B)}. \\] Proof. By the definition of conditional probability (6.1) and the multiplication rule (6.1): \\[\\begin{equation} P(A | B) = \\frac{P(A \\textbf{ and } B)}{P(B)} = \\frac{P(A) P(B | A)}{P(B)}. \\end{equation}\\] The next video provides intuition about this proof, connecting it with concepts from the past few lessons, including conditional probability and independence. To solve most problems, you will need to combine Bayes’ Theorem with the Law of Total Probability (8.1). The solution to the HIV testing example from above demonstrates some of the common tricks. Solution. Let’s represent HIV positive by \\(H\\) and a positive ELISA test by \\(T\\). The problem statement tells us that \\[\\begin{align*} P(H) &amp;= 0.01 &amp; P(T | H) &amp;= 0.98 &amp; P(\\textbf{not } T | \\textbf{not } H) &amp;= 0.94. \\end{align*}\\] By the Complement Rule, we can infer that \\[\\begin{align*} P(\\textbf{not } H) &amp;= 0.99 &amp; P(\\textbf{not } T | H) &amp;= 0.02 &amp; P(T | \\textbf{not } H) &amp;= 0.06. \\end{align*}\\] Since we already have \\(P(T | H)\\) and we want to know \\(P(H | T)\\), this is a job for Bayes’ Rule: \\[ P(H | T) = \\frac{P(H) P(T | H)}{P(T)} = \\frac{0.01 \\cdot 0.98}{P(T)}. \\] Unfortunately, we do not know \\(P(T)\\), the probability of testing positive overall. However, we do know its probability, conditional on HIV status. So we apply the Law of Total Probability, partitioning by HIV status: \\[ P(T) = P(H) P(T | H) + P(\\textbf{not } H) P(T | \\textbf{not } H) = 0.01 \\cdot 0.98 + 0.99 \\cdot 0.06. \\] Finally, we plug this result into Bayes’ Rule: \\[ P(H | T) = \\frac{0.01 \\cdot 0.98}{0.01 \\cdot 0.98 + 0.99 \\cdot 0.06} = .142. \\] So even though the patient tested positive for HIV, he only has a 14.2% chance of actually having HIV! The low probability is surprising at first. But it makes sense if we think about the problem geometrically. The figure below partitions adult males based on their HIV status and test status. The shaded area represents all people who tested positive. The people who actually have HIV make up only a tiny fraction of all the people who tested positive because there are so many more people who do not have the disease, that the false positives overwhelm the true positives. Figure 9.1: Intuition for Bayes’ Rule The next video will give you deep insights about Bayes’ rule. You should be able to follow most of it, but you may want to come back to this video after trying some of the examples below. 9.3 Examples The rare mineral unobtanium is present in only 1% of rocks in a mine. You have an unobtanium detector, which never fails to detect unobtanium when it is present. Otherwise, it is still reliable, returning accurate readings 90% of the time when unobtanium is not present. What is \\(P(\\text{unobtanium detected} | \\text{unobtanium present})\\)? What is \\(P(\\text{unobtanium present} | \\text{unobtanium detected})\\)? (Hint: One of these probabilities can be read off directly from the question prompt. The other needs to be calculated using Bayes’ Rule.) One application where Bayes’ Theorem has been extremely successful is spam filtering. From historical data, 80% of all e-mail is spam, and the phrase “free money” is used in 10% of spam e-mails. That is, \\(P(\\text{&quot;free money&quot;} | \\text{spam}) = 0.1\\). The phrase is also used in 1% of non-spam e-mails. A new e-mail has just arrived which contains the phrase “free money”. Given this information, what is the probability that it is spam, \\(P(\\text{spam} | \\text{&quot;free money&quot;})\\)? A certain disease afflicts 10% of the population. A test for the disease is 90% accurate for patients with the disease and 80% accurate for patients without the disease. Suppose you test positive for the disease. What is the probability that you actually have the disease? "],
["rv.html", "Lesson 10 Random Variables Motivating Example Theory Essential Practice Additional Exercises", " Lesson 10 Random Variables Motivating Example Texas hold ’em is a popular variant of poker. In Texas hold’em, each player starts with 2 cards (called “hole cards”) that are only known to them. In addition, there are 5 cards in the center (called “community cards”) that are shared by all the players. The player that wins is the one with the best five-card poker hand among the 7 cards (i.e., the 2 hole cards unique to them, plus the 5 community cards). Alice and Bob are playing Texas hold’em using a single deck of cards. The 5 community cards have not been revealed yet. Alice is looking at her 2 hole cards, which are Because she already has two diamonds, she wonders how many more diamonds there are in the community cards. If there are 3 or more, then she has a flush. Bob, on the other hand, has the following hole cards Because he has two jacks of different suits, he is less interested in the suit than in the number of jacks among the community cards. If there are 2, then he has a four-of-a-kind. If there are 0, then he just has a lowly pair. Both Alice and Bob are interested in the same random phenomenon: the 5 community cards with their \\(\\binom{48}{5} \\approx 1,712,304\\) possible outcomes. However, their attention is drawn to different quantities: Alice to the number of diamonds Bob to the number of jacks The number of diamonds and the number of jacks are two examples of random variables associated with this phenomenon. A random variable is simply a way of assigning a number to every possible outcome in a probability experiment. As we have seen, depending on the quantity of interest, there may be many random variables associated with the same probability experiment. To appreciate that Alice and Bob are interested in different random variables, suppose the 5 community cards are revealed to be Alice’s random variable (the number of diamonds) is 2, while Bob’s (the number of jacks) is 1. To help them decide how much to bet, Alice and Bob need to know the probabilities, such as the probability that the number of diamonds is at least 3. the probability that the number of jacks equals 2. Theory We describe random variables (such as the number of diamonds or the number of jacks) by the probabilities of their possible values. This is summarized by a function called the probability mass function. Definition 10.1 (Probability Mass Function) The probability mass function (p.m.f.) of a random variable \\(X\\) is a function that specifies the probability of different outcomes: \\[ f(x) = P(X = x). \\] Informally, the information contained in the p.m.f. is called the distribution of the random variable. Example 10.1 (Calculating the P.M.F.) Let’s calculate the p.m.f. of the number of diamonds, \\(X\\), among the community cards. We deal 5 cards from a deck of cards that has had 4 cards removed (because they have already been dealt to Alice and Bob). Furthermore, we know that 2 of these cards were diamonds. So the deck has 48 cards left, of which 11 are diamonds. First, we calculate \\(f(0)\\), the probability that \\(X = 0\\). In order for there to be no diamonds, all 5 cards must be selected from the \\(48 - 11 = 37\\) non-diamonds. So the probabiilty is \\[ f(0) = P(X = 0) = \\frac{\\binom{37}{5}}{\\binom{48}{5}} = .2546. \\] Next, we calculate \\(f(1)\\), the probability that \\(X = 1\\). We can choose any one of the 11 diamonds and pair it with any of the \\(\\binom{37}{4}\\) ways to choose 4 cards from the non-diamonds. \\[ f(1) = P(X = 1) = \\frac{11 \\cdot \\binom{37}{4}}{\\binom{48}{5}} = .4243. \\] Now, we calculate \\(f(2)\\), the probability that \\(X = 2\\). We can match any one of the \\(\\binom{11}{2}\\) ways to choose 2 diamonds with the \\(\\binom{37}{3}\\) ways to choose 3 non-diamonds: \\[ f(2) = P(X = 2) = \\frac{\\binom{11}{2} \\cdot \\binom{37}{3}}{\\binom{48}{5}} = .2496. \\] Continuing in this way, we can calculate \\(f(3)\\), \\(f(4)\\), and \\(f(5)\\). (Try these yourself!) When the random variable only takes on a handful of possible values, we can write out the probabilities in a table. 0 1 2 3 4 5 \\(f(x)\\) .2546 .4243 .2496 .0642 .0071 .0002 For random variables that take on many possible values, it is usually more convenient to specify the p.m.f. as a formula. In this example, the formula below produces the same probabilities as the table above, when you plug in the right value of \\(x\\): \\[\\begin{align*} f(x) &amp;= \\frac{\\binom{11}{x} \\binom{37}{5-x}}{\\binom{48}{5}} &amp; x &amp;= 0, 1, 2, 3, 4, 5. \\end{align*}\\] Try plugging different values of \\(x\\) into this formula and verifying that you get the probabilities in the table above. Example 10.2 (Using the P.M.F.) In order for Alice to have a flush, there must be at least 3 diamonds among the community cards. Let’s see how she can easily calculate this probability, once she has the p.m.f. \\(f(x)\\). In terms of the random variable \\(X\\), the probability that there are at least 3 diamonds is \\(P(X \\geq 3)\\), which is \\[\\begin{align*} P(X \\geq 3) &amp;= f(3) + f(4) + f(5) \\\\ &amp;= .0642 + .0071 + .0002 \\\\ &amp;= .0715. \\end{align*}\\] The complement rule (5.2) can sometimes save time. Although it would not helped in this example, we could have also calculated the probability as follows: \\[\\begin{align*} P(X \\geq 3) &amp;= 1 - P(X &lt; 3) \\\\ &amp;= 1 - (f(0) + f(1) + f(2)) \\\\ &amp;= 1 - (.2546 + .4243 + .2496) \\\\ &amp;= .0715. \\end{align*}\\] Example 10.3 (Graphing the P.M.F.) A graph of the p.m.f. is the best way to understand the distribution of a random variable over its possible values. On the graph below, the \\(x\\)-axis represents the possible values of the random variable. Each impulse represents the probability of a possible value. From the graph, it is immediately clear that 1 diamond is most probable. Unfortunately for Alice, it does not seem promising that she will get the 3 or more diamonds she needs to secure a flush. Essential Practice Continuing with the example from the lesson, let \\(Y\\) be the number of Jacks in the community cards. Calculate and graph the p.m.f. of \\(Y\\). Two fair, six-sided dice are rolled. Let \\(S\\) be the sum of the two numbers. Calculate and graph the p.m.f. of \\(S\\). Let \\(D\\) be the absolute difference between the two numbers. (That is, \\(D\\) is always a positive number.) Calculate and graph the p.m.f. of \\(D\\). A fair coin is tossed 5 times. Let \\(Z\\) be the number of heads. Calculate and graph the p.m.f. of \\(Z\\). Use the p.m.f. to calculate the probability of getting at least 2 heads. Additional Exercises In college basketball, when a player is fouled while not in the act of shooting and the opposing team is “in the penalty,” the player is awarded a “1 and 1.” In the 1 and 1, the player is awarded one free throw, and if that free throw goes in, the player is awarded a second free throw. Find the p.m.f. of \\(Y\\), the number of points scored in a 1 and 1 given that any free throw goes in with probability \\(0.7\\), independent of any other free throw. "],
["cdf.html", "Lesson 11 Cumulative Distribution Functions Theory Examples", " Lesson 11 Cumulative Distribution Functions Theory The p.m.f. (10.1) is one way to describe a random variable, but it is not the only way. The cumulative distribution function is a different representation that contains the same information as the p.m.f. Definition 11.1 (Cumulative Distribution Function) The cumulative distribution function (c.d.f.) is a function that returns the probability that a random variable is less than or equal to a particular value: \\[ F(x) = P(X \\leq x). \\] It is called “cumulative” because it includes all the probability up to (and including) \\(x\\). Example 11.1 (Calculating the C.D.F.) Let’s calculate the c.d.f. of \\(X\\), the number of diamonds among the community cards, using the p.m.f. that we calculated in Lesson 10. Note that \\(F(x)\\) is the sum of all the probabilities up to \\(x\\). So, for example, \\[\\begin{align*} F(2.8) = P(X \\leq 2.8) &amp;= f(0) + f(1) + f(2) \\\\ &amp;= .2546 + .4243 + .2496 \\\\ &amp;= .9284. \\end{align*}\\] There is no simple formula for \\(F(x)\\). However, we can describe it piecewise. \\[ F(x) = \\begin{cases} 0 &amp; x \\leq 0 \\\\ .2546 &amp; 0 \\leq x &lt; 1 \\\\ .6788 &amp; 1 \\leq x &lt; 2 \\\\ .9284 &amp; 2 \\leq x &lt; 3 \\\\ .9926 &amp; 3 \\leq x &lt; 4 \\\\ .9997 &amp; 4 \\leq x &lt; 5 \\\\ 1.0 &amp; x \\geq 5 \\end{cases}. \\] Note that the c.d.f. of \\(X\\) has the following properties: It is constant between integers. Because it is impossible for the random variable \\(X\\) to assume non-integer values, \\(F(1.2) = P(X \\leq 1.2)\\) and \\(F(1) = P(X \\leq 1)\\) must be the same. The value of \\(F(x)\\) increases from 0 to 1 as \\(x\\) increases. This makes sense because as \\(x\\) increases, we accumulate more and more probability. Example 11.2 (Graphing the C.D.F.) The properties of the c.d.f. become clearer on a graph, like the one below. Because the random variable \\(X\\) cannot take on decimal values, the c.d.f. of \\(X\\) does not change between integers, giving it its step-function appearance. Note that the c.d.f. \\(F(x)\\) can be evaluated at all values \\(x\\), not just at integer values. ``` Example 11.3 (Using the C.D.F.) Some probabilities are easier to calculate using the c.d.f. than using the p.m.f. For example, the probability that Alice gets a flush, \\(P(X \\geq 3)\\), can be calculated by using the complement rule (5.2) and looking up the appropriate probability directly from the c.d.f. \\(F(x)\\). \\[\\begin{align*} P(X \\geq 3) &amp;= 1 - P(X &lt; 3) \\\\ &amp;= 1 - P(X \\leq 2) \\\\ &amp;= 1 - F(2) \\\\ &amp;= 1 - .9284 \\\\ &amp;= .0716 \\end{align*}\\] Remember that the c.d.f. \\(F(x)\\) always includes the probability of \\(x\\). Since \\(P(X &lt; 3)\\) should not include the probability of \\(3\\), we use \\(F(2)\\) instead of \\(F(3)\\). At the beginning of this lesson, we mentioned that the c.d.f. contains the exact same information as the p.m.f., no more and no less. Therefore, it should be possible to recover the p.m.f. from the c.d.f. For example, how would we calculate \\(f(3) = P(X = 3)\\), if we only knew the c.d.f. \\(F(x)\\)? We could subtract \\(P(X \\leq 2)\\) from \\(P(X \\leq 3)\\) to get just the probability that it is equal to 3. \\[\\begin{align*} f(3) = P(X = 3) &amp;= P(X \\leq 3) - P(X \\leq 2) \\\\ &amp;= F(3) - F(2) \\\\ &amp;= .9926 - .9284 \\\\ &amp;= .0642, \\end{align*}\\] which agrees with the p.m.f. from Lesson 10. Examples Continuing with the example from the lesson, let \\(Y\\) be the number of Jacks among the community cards. Calculate and graph the c.d.f. of \\(Y\\). Consider a random variable \\(Z\\) with c.d.f. given by the formula \\[\\begin{align*} F(x) &amp;= \\begin{cases} 1 - 3^{-\\lfloor x \\rfloor} &amp; x \\geq 0 \\\\ 0 &amp; \\text{otherwise} \\end{cases}. \\end{align*}\\] (Note that \\(\\lfloor x \\rfloor\\) denotes the floor operator, which rounds \\(x\\) down to the nearest integer. So \\(\\lfloor 3.9 \\rfloor = 3\\) and \\(\\lfloor 7.1 \\rfloor = 7\\).) Graph the c.d.f. \\(F(x)\\). Then, use it to calculate: \\(P(Z &gt; 3)\\) \\(P(Z = 2)\\) "],
["hypergeometric.html", "Lesson 12 Hypergeometric Distribution Motivating Example Theory Essential Practice Additional Exercises", " Lesson 12 Hypergeometric Distribution Motivating Example We revisit the Texas Hold’em example from Lesson 10, when we first learned about random variables. In that example, Alice was dealt and she wanted to know the distribution of the number of diamonds among the community cards. If this random variable is at least 3, then she has a flush. In Lesson 10, we derived the p.m.f. of the number of diamonds from scratch. In this lesson, we will derive the p.m.f. by matching this random variable to a template. Theory In probability, some distributions are so common that they have been given names. The first named distribution that we will learn is the hypergeometric distribution. Theorem 12.1 (Hypergeometric Distribution) If a random variable can be described as the number of \\(\\fbox{1}\\)s in \\(n\\) random draws, without replacement, from the box \\[ \\overbrace{\\underbrace{\\fbox{0}\\ \\ldots \\fbox{0}}_{N_0}\\ \\underbrace{\\fbox{1}\\ \\ldots \\fbox{1}}_{N_1}}^N, \\] then its p.m.f. is given by \\[\\begin{equation} f(x) = \\dfrac{\\binom{N_1}{x}\\binom{N_0}{n-x}}{\\binom{N}{n}}, x=0, ..., n, \\tag{12.1} \\end{equation}\\] where \\(N = N_1 + N_0\\) is the number of tickets in the box. We say that the random variable has a \\(\\text{Hypergeometric}(n, N_1, N_0)\\) distribution, and \\(n\\), \\(N_1\\), \\(N_0\\) are called parameters of the distribution. We will derive the formula (12.1) later in this lesson. First, let’s see how this result allows us to avoid most calculations. Example 12.1 (The Number of Diamonds) In Alice’s case, the community cards are \\(5\\) cards taken at random, without replacement, from a deck of \\(48\\) cards. So we can represent it by a box model with \\(N=48\\) tickets, with \\[\\begin{align*} \\text{$N_1=11$ tickets labeled } \\fbox{1} &amp;\\text{ representing the diamond cards} \\\\ \\text{$N_0=37$ tickets labeled } \\fbox{0} &amp;\\text{ representing the non-diamond cards}. \\end{align*}\\] Now, if we draw \\(n=5\\) times from this box without replacement, then the number of \\(\\fbox{1}\\)s we get corresponds to the number of diamonds. Therefore, by Theorem 12.1, we know that the number of diamonds follows a \\(\\text{Hypergeometric}(n=5, N_1=11, N_0=37)\\) distribution. We can now write down the p.m.f. by plugging the values of the parameters \\(n\\), \\(N_1\\), \\(N_0\\) into (12.1): \\[ f(x) = \\frac{\\binom{11}{x} \\binom{37}{5-x}}{\\binom{48}{5}}, x=0, 1, \\ldots, 5. \\] Now that we have a formula for the p.m.f., we can calculate probabilities by plugging numbers into it. So, for example, the probability that Alice gets a flush is: \\[\\begin{align*} P(X \\geq 3) &amp;= f(3) + f(4) + f(5) \\\\ &amp;= \\frac{\\binom{11}{3} \\binom{37}{5-3}}{\\binom{48}{5}} + \\frac{\\binom{11}{4} \\binom{37}{5-4}}{\\binom{48}{5}} + \\frac{\\binom{11}{5} \\binom{37}{5-5}}{\\binom{48}{5}} \\\\ &amp;\\approx .0715. \\end{align*}\\] Now, let’s derive the p.m.f. of the hypergeometric distribution. Understanding this derivation will help you remember the formula! Proof (Theorem 12.1). If we number each ticket \\(1, 2, \\ldots, N\\), then there are \\(\\binom{N}{n}\\) equally likely unordered outcomes. Note that in this way of counting, the \\(\\fbox{1}\\)s in the box are distinct. So drawing the first \\(\\fbox{1}\\) in the box is not the same as drawing the second \\(\\fbox{1}\\) in the box. How many of the possible outcomes have exactly \\(x\\) \\(\\fbox{1}\\)s? There are \\(\\binom{N_1}{x}\\) unordered ways to choose \\(x\\) \\(\\fbox{1}\\)s from the \\(N_1\\) \\(\\fbox{1}\\)s. There are \\(\\binom{N_0}{n-x}\\) unordered ways to choose the remaining \\(n-x\\) \\(\\fbox{0}\\)s. Since any one of the \\(\\binom{N_1}{x}\\) ways of choosing the \\(\\fbox{1}\\)s can be paired with any one of the \\(\\binom{N_0}{n-x}\\) ways of choosing the \\(\\fbox{0}\\)s, the total number of ways to choose \\(n\\) tickets, resulting in \\(x\\) \\(\\fbox{1}\\)s and \\(n-x\\) \\(\\fbox{0}\\)s, is \\[ \\binom{N_1}{x} \\cdot \\binom{N_0}{n-x}, \\] by the multiplication principle of counting (Theorem 1.1). Therefore, the probability of getting exactly \\(x\\) \\(\\fbox{1}\\)s in \\(n\\) draws is: \\[ f(x) = P(X = x) = \\dfrac{\\binom{N_1}{x}\\binom{N_0}{n-x}}{\\binom{N}{n}}. \\] Visualizing the Distribution Let’s graph the hypergeometric distribution for different values of \\(n\\), \\(N_1\\), and \\(N_0\\). First, we hold the number of draws constant at \\(n=5\\) and vary the composition of the box. The distribution shifts, depending on the composition of the box. The more \\(\\fbox{1}\\)s there are in the box, the more \\(\\fbox{1}\\)s in the sample. Next, we study how the distribution changes as a function of \\(n / N\\), the relative fraction of tickets removed from the box. For all of the graphs below, \\(N_1 = N_0 = N/2\\). All three plots are symmetric, which makes sense, since there are exactly as many \\(\\fbox{1}\\)s as \\(\\fbox{0}\\)s in the box. However, when the number of draws makes up a large fraction of the box, as in the leftmost plot, the distribution is very tightly concentrated around intermediate values, such as 4, 5, and 6. This makes sense because sampling without replacement is “self-balancing”. Each time we draw a \\(\\fbox{1}\\), it becomes less likely that we will draw a \\(\\fbox{1}\\) again (and more likely to draw a \\(\\fbox{0}\\)). This makes extreme outcomes, such as drawing all \\(\\fbox{1}\\)s, less likely. Calculating Hypergeometric Probabilities on the Computer Calculating hypergeometric probabilities by hand is unwieldy when \\(n\\), \\(N_1\\), and \\(N_0\\) are large. Fortunately, the hypergeometric distribution is built into many software packages. For example, suppose we want to solve the following problem. Example 12.2 (Capture-Recapture) One way to estimate the number of animals in a population is capture-recapture. For example, suppose we want to estimate the number of fish in a lake. Clearly, it is impractical to catch all of the fish. Instead, we capture \\(m\\) fish one week, tag them, and release them back into the lake. We go back the next week, after these tagged fish have had a chance to mix with the population, and catch another \\(n\\) distinct fish. Some, but not all, of these \\(n\\) fish will be tagged. The number of tagged fish in this second catch allows us to estimate the population of fish in the lake. Suppose there are actually 100 fish in the lake; we capture \\(m=20\\) fish the first week and \\(n=30\\) fish the next week. What is the probability that at least \\(7\\) of the \\(30\\) fish will be tagged? Solution. We can represent this using a box model. The fish in the lake will be represented by \\(N=100\\) tickets, with \\[\\begin{align*} \\text{$N_1=20$ tickets labeled } \\fbox{1} &amp;\\text{ representing the tagged fish} \\\\ \\text{$N_0=80$ tickets labeled } \\fbox{0} &amp;\\text{ representing the non-tagged fish}. \\end{align*}\\] Now, if we draw \\(n=30\\) times from this box without replacement, then the number of \\(\\fbox{1}\\)s we get corresponds to the number of tagged fish we get. Therefore, the number of tagged fish is a \\(\\text{Hypergeometric}(n=30, N_1=20, N_0=80)\\) random variable. However, to calculate the probability that at least \\(7\\) of the \\(30\\) fish will be tagged, we have to evaluate the p.m.f. at 7, 8, 9, etc. This is a job for a computer, not a human. In Python, we use a library called Symbulate. We first specify the parameters of the hypergeometric distribution; then we evaluate the p.m.f. using the .pmf() method. Note that .pmf() accepts either a single number or a list of numbers. If a list of numbers is passed into .pmf(), then it will evaluate the p.m.f. at each of those numbers, returning a list of probabilities. from symbulate import * probs = Hypergeometric(n=30, N1=20, N0=80).pmf(range(7, 31)) probs ## array([1.80287211e-01, 1.16176457e-01, 5.77600464e-02, 2.22376179e-02, ## 6.62820205e-03, 1.52341741e-03, 2.67853610e-04, 3.55743076e-05, ## 3.50270105e-06, 2.48771382e-07, 1.22310776e-08, 3.89715707e-10, ## 7.13438366e-12, 5.60558716e-14, 0.00000000e+00, 0.00000000e+00, ## 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ## 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]) To add these probabilities, we call sum(): sum(probs) ## 0.38492014376629696 We could have also gotten the same answer by using c.d.f.s. Note that \\(P(X \\geq 7) = 1 - F(6)\\). 1 - Hypergeometric(n=30, N1=20, N0=80).cdf(6) ## 0.384920143766305 You can play around with the Python code in this Colab notebook. It is possible to do the same calculation in R, a statistical programming language. Note that R uses different names for the parameters. Like Python, R can evaluate the p.m.f. at a single value or a vector of values. probs &lt;- dhyper(x=7:30, m=20, n=80, k=30) probs ## [1] 1.802872e-01 1.161765e-01 5.776005e-02 2.223762e-02 6.628202e-03 ## [6] 1.523417e-03 2.678536e-04 3.557431e-05 3.502701e-06 2.487714e-07 ## [11] 1.223108e-08 3.897157e-10 7.134384e-12 5.605587e-14 0.000000e+00 ## [16] 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 ## [21] 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 To add these probabilities, we call sum(): sum(probs) ## [1] 0.3849201 We could have also gotten the same answer by using c.d.f.s. Notice how R uses the prefix d for p.m.f.s and the prefix p for c.d.f.s. 1 - phyper(6, m=20, n=80, k=30) ## [1] 0.3849201 You can play around with the R code in this Colab notebook. Another Formula for the Hypergeometric Distribution (optional) There is another formula for the hypergeometric p.m.f. that looks different but is equivalent to (12.1). It is based on counting the number of ordered outcomes, instead of the number of unordered outcomes. You should verify that this formula gives the same probabilities as (12.1). Theorem 12.2 (Another Formula for the Hypergeometric) The p.m.f. of a \\(\\text{Hypergeometric}(n, N_1, N_0)\\) random variable can also be written as \\[ f(x) = \\frac{\\binom{n}{x} \\cdot \\frac{N_1!}{(N_1 - x)!} \\cdot \\frac{N_0!}{(N_0 - n + x)!}}{\\frac{N!}{(N-n)!}}. \\] Proof. There are \\(\\frac{N!}{(N-n)!}\\) ways to choose \\(n\\) tickets from \\(N\\), if we account for the order in which \\(n\\) the tickets were drawn. How many of these ordered outcomes have exactly \\(x\\) \\(\\fbox{1}\\)s and \\(n-x\\) \\(\\fbox{0}\\)s? Let’s start by counting the number of outcomes that look like \\[\\begin{equation} \\underbrace{\\fbox{1}, \\ldots, \\fbox{1}}_{x}, \\underbrace{\\fbox{0}, \\ldots, \\fbox{0}}_{n-x}, \\tag{12.2} \\end{equation}\\] in this exact order. There are \\(N_1\\) choices for the first \\(\\fbox{1}\\), \\(N_1 - 1\\) choices for the second, and so on, until we get to the last \\(\\fbox{1}\\), for which there are \\(N_1 - x + 1\\) choices. Then, there are \\(N_0\\) choices for the first \\(\\fbox{0}\\), \\(N_0 - 1\\) choices for the second, and so on. By the multiplication principle of counting (Theorem 1.1), there are \\[\\begin{equation} \\underbrace{N_1 \\cdot (N_1 - 1) \\cdot \\ldots \\cdot (N_1 - x + 1)}_{\\displaystyle\\frac{N_1!}{(N_1 - x)!}} \\cdot \\underbrace{N_0 \\cdot (N_0 - 1) \\cdot \\ldots \\cdot (N_0 - (n - x) + 1)}_{\\displaystyle\\frac{N_0!}{(N_0 - n + x)!}}. \\tag{12.3} \\end{equation}\\] ways to get an outcome like (12.2), in that exact order. However, because we are counting ordered outcomes, we need to account for the possibility that the \\(\\fbox{1}\\)s and \\(\\fbox{0}\\)s were drawn in a different order than (12.2). There are \\(\\binom{n}{x}\\) ways to reorder the \\(\\fbox{1}\\)s and \\(\\fbox{0}\\)s, each of which can be obtained in (12.3) ways. So the total number of (ordered) ways to get \\(x\\) \\(\\fbox{1}\\)s and \\(n-x\\) \\(\\fbox{0}\\)s is \\[ \\binom{n}{x} \\cdot \\frac{N_1!}{(N_1 - x)!} \\cdot \\frac{N_0!}{(N_0 - n + x)!} \\] So the p.m.f. can be written as \\[ f(x) = P(X = x) = \\frac{\\binom{n}{x} \\cdot \\frac{N_1!}{(N_1 - x)!} \\cdot \\frac{N_0!}{(N_0 - n + x)!}}{\\frac{N!}{(N-n)!}}. \\] It is easy to see that this formula is equivalent to (12.1), if you write out the binomial coefficients in (12.1) as factorials and regroup \\(\\frac{n!}{x! (n-x)!}\\) as \\(\\binom{n}{x}\\). Essential Practice Recall in the example from Lesson 10, there was another player, Bob, who had two Jacks and was looking to get a four-of-a-kind. For Bob, the random variable of interest was the number of Jacks among the community cards. Use a box model to argue that Bob’s random variable also has a hypergeometric distribution. What are its parameters? In order to ensure safety, a random sample of cars on each production line are crash-tested before being released to the public. The process of crash testing destroys the car. Suppose that a production line contains 10 defective and 190 working cars. If 4 of these cars are chosen at random for crash-testing, what is: the probability that at least 1 car will be found defective? the probability that exactly 2 cars will be found defective? The state proposes a lottery in which you select \\(6\\) numbers from \\(1\\) to \\(15\\). When it is time to draw, the lottery selects \\(8\\) different numbers, and you win if at least \\(4\\) of the \\(6\\) numbers you picked are among the \\(8\\) numbers that the lottery drew. What is the probability you win the prize? Additional Exercises You are enrolled in \\(3\\) courses this quarter, and the breakdown of majors by class is as follows: Class 1: \\(4\\) Statistics majors and \\(6\\) Computer Science majors Class 2: \\(17\\) Statistics majors and \\(13\\) Computer Science majors Class 3: \\(11\\) Statistics majors and \\(9\\) Computer Science majors If you take a simple random sample of \\(20\\%\\) of the students in Class 1, what is the probability that the number of Statistics majors in your sample is equal to the number of Computer Science majors? (Note: In a simple random sample, each student can be selected at most once.) Now, suppose you pick one of your \\(3\\) classes at random and then choose a random sample of \\(20\\%\\) of students from that class. What is the probability that the number of Statistics majors in your sample is equal to the number of Computer Science majors in your sample? In Texas Hold’em, each player has \\(2\\) cards of their own, and all players share \\(5\\) cards in the center of the table. A player has a flush when there are at least \\(5\\) cards of the same suit out of the \\(7\\) total cards. The deck is shuffled between hands, so that the probability you obtain a flush is independent from hand to hand. What is the probability that you get a flush at least once in \\(10\\) hands of Texas Hold’em? (Hint: First, calculate the probability of a flush of spades. Then, repeat for the other suits, and add the probabilities together to obtain the overall probability of a flush.) There are \\(25\\) coins in a jar. \\(15\\) are quarters, \\(7\\) are dimes, and \\(3\\) are pennies. Each time you reach in the jar, you are equally likely to pick any of the coins in the jar. The coins are not replaced in the jar after each draw. What is the minimum number of times you must reach in the jar to have at least a \\(50\\%\\) chance of getting all \\(3\\) pennies? (Hint: In this question, \\(n\\) is unknown. You will have to try a few different values of \\(n\\) to get the answer.) "],
["binomial.html", "Lesson 13 Binomial Distribution Motivating Example Theory Essential Practice Additional Exercises", " Lesson 13 Binomial Distribution Motivating Example In 1693, Samuel Pepys (who is best remembered today for his diary) wrote a letter to Isaac Newton inquiring about a wager that Pepys was planning to make. Pepys wanted to know which of the following events had the highest probability of occurring. A. 6 dice are thrown and at least 1 is a ⚅ B. 12 dice are thrown and at least 2 are ⚅s C. 18 dice are thrown and at least 3 are ⚅s Pepys thought that C had the highest probability, but Newton disagreed. The probability of A is straightforward to calculate. We use the Complement Rule (Theorem 5.2), much like we did in the Chevalier de Méré example from Lesson 5. \\[\\begin{align*} P(\\text{at least 1 ⚅ in 6 rolls}) &amp;= 1 - P(\\text{0 ⚅s in 6 rolls}) \\\\ &amp;= 1 - \\frac{5^6}{6^6} \\\\ &amp;\\approx .665 \\end{align*}\\] However, the probabilities of the other two events are trickier to calculate. For example, it is not obvious how to count the number of ways to get exactly 2 sixes in 18 dice rolls. In this lesson, we learn how this is done. Theory In this lesson, we learn another named distribution that is virtually identical to the hypergeometric distribution, except in one important detail: the draws are made with replacement instead of without replacement. Theorem 13.1 (Binomial Distribution) If a random variable can be described as the number of \\(\\fbox{1}\\)s in \\(n\\) random draws, with replacement, from the box \\[ \\overbrace{\\underbrace{\\fbox{0}\\ \\ldots \\fbox{0}}_{N_0}\\ \\underbrace{\\fbox{1}\\ \\ldots \\fbox{1}}_{N_1}}^N, \\] then its p.m.f. is given by \\[\\begin{equation} f(x) = \\dfrac{\\binom{n}{x} N_1^x N_0^{n-x}}{N^n}, x=0, ..., n, \\tag{13.1} \\end{equation}\\] where \\(N = N_1 + N_0\\) is the number of tickets in the box. We say that the random variable has a \\(\\text{Binomial}(n, N_1, N_0)\\) distribution, and \\(n\\), \\(N_1\\), \\(N_0\\) are called parameters of the distribution. Equivalently, (13.1) can be written as \\[\\begin{equation} f(x) = \\binom{n}{x} p^x (1 - p)^{n-x}, x=0, ..., n, \\tag{13.2} \\end{equation}\\] where \\(p = N_1 / N\\) is the proportion of \\(\\fbox{1}\\)s in the box. We will derive the formulas (13.1) and (13.2) later in this lesson. For now, let’s see how these formulas allow us to bypass calculations. Example 13.1 (The Newton-Pepys Problem) Let’s model each die roll as a draw from a box. Each die has \\(6\\) equally likely outcomes, so we place \\(N=6\\) tickets into the box. Since we are only interested in the number of ⚅s, we will label only one these tickets \\(\\fbox{1}\\), corresponding to a ⚅; the other five tickets will be labeled \\(\\fbox{0}\\). \\[ \\fbox{$\\fbox{1}\\ \\fbox{0}\\ \\fbox{0}\\ \\fbox{0}\\ \\fbox{0}\\ \\fbox{0}$} \\] To model 12 rolls of the die, we draw \\(n=12\\) tickets with replacement. We draw with replacement so that the outcome of one die roll does not affect the outcome of another. In other words, we want the dice rolls to be independent, and drawing with replacement is the only way to model independence. The number of \\(\\fbox{1}\\)s in these 12 draws represents the number of ⚅s that one would get in 12 rolls of a fair die. Therefore, by Theorem 13.1, we now know that the number of ⚅s in 12 rolls follows a \\(\\text{Binomial}(n=12, N_1=1, N_0=5)\\) distribution. We can now write down the p.m.f. by plugging the values of the parameters \\(n\\), \\(N_1\\), \\(N_0\\) into (13.1): \\[ f(x) = \\frac{\\binom{12}{x} 1^x 5^{12-x}}{6^{12}}, x=0, 1, \\ldots, 12. \\] Equivalently, we have \\(p = N_1/N = 1/6\\), and plugging in the values of the parameters \\(n\\) and \\(p\\) into (13.2), we have: \\[ f(x) = \\binom{12}{x} \\left(\\frac{1}{6}\\right)^x \\left(\\frac{5}{6} \\right)^{12-x}, x=0, 1, \\ldots, 12. \\] Both formulas should produce the same probabilities. To answer Pepys’ question about the probability of getting at least 2 ⚅s in 12 rolls, we combine the binomial distribution with the complement rule, \\[\\begin{align*} P(X \\geq 2) &amp;= 1 - P(X \\leq 1) \\\\ &amp;= 1 - (f(0) + f(1)) \\\\ &amp;= 1 - \\binom{12}{0} \\left(\\frac{1}{6}\\right)^0 \\left(\\frac{5}{6} \\right)^{12} - \\binom{12}{1} \\left(\\frac{1}{6}\\right)^1 \\left(\\frac{5}{6} \\right)^{11} \\\\ &amp;= 1 - \\left(\\frac{5}{6} \\right)^{12} - 12 \\left(\\frac{1}{6}\\right) \\left(\\frac{5}{6} \\right)^{11} \\\\ &amp;\\approx .6187. \\end{align*}\\] Now, let’s derive the p.m.f. of the binomial distribution. Proof (Theorem 13.1). To calculate the p.m.f. at \\(x\\), we need to calculate the probability of getting exactly \\(x\\) \\(\\fbox{1}\\)s in \\(n\\) draws. First, there are \\(N^n\\) ordered ways to draw \\(n\\) tickets from \\(N\\) with replacement. (We must count ordered outcomes because the unordered outcomes are not all equally likely. See Lesson 4.) Next, we count the outcomes that have exactly \\(x\\) \\(\\fbox{1}\\)s. We proceed in two steps: Count outcomes that look like \\[\\begin{equation} \\underbrace{\\fbox{1}, \\ldots, \\fbox{1}}_{x}, \\underbrace{\\fbox{0}, \\ldots, \\fbox{0}}_{n-x}, \\tag{13.3} \\end{equation}\\] where the \\(x\\) \\(\\fbox{1}\\)s are drawn first. There are \\(N_1\\) choices for the first \\(\\fbox{1}\\), \\(N_1\\) choices for the second \\(\\fbox{1}\\), and in fact, \\(N_1\\) choices for each of the \\(x\\) \\(\\fbox{1}\\)s, since we are drawing with replacement. Likewise, there are \\(N_0\\) choices for each of the \\(n-x\\) \\(\\fbox{0}\\)s. By the multiplication principle of counting (Theorem 1.1), there are \\[\\begin{equation} N_1^x \\cdot N_0^{n-x}. \\tag{13.4} \\end{equation}\\] ways to get an outcome like (13.3), in that exact order. Account for the possibility that the \\(\\fbox{1}\\)s and \\(\\fbox{0}\\)s were drawn in a different order than (13.3). There are \\(\\binom{n}{x}\\) ways to rearrange the \\(\\fbox{1}\\)s and \\(\\fbox{0}\\)s. So the total number of (ordered) ways to get \\(x\\) \\(\\fbox{1}\\)s and \\(n-x\\) \\(\\fbox{0}\\)s is \\[ \\binom{n}{x} \\cdot N_1^x \\cdot N_0^{n-x}. \\] Dividing this by the total number of outcomes \\(N^x\\) gives the p.m.f.: \\[ f(x) = P(X = x) = \\frac{\\binom{n}{x} \\cdot N_1^x \\cdot N_0^{n-x}}{N^n}. \\] To see that this formula is the same as (13.2), we write \\(N^n = N^x \\cdot N^{n-x}\\). Then, we have: \\[\\begin{align*} f(x) &amp;= \\binom{n}{x}\\frac{N_1^x \\cdot N_0^{n-x}}{N^x \\cdot N^{n-x}} \\\\ &amp;= \\binom{n}{x} \\left( \\frac{N_1}{N} \\right)^x \\left( \\frac{N_0}{N} \\right)^{n-x} \\\\ &amp;= \\binom{n}{x} p^x (1 - p)^{n-x}, \\end{align*}\\] where in the last line, we used the fact that \\(\\frac{N_0}{N} = \\frac{N - N_1}{N} = 1 - \\frac{N_1}{N} = 1 - p\\). Visualizing the Distribution Let’s graph the binomial distribution for different values of \\(n\\), \\(N_1\\), and \\(N_0\\). First, we hold the number of draws constant at \\(n=5\\) and vary the composition of the box. The distribution shifts, depending on the composition of the box. The more \\(\\fbox{1}\\)s there are in the box, the more \\(\\fbox{1}\\)s in the sample. Next, we study how the distribution changes as a function of \\(n / N\\), the relative fraction of draws we make from the box. For all of the graphs below, \\(N_1 = N_0 = N/2\\). In contrast to the hypergeometric distribution, the binomial distribution does not change when we vary the number of tickets in the box, as long as we keep the relative proportions of \\(\\fbox{1}\\)s and \\(\\fbox{0}\\)s the same. This makes sense because we are drawing with replacement, so it does not matter how many draws we make; the box always looks the same. The binomial distribution is indifferent to the exact number of tickets \\(N\\) in the box. For example, to model a coin toss, we could use \\[ \\displaystyle \\fbox{\\(\\fbox{1}\\ \\fbox{0}\\)} \\] or \\[ \\displaystyle \\fbox{\\(\\fbox{1}\\ \\fbox{1}\\ \\fbox{0}\\ \\fbox{0}\\)}. \\] Although the first box may be more natural, the second box is equally valid. Any box with the same number of \\(\\fbox{1}\\)s as \\(\\fbox{0}\\)s can be used to model a coin toss, since they all guarantee a 50% chance of drawing a \\(\\fbox{1}\\). The fact that the binomial distribution does not depend on \\(N\\) should not be surprising in light of (13.2), which shows that the binomial p.m.f. can be written solely in terms of \\(p = N_1 / N\\), the proportion of \\(\\fbox{1}\\)s in the box. Calculating Binomial Probabilities on the Computer Calculating binomial probabilities by hand can be unwieldy when \\(n\\) is large. Fortunately, the binomial distribution is built into many software packages. For example, suppose we want to solve the following problem. Example 13.2 (Parity Checks) Messages that are exactly 50-bits long are regularly sent over a noisy communication channel. Each bit has a 1% chance of being corrupted by the channel. That is, the receiver saw a \\(0\\) where the original message had a \\(1\\), and vice versa. Each bit is corrupted independently of any other bit. To help detect errors, a 51st bit, called a parity bit, is sent along with the message. This bit is chosen to make the sum of all 51 bits come out to an even integer. When the receiver receives the message, she can calculate the sum of all 51 bits herself. If the sum is odd, then she knows that the message has been corrupted and can ask the sender to resend the message. This is called a parity check. The parity check works if exactly one bit is corrupted. However, if exactly two bits are corrupted, then the sum of all 51 bits will be even, and hence the receiver will not detect the error. In general, errors will not be detected if an even number of bits are corrupted. What is the probability that a corrupted message goes undetected? Solution. First, we will set up a box model for the number of corrupted bits. We have a box with \\(N_0 = 99\\) tickets labeled \\(\\fbox{0}\\) \\(N_1 = 1\\) tickets labeled \\(\\fbox{1}\\) to represent the 1% chance that each bit is corrupted. We will draw 51 times from this box to represent the 51 bits in the message. We draw with replacement, since the bits are corrupted independently. Now, the number of \\(\\fbox{1}\\)s in the 51 draws corresponds to the number of corrupted bits. Therefore, we know that the number of corrupted bits, which we will call \\(X\\), follows a \\(\\text{Binomial}(n=51, N_1=1, N_0=99)\\) distribution. The probability that a corrupted message goes undetected is the probability that \\(X\\) is positive and even. (If \\(X=0\\), then the message was not corrupted in the first place. If \\(X\\) is odd, then the error will be caught by the parity check.) To calculate this probability, we sum the p.m.f. over the relevant values: \\[\\begin{align*} P(\\text{corrupted message goes undetected}) &amp;= P(\\text{$X$ is positive and even}) \\\\ &amp;= f(2) + f(4) + f(6) + \\ldots + f(50) \\end{align*}\\] This requires evaluating the p.m.f. at 25 different values! This is a job for a computer, not a human. Here’s how we would calculate the probability using the Python library Symbulate. We first specify the parameters of the binomial distribution. Note that Symbulate requires that the parameters be \\(n\\) and \\(p\\), so we have to convert \\(N_1=1, N_0=99\\) into \\(p = 0.01\\). Then, we create a list of the positive even values and evaluate the p.m.f. at all of these values, in one fell swoop, using the .pmf() method. from symbulate import * probs = Binomial(n=51, p=0.01).pmf(range(2, 51, 2)) probs ## array([7.79174480e-02, 1.55818996e-03, 1.14573571e-05, 4.13324569e-08, ## 8.46244910e-11, 1.07274277e-13, 8.91255091e-17, 5.04689904e-20, ## 2.00253338e-23, 5.67792557e-27, 1.16616574e-30, 1.75027722e-34, ## 1.92868014e-38, 1.56177790e-42, 9.26787459e-47, 4.00356955e-51, ## 1.24511721e-55, 2.74244677e-60, 4.17928311e-65, 4.26413949e-70, ## 2.77920480e-75, 1.07909959e-80, 2.23393269e-86, 2.02064767e-92, ## 5.04900000e-99]) To add these probabilities, we call sum(): sum(probs) ## 0.07948713677652883 You can play around with the Python code in this Colab notebook. It is also possible to do this calculation in R, a statistical programming language. Note that R uses the names size= and prob= for \\(n\\) and \\(p\\), respectively. We create a list of the positive even integers from 2 to 51, and evaluate the binomial p.m.f. at these values. probs &lt;- dbinom(seq(from=2, to=51, by=2), size=51, prob=0.01) probs ## [1] 7.791745e-02 1.558190e-03 1.145736e-05 4.133246e-08 8.462449e-11 ## [6] 1.072743e-13 8.912551e-17 5.046899e-20 2.002533e-23 5.677926e-27 ## [11] 1.166166e-30 1.750277e-34 1.928680e-38 1.561778e-42 9.267875e-47 ## [16] 4.003570e-51 1.245117e-55 2.742447e-60 4.179283e-65 4.264139e-70 ## [21] 2.779205e-75 1.079100e-80 2.233933e-86 2.020648e-92 5.049000e-99 To add these probabilities, we call sum(): sum(probs) ## [1] 0.07948714 You can play around with the R code in this Colab notebook. Essential Practice Show Mr. Pepys that C (at least 3 ⚅s in 18 rolls) is actually the least likely of the three options. About 10% of passengers who are scheduled to take a particular flight fail to show up. For this reason, airlines overbook flights, selling more tickets than they have seats, with the expectation that they will have some no shows. An airline with seating for 100 passengers sells 110 tickets for the flight. What is the probability that they will have enough seats for all the passengers for all of the passengers who show up for the flight? (Assume that passengers independently show up for the flight. Can you think of a situation where this would not be a reasonable assumption?) In the World Series of baseball, two teams (call them A and B) play a sequence of games against each other, and the first team to win four games wins the series. Suppose team \\(A\\) is slightly better, with a \\(0.6\\) probability of winning each game, and assume the games are independent. What is the probability that team \\(A\\) wins the series? (Hint: After 7 games, one of the teams must have won the Series. Even though the teams only play until one team has won four games, this calculation is easiest if you assume that the teams always play 7 games.) Additional Exercises "],
["geometric.html", "Lesson 14 Geometric Distribution Motivating Example Theory Essential Practice", " Lesson 14 Geometric Distribution Motivating Example In the casino game craps, after the “point” has been set, two dice are rolled repeatedly until either the “point” or a 7 comes up, at which time the round ends. Suppose the point is 4. What is the probability that it takes more than 6 rolls for the round to end? We can calculate the probability that the round ends on a given roll by directly counting the 36 possible outcomes of two dice: \\[ P(\\text{roll a 4 or a 7}) = \\frac{9}{36}. \\] But how do we use this to determine the probability that it takes more than 6 rolls for the round to end? Theory Theorem 14.1 (Geometric Distribution) If a random variable can be described as the number of draws, with replacement, from the box \\[ \\overbrace{\\underbrace{\\fbox{0}\\ \\ldots \\fbox{0}}_{N_0}\\ \\underbrace{\\fbox{1}\\ \\ldots \\fbox{1}}_{N_1}}^N \\] until a \\(\\fbox{1}\\) is drawn, then its p.m.f. is given by \\[\\begin{equation} f(x) = \\dfrac{N_0^{x-1} \\cdot N_1}{N^x}, x=1, 2, 3, \\ldots \\tag{14.1} \\end{equation}\\] where \\(N = N_1 + N_0\\) is the number of tickets in the box. We say that the random variable has a \\(\\text{Geometric}(N_1, N_0)\\) distribution, and \\(N_1\\), \\(N_0\\) are called parameters of the distribution. Equivalently, (14.1) can be written as \\[\\begin{equation} f(x) = (1-p)^{x-1} p, x=1, 2, 3, \\ldots, \\tag{14.2} \\end{equation}\\] where \\(p = N_1 / N\\) is the proportion of \\(\\fbox{1}\\)s in the box. So we can instead specify the distribution as \\(\\text{Geometric}(p)\\), where \\(p\\) is the parameter. Note that in contrast to the hypergeometric and binomial distributions, there is no upper bound on the possible values of the geometric distribution. We could draw an unlimited number of \\(\\fbox{0}\\)s, so in theory, we might need to wait an arbitrarily long time for a \\(\\fbox{1}\\). We will derive the formulas (14.1) and (14.2) later in this lesson. For now, let’s see how these formulas can be used to solve problems. Example 14.1 (The Craps Problem) Let’s model each roll as a draw from a box. There are \\(36\\) equally likely outcomes when we roll two dice, so we place \\(N=36\\) tickets into the box. Only 9 of these outcomes results in the end of the round, so we label \\(N_1=9\\) of these tickets as \\(\\fbox{1}\\); the other \\(N_0=27\\) tickets are labeled \\(\\fbox{0}\\). \\[ \\overbrace{\\underbrace{\\fbox{1}\\ \\ldots \\fbox{1}}_{N_1=9}\\ \\underbrace{\\fbox{0}\\ \\ldots \\fbox{0}}_{N_0=27}}^{N=36} \\] Now, the number of rolls until the end of the round is just the number of draws until a \\(\\fbox{1}\\) is drawn. So the number of rolls follows the \\(\\text{Geometric}(N_1=9, N_0=27)\\) distribution. We can now write down its p.m.f. by plugging the values of the parameters \\(N_1\\), \\(N_0\\) into (14.1): \\[ f(x) = \\frac{27^{x-1} \\cdot 9}{36^x}, x=1, 2, \\ldots. \\] Equivalently, we have \\(p = N_1/N = 9/36\\), and plugging in this value into (14.2), we have: \\[ f(x) = \\left(1 - \\frac{9}{36}\\right)^{x-1} \\frac{9}{36}, x=1, 2, \\ldots. \\] Finally, we can calculate probability that it takes more than 6 rolls for the round to end in a few different ways: Using the complement rule and the geometric distribution: \\[\\begin{align*} P(X &gt; 6) &amp;= 1 - P(X \\leq 6) \\\\ &amp;= 1 - (f(1) + f(2) + \\ldots + f(6)) \\\\ &amp;= 1 - \\left( \\frac{27}{36} \\right)^0 \\frac{9}{36} - \\left( \\frac{27}{36} \\right)^1 \\frac{9}{36} - \\ldots - \\left( \\frac{27}{36} \\right)^5 \\frac{9}{36} \\\\ &amp;\\approx .178. \\end{align*}\\] Directly, using the geometric distribution and the geometric series: \\[\\begin{align*} P(X &gt; 6) &amp;= f(7) + f(8) + f(9) + ... \\\\ &amp;= \\left( \\frac{27}{36} \\right)^6 \\frac{9}{36} + \\left( \\frac{27}{36} \\right)^7 \\frac{9}{36} + \\left( \\frac{27}{36} \\right)^8 \\frac{9}{36} + \\ldots \\\\ &amp;= \\frac{\\left( \\frac{27}{36} \\right)^6 \\frac{9}{36}}{ 1 - \\frac{27}{36}} \\\\ &amp;\\approx .178. \\end{align*}\\] In the second-to-last line, we used the formula for an infinite geometric series: \\[ a + ar + ar^2 + ar^3 + \\ldots = \\frac{a}{1 - r}, |r| &lt; 1. \\] Without using the geometric distribution at all. In order for the round to end after more than 6 rolls, the first 6 rolls must all have failed to end the round. In other words, all 6 of these rolls resulted in one of the other 27 outcomes. The probability of this is \\[ \\frac{27^6}{36^6} \\approx .178. \\] Now, let’s derive the p.m.f. of the geometric distribution. Proof (Theorem 14.1). To calculate the p.m.f. at \\(x\\), we need to determine the probability that it takes exactly \\(x\\) draws to get the first \\(\\fbox{1}\\). First, there are \\(N^x\\) equally likely ways to draw \\(x\\) tickets from \\(N\\) with replacement, taking order into account. (We must count ordered outcomes because the unordered outcomes are not all equally likely. See Lesson 4.) Next, we count the outcomes where the first \\(\\fbox{1}\\) is on the \\(x\\)th draw. In order for this to happen, the first \\(x-1\\) draws must all be \\(\\fbox{0}\\)s and the \\(x\\)th draw a \\(\\fbox{1}\\): \\[\\begin{equation} \\underbrace{\\fbox{0}, \\ldots, \\fbox{0}}_{x-1}, \\fbox{1}. \\tag{14.3} \\end{equation}\\] The number of ways to do this is: \\[\\begin{equation} \\underbrace{N_0 \\cdot \\ldots \\cdot N_0}_{x-1} \\cdot N_1, \\tag{14.4} \\end{equation}\\] since we are drawing with replacement (so the composition of the box does not change from one draw to the next). Dividing this by the total number of outcomes, we obtain the p.m.f. \\[ f(x) = P(X = x) = \\frac{N_0^{x-1} \\cdot N_1}{N^x}. \\] To see that this formula is the same as (14.2), we write \\(N^x = N^{x-1} \\cdot N\\). Then, we have: \\[\\begin{align*} f(x) &amp;= \\frac{N_0^{x-1} \\cdot N_1}{N^{x-1} \\cdot N} \\\\ &amp;= \\left( \\frac{N_0}{N} \\right)^{x-1} \\frac{N_1}{N} \\\\ &amp;= (1 - p)^{x-1} p, \\end{align*}\\] where in the last line, we used the fact that \\(\\frac{N_0}{N} = \\frac{N - N_1}{N} = 1 - \\frac{N_1}{N} = 1 - p\\). Visualizing the Distribution Let’s graph the geometric distribution for different values of \\(N_1\\) and \\(N_0\\). As the number of \\(\\fbox{1}\\)s in the box increases, we tend to draw a \\(\\fbox{1}\\) sooner, so not surprisingly, smaller values of the geometric random variable become more probable. Essential Practice Carl is a bad driver, so each time he takes the driving test, he only has a \\(30\\%\\) chance of passing, independently of all previous attempts. If he takes the driving test over and over until he passes, what is the probability that he passes within his first 5 attempts? Samuel Pepys was interested in the probability of getting at least 1 ⚅ in 6 throws of a die. Previously, we saw how this probability could be calculated using the complement rule or the binomial distribution. Show how this probability can also be calculated by defining an appropriate geometric random variable. "],
["negative-binomial.html", "Lesson 15 Negative Binomial Distribution Motivating Example Theory Essential Practice Additional Exercises", " Lesson 15 Negative Binomial Distribution Motivating Example On a (American) roulette wheel, there are 38 spaces: 18 black, 18 red, and 2 green. You’ve been at the casino for a while now and decide to leave after you have won 3 bets on red. What is the probability that you leave the casino after placing exactly 5 bets on red? Theory To answer the question posed at the beginning of the lesson, we need a distribution like the geometric, except that stops after \\(3\\) \\(\\fbox{1}\\)s have been drawn (instead of after the first \\(\\fbox{1}\\)). The negative binomial is that distribution. Theorem 15.1 (Negative Binomial Distribution) If a random variable can be described as the number of draws, with replacement, from the box \\[ \\overbrace{\\underbrace{\\fbox{0}\\ \\ldots \\fbox{0}}_{N_0}\\ \\underbrace{\\fbox{1}\\ \\ldots \\fbox{1}}_{N_1}}^N \\] until \\(r\\) \\(\\fbox{1}\\)s have been drawn, then its p.m.f. is given by \\[\\begin{align} f(x) &amp;= \\dfrac{\\binom{x-1}{r-1} N_0^{x-r} \\cdot N_1^r}{N^x}, &amp; x&amp;=r, r+1, r+2, \\ldots \\tag{15.1} \\end{align}\\] where \\(N = N_1 + N_0\\) is the number of tickets in the box. We say that the random variable has a \\(\\text{NegativeBinomial}(r, N_1, N_0)\\) distribution, and \\(r\\), \\(N_1\\), \\(N_0\\) are called parameters of the distribution. Equivalently, (15.1) can be written as \\[\\begin{align} f(x) &amp;= \\binom{x-1}{r-1} (1-p)^{x-r} p^r, &amp; x &amp;= r, r+1, r+2, \\ldots, \\tag{15.2} \\end{align}\\] where \\(p = N_1 / N\\) is the proportion of \\(\\fbox{1}\\)s in the box. So we can instead specify the distribution as \\(\\text{NegativeBinomial}(r, p)\\), where \\(r\\) and \\(p\\) are the parameters. Like the geometric distribution, there is no upper bound on the possible values of a negative binomial random variable. We might have to wait arbitrarily long to collect \\(r\\) \\(\\fbox{1}\\)s. Also, note that the minimum possible value of a negative binomial random variable is \\(r\\). This makes sense because you need to have drawn at least \\(r\\) times before you can have \\(r\\) \\(\\fbox{1}\\)s. We will derive the formulas (15.1) and (15.2) later in this lesson. For now, let’s see how these formulas can be applied to real problems. Example 15.1 (Three Wins in Roulette) There are 38 equally likely spaces on a roulette wheel, 18 of which are red. So we set up a box model where the \\(\\fbox{1}\\)s represent the red spaces: \\[ \\overbrace{\\underbrace{\\fbox{1}\\ \\ldots \\fbox{1}}_{N_1=18}\\ \\underbrace{\\fbox{0}\\ \\ldots \\fbox{0}}_{N_0=20}}^{N=38} \\] The number of draws until we get \\(r=3\\) \\(\\fbox{1}\\)s corresponds to the number of bets we make until we have won 3 times. So the number of bets follows a \\(\\text{NegativeBinomial}(r=3, N_1=18, N_0=20)\\) distribution. Therefore, we know its p.m.f. by (15.2): \\[ f(x) = \\binom{x-1}{3-1} \\left( \\frac{20}{38} \\right)^{x-3} \\left( \\frac{18}{38} \\right)^3. \\] To calculate the probability that we leave the casino after exactly 5 bets, we plug in \\(5\\) for \\(x\\): \\[ f(5) = \\binom{4}{2} \\left( \\frac{20}{38} \\right)^2 \\left( \\frac{18}{38} \\right)^3 \\approx .1766. \\] Now, let’s derive the p.m.f. of the binomial distribution. Proof (Theorem 15.1). To calculate the p.m.f. at \\(x\\), we need to determine the probability that it takes exactly \\(x\\) draws to get \\(r\\) \\(\\fbox{1}\\)s. First, there are \\(N^x\\) equally likely ways to draw \\(x\\) tickets from \\(N\\) with replacement, taking order into account. (We must count ordered outcomes because the unordered outcomes are not all equally likely. See Lesson 4.) Next, we count the outcomes where the \\(r\\)th \\(\\fbox{1}\\) happens on the \\(x\\)th draw. We proceed in two steps: Count outcomes that look like \\[\\begin{equation} \\underbrace{\\fbox{0}, \\ldots, \\fbox{0}}_{x-r}, \\underbrace{\\fbox{1}, \\ldots, \\fbox{1}}_{r}, \\tag{15.3} \\end{equation}\\] where the \\(r\\) \\(\\fbox{1}\\)s are all at the end. There are \\(N_0\\) choices for the first \\(\\fbox{0}\\), \\(N_0\\) choices for the second \\(\\fbox{0}\\), and in fact, \\(N_0\\) choices for each of the \\(x-r\\) \\(\\fbox{0}\\)s, since we are drawing with replacement. Likewise, there are \\(N_1\\) choices for each of the \\(r\\) \\(\\fbox{1}\\)s. By the multiplication principle of counting (Theorem 1.1), there are \\[\\begin{equation} N_0^{x-r} \\cdot N_1^r. \\tag{15.4} \\end{equation}\\] ways to get an outcome like (15.3), in that exact order. Account for the possibility that the \\(\\fbox{1}\\)s and \\(\\fbox{0}\\)s were drawn in a different order than (15.3). Unlike the binomial, we cannot rearrange the \\(\\fbox{1}\\)s and \\(\\fbox{0}\\)s any order we like. With the negative binomial, the \\(x\\)th draw must be a \\(\\fbox{1}\\), since we need the \\(r\\)th \\(\\fbox{1}\\) to come on the \\(x\\)th draw. Other than this last draw, we have complete freedom to rearrange the remaining \\(r-1\\) \\(\\fbox{1}\\)s among the first \\(x-1\\) draws. Therefore, there are \\(\\binom{x-1}{r-1}\\) valid arrangements of the \\(\\fbox{1}\\)s and \\(\\fbox{0}\\)s where that the \\(r\\)th \\(\\fbox{1}\\) comes on the \\(x\\)th draw. So the total number of (ordered) ways to get the \\(r\\)th \\(\\fbox{1}\\)s on the \\(x\\)th draw is: \\[ \\binom{x-1}{r-1} \\cdot N_0^{x-r} \\cdot N_1^r. \\] Dividing this by the total number of outcomes, \\(N^x\\), gives the p.m.f.: \\[ f(x) = P(X = x) = \\frac{\\binom{x-1}{r-1} \\cdot N_0^{x-r} \\cdot N_1^r}{N^x}. \\] To see that this formula is the same as (15.2), we write \\(N^n = N^{x-r} \\cdot N^{r}\\). Then, we have: \\[\\begin{align*} f(x) &amp;= \\binom{x-1}{r-1} \\frac{N_0^{x-r} \\cdot N_1^r}{N^{x-r} \\cdot N^{r}} \\\\ &amp;= \\binom{x-1}{r-1} \\left( \\frac{N_0}{N} \\right)^{x-r} \\left( \\frac{N_1}{N} \\right)^{r} \\\\ &amp;= \\binom{x-1}{r-1} (1 - p)^{x-r} p^r, \\end{align*}\\] where in the last line, we used the fact that \\(\\frac{N_0}{N} = \\frac{N - N_1}{N} = 1 - \\frac{N_1}{N} = 1 - p\\). Visualizing the Distribution Let’s graph the negative binomial distribution for different values of \\(n\\), \\(N_1\\), and \\(N_0\\). First, we fix the number of \\(\\fbox{1}\\)s at \\(r=5\\) and vary the composition of the box. Not surprisingly, as we increase the number of \\(\\fbox{1}\\)s in the box, the \\(\\fbox{1}\\)s are drawn sooner, so the \\(r=5\\)th \\(\\fbox{1}\\) comes after fewer draws. Next, we study the effect of increasing \\(r\\) on the negative binomial distribution. Not surprisingly, when we require more \\(\\fbox{1}\\)s by increasing \\(r\\), the distribution shifts to the right, indicating that it takes longer to achieve that goal. Calculating Negative Binomial Probabilities on the Computer The negative binomial distribution is built into many software packages. However, we have to check which definition the package is using. Some packages define a negative binomial random variable to be the number of \\(\\fbox{0}\\)s that were drawn, instead of the total number of draws. Example 15.2 (Telemarketing) Suppose a telemarketer has a 15% chance of making a sale on any given phone call. He is required to make 10 successful sales before leaving for the day. What is the probability that he needs to make more than 40 calls? Solution. First, we will set up a box model for the number of calls. We have a box with \\(N_0 = 85\\) tickets labeled \\(\\fbox{0}\\) \\(N_1 = 15\\) tickets labeled \\(\\fbox{1}\\) to represent the 15% chance of making a sale. We will draw from this box until we have drawn 10 \\(\\fbox{1}\\)s, representing the 10 successful calls. We will assume that his success on one call is independent of his success on any other call, so we make the draws with replacement. This shows that the number of calls, which we will call \\(X\\), follows a \\(\\text{NegativeBinomial}(r=10, N_1=15, N_0=85)\\) distribution. The probability that he has to make more than 40 calls is \\(P(X &gt; 40)\\). To calculate this directly, we would have to evaluate an infinite sum: \\[ P(X &gt; 40) = f(41) + f(42) + f(43) + \\ldots. \\] The complement rule makes this slightly more palatable: \\[ P(X &gt; 40) = 1 - P(X \\leq 40) = 1 - f(40) - f(39) - \\ldots - f(10), \\] but this is still a calculation that would be unpleasant to do by hand. Here’s how we would calculate the probability using the Python library Symbulate. We first specify the parameters of the negative binomial distribution. Note that Symbulate requires that the parameters be \\(r\\) and \\(p\\), so we have to convert \\(N_1=15, N_0=85\\) into \\(p = 0.15\\). Calculating the probability directly involves evaluating the p.m.f. at infinitely many values, so we look at the complement. We can evaluate the p.m.f. at all of these values using the .pmf() method and add the probabilities using sum(). from symbulate import * probs = NegativeBinomial(r=10, p=0.15).pmf( range(10, 41) # range(..., 41) does not include 41 ) 1 - sum(probs) ## 0.9327797386121522 Alternatively, we could also calculate this using the c.d.f. and the complement rule: 1 - NegativeBinomial(r=10, p=0.15).cdf(40) ## 0.9327797386121518 You can play around with the Python code in this Colab notebook. It is also possible to do this calculation in R, a statistical programming language. R defines the negative binomial distribution a bit differently; it only counts the number of \\(\\fbox{0}\\)s that were drawn, rather than the total number of draws. So we have to remember to subtract the \\(r=10\\) \\(\\fbox{1}\\)s from the total number of draws before passing the values to dnbinom or pnbinom. probs &lt;- dnbinom((10:40) - 10 , size=10, prob=0.15) 1 - sum(probs) ## [1] 0.9327797 We can also use the c.d.f. function: 1 - pnbinom(40 - 10, size=10, prob=0.15) ## [1] 0.9327797 You can play around with the R code in this Colab notebook. Essential Practice Complete the sentence: The geometric distribution is a special case of the negative binomial distribution where \\(r=\\) _____. Calculate the following probabilities. You toss a coin 4 times. The probability that you get (exactly) 2 heads. You toss a coin until you get 2 heads. The probability that it takes (exactly) 4 tosses. Which is larger? Explain why the answer makes intuitive sense. In Major League Baseball’s Home Run Derby, each contestant is allowed to keep swinging the bat until they have made 10 “outs”. (An “out” is anything that is not a home run.) If Barry Bonds has a 70% chance of hitting a home run on any given swing, what is the probability that he hits at least 10 home runs before his turn is up? Additional Exercises A medical researcher is recruiting 20 subjects for a study on an experimental drug for COVID-19. Each person that she interviews has a 60% chance of being eligible to participate in the study. What is the probability that she will have to interview more than 40 people? Your coach tells you that you cannot leave basketball practice until you have made at least \\(20\\) free throws. If you free throw probability is \\(80\\%\\), find the probability that you are out of practice after taking an even amount of free throws. You have two coins. One coin is a fair coin with a \\(.5\\) probability of landing on heads. The other coin is a biased coin with a \\(.25\\) probability of landing on heads. You pick one of these two coins at random, and begin flipping until you get \\(5\\) heads. It takes you \\(12\\) flips in order to get your \\(5\\) heads. What is the probability that the coin you picked was the fair coin? What is the probability you picked the biased coin? "],
["poisson.html", "Lesson 16 Poisson Distribution Motivating Example Theory Essential Practice", " Lesson 16 Poisson Distribution Motivating Example You are in a room of \\(n\\) people (including yourself). Each person in the room has contributed $1 to a central pot, so there is a total of $\\(n\\) in the pot. The money in the pot will be redistributed back to the people in the room, in the following way: each dollar is equally likely to go to any one of the \\(n\\) people, independently of the other dollars in the pot. This means that some people could get more than $1, while others end up with nothing. As \\(n\\to\\infty\\), what is the probability that you end up with no money? There are two common schools of thought: As \\(n\\to\\infty\\), the number of dollars in the pot increases to infinity, so it seems that the probability that you end up with at least one of those dollars should approach \\(1\\), i.e., the probability that you end up with no money approaches 0. As \\(n\\to\\infty\\), the chance that you earn each dollar, \\(1/n\\), decreases to 0, so it seems that the probability that you end up with no money approaches 1. Which school of thought is correct? As it turns out, both arguments are wrong. Let’s see why. We can model the number of dollars you get as the number of \\(\\fbox{1}\\)s in \\(n\\) draws, with replacement, from the box \\[ \\overbrace{\\fbox{1}\\ \\underbrace{\\fbox{0}\\ \\ldots\\ \\fbox{0}}_{n-1}}^{n}. \\] (Each ticket in the box represents a person in the room. Each draw represents a dollar, and you only get that dollar if your name is drawn.) This is exactly the description of a \\(\\text{Binomial}(n, p=\\frac{1}{n})\\) distribution. So the probability that you end up with no money is \\[\\begin{align*} f(0) &amp;= \\binom{n}{0} \\left( \\frac{1}{n} \\right)^{0} \\left( 1 - \\frac{1}{n} \\right)^{n} \\\\ &amp;= \\left(1 - \\frac{1}{n} \\right)^n. \\end{align*}\\] What is the limit of this probability as \\(n\\to\\infty\\)? Try plugging in some very large numbers for \\(n\\) into the expression above. You will see that the probability is nowhere near 0 or 1. But what is it approaching? This is a very famous limit in mathematics. In case you are not familiar with it, take the (natural) logarithm to bring the \\(n\\) down from the exponent, and apply L’Hôpital’s Rule: \\[\\begin{align*} \\lim_{n\\to\\infty} \\log \\left(1 - \\frac{1}{n} \\right)^n &amp;= \\lim_{n\\to\\infty} n \\log \\left(1 - \\frac{1}{n} \\right) &amp; \\text{(Property of logs: $\\log b^a = a \\log b$)} \\\\ &amp;= \\lim_{x \\to 0} \\frac{\\log \\left(1 - x \\right)}{x} &amp; \\text{(Let $x = 1/n$.)} \\\\ &amp;= \\lim_{x \\to 0} \\frac{\\frac{d}{dx} \\log \\left(1 - x \\right)}{\\frac{d}{dx} x} &amp; \\text{(L&#39;Hôpital&#39;s Rule on $0/0$ indeterminate form)} \\\\ &amp;= \\lim_{x \\to 0} \\frac{-\\frac{1}{1 - x}}{1} &amp; \\text{(Remember your derivatives?)} \\\\ &amp;= -1. \\end{align*}\\] Remember that \\(-1\\) is the limit of the logarithm, so to obtain the limit of the original expression, we need to “undo” the logarithm, i.e., exponentiate: \\[\\begin{equation} \\lim_{n\\to\\infty} \\left(1 - \\frac{1}{n} \\right)^n = e^{-1}. \\tag{16.1} \\end{equation}\\] So the probability that you end up with no money approaches \\(1/e \\approx 0.368\\) as \\(n\\to\\infty\\). Theory The motivating example above illustrates a general phenomenon. A binomial distribution with large \\(n\\) and small \\(p\\) can be approximated by a p.m.f. involving the constant \\(e\\). The next theorem makes this precise. Theorem 16.1 (Poisson Distribution) Let \\(X\\) be a \\(\\text{Binomial}(n, p=\\frac{\\mu}{n})\\) random variable, where \\(\\mu\\) is a constant. Then, as \\(n\\to\\infty\\), the p.m.f. of \\(X\\) approaches \\[\\begin{align} f(x) &amp;= e^{-\\mu}\\dfrac{\\mu^x}{x!} &amp; x&amp;=0, 1, 2, .... \\tag{16.2} \\end{align}\\] A random variable with (16.2) as its p.m.f. is said to follow a \\(\\text{Poisson}(\\mu)\\) distribution. Example 16.1 In the motivating example, \\(\\mu = 1\\), so \\(f(0) = e^{-1} \\frac{1^0}{0!} = e^{-1}\\), which matches (16.1). Even when the data does not originate from a binomial model, it is common to assume that count data follow a Poisson distribution. In the next example, we are explicitly told that the random variable follows a Poisson distribution. Example 16.2 (Database Queries) The number of typos in a New York Times op-ed when it reaches the copy editor is a \\(\\text{Poisson}(\\mu=4.6)\\) random variable. What is the probability that there are 2 or more typos in a randomly selected op-ed? Solution. Let \\(X\\) be the number of typos in the op-ed. We want to know \\(P(X \\geq 2)\\). We could calculate this directly, but that would involve summing the p.m.f. at infinitely many values. Instead, we use the Complement Rule (5.2): \\[\\begin{align*} P(X \\geq 2) &amp;= 1 - P(X &lt; 2) \\\\ &amp;= 1 - f(0) - f(1) \\\\ &amp;= 1 - e^{-4.6} \\frac{4.6^0}{0!} - e^{-4.6} \\frac{4.6^1}{1!} \\\\ &amp;= 1 - e^{-4.6} - 4.6 e^{-4.6} \\\\ &amp;\\approx .944. \\end{align*}\\] Why might the Poisson distribution be a reasonable model for the number of typos? Each op-ed has many words (e.g., \\(n = 1000\\)). There is a small probability that each word has a typo (e.g., \\(p = .0046\\)). If typos are independent across words, then the number of typos follows a binomial distribution. Since \\(n\\) is large and \\(p\\) is small, this binomial distribution can be approximated by a \\(\\text{Poisson}(\\mu=np=4.6)\\) distribution. However, all of this is conjecture. We are not told how many words the op-ed has, nor the probability that each word has a typo. We simply assume that the number of typos follows a Poisson distribution. In practice, the Poisson model is often used for count data, even when there is no underlying binomial model. Finally, we include the proof of Theorem 16.1 for completeness. This proof is not particularly interesting or insightful, so you do not need to know it. Proof (Theorem 16.1, optional). Substitute \\(p = \\frac{\\mu}{n}\\) into the binomial p.m.f. and watch what happens as \\(n \\to \\infty\\): \\[\\begin{align*} f(x) &amp;= \\binom{n}{x} (\\frac{\\mu}{n})^x (1 - \\frac{\\mu}{n})^{n-x} \\\\ &amp;= \\frac{n!}{x!(n-x)!} \\frac{\\mu^x}{n^x} (1 - \\frac{\\mu}{n})^{n-x} \\\\ &amp;= \\frac{n!}{(n-x)! n^x} \\cdot \\frac{\\mu^x}{x!} \\cdot (1 - \\frac{\\mu}{n})^{n-x} \\\\ &amp;\\to 1 \\cdot \\frac{\\mu^x}{x!} \\cdot e^{-\\mu} \\end{align*}\\] Visualizing the Distribution Let’s graph the Poisson distribution for different values of \\(\\mu\\). The probability mass shifts to the right as \\(\\mu\\) increases. This makes sense if we interpret the Poisson distribution as an approximation to the binomial, where \\(\\mu=np\\). To increase \\(\\mu\\), we must either increase \\(n\\) or \\(p\\), both of which tend to increase the number of \\(\\fbox{1}\\)s that we draw. Calculating Poisson Probabilities on the Computer The Poisson distribution is built into many software packages. Example 16.3 (Disk Failures at a Data Center) A data center has 10,000 disk drives. Suppose that a disk drive fails in a given day with probability \\(10^{-3}\\). What is the probability that there are 12 or more disk failures tomorrow? How many spare disk drives should be available so that all failures in a day can be replaced with probability 99%? Solution. First, we will set up a box model for the number of disk failures. We have a box with \\(N_0 = 999\\) tickets labeled \\(\\fbox{0}\\) \\(N_1 = 1\\) tickets labeled \\(\\fbox{1}\\) to represent the \\(10^{-3}\\) probability of failure. We will draw 10,000 tickets from this box, with replacement, to represent whether each of the 10,000 disks fails. This shows that the number of failures, which we will call \\(X\\), follows a \\(\\text{Binomial}(n=10^4, p=10^{-3})\\) distribution. We can calculate the exact probabilities using this binomial distribution or approximate probabilities using a \\(\\text{Poisson}(\\mu=np=10)\\) distribution. Either way, we will want to calculate the probabilities at a computer. For example, the quickest way to calculating \\(P(X \\geq 12)\\) still requires calculating \\[ 1 - f(0) - f(1) - f(2) - \\ldots - f(11), \\] which is not something we want to do by hand. Here’s how we would calculate the probability using the Python library Symbulate. from symbulate import * probs = Poisson(10).pmf( range(12) # range(12) is [0, 1, 2, ..., 11] ) 1 - sum(probs) ## 0.303223853696892 Alternatively, we could also calculate this using the c.d.f. and the complement rule. This time, let’s compare the approximate answer that we get from the Poisson distribution with the exact answer that we get from the binomial distribution. 1 - Poisson(10).cdf(11), 1 - Binomial(n=10 ** 4, p=10 ** -3).cdf(11) ## (0.30322385369689386, 0.30316693332735856) Very close indeed! The second question can be addressed by trial and error. We want to figure out the value \\(c\\) such that \\(F(c) = P(X \\leq c) = .99\\). From above, we already know that \\(F(11) \\approx 0.70\\), so we can start trying values from \\(c=12\\). The simple script below increases \\(x\\) by \\(1\\) until the cumulative probability crosses \\(.99\\). x = 12 while Poisson(10).cdf(x) &lt; .99: x += 1 # print out the value of x and the probability x, Poisson(10).cdf(x) ## (18, 0.9928134953961456) You can play around with the Python code in this Colab notebook. It is also possible to do this calculation in R, a statistical programming language. probs &lt;- dpois(0:11, 10) 1 - sum(probs) ## [1] 0.3032239 We can also use the c.d.f. function: 1 - ppois(11, 10) ## [1] 0.3032239 The second question can be addressed by trial and error. We want to figure out the value \\(c\\) such that \\(F(c) = P(X \\leq c) = .99\\). From above, we already know that \\(F(11) \\approx 0.70\\), so we can start trying values from \\(c=12\\). The simple script below increases \\(x\\) by \\(1\\) until the c.d.f. crosses \\(.99\\). x &lt;- 12 while(ppois(x, 10) &lt; .99) { x &lt;- x + 1 } # print out the value of x and the probability c(x, ppois(x, 10)) ## [1] 18.0000000 0.9928135 You can play around with the R code in this Colab notebook. Essential Practice If you buy a lottery ticket in 50 lotteries, in each of which your chances of winning a prize of \\(1/100\\), what is the probability that you will win a prize: at least once? exactly twice? at least twice? Calculate both the exact probabilities (using the binomial distribution) and the approximate probabilities (using the Poisson distribution). The number of organisms in \\(V\\) cubic meters of ballast water discharged from a ship follows a \\(\\text{Poisson}(\\mu=10 V)\\) distribution. (See “Counting at Low Concentrations: The Statistical Challenges of Verifying Ballast Water Discharge Standards”, Ecological Applications, 2013:339–351.) What is the probability that there are at least 12 organisms in 1.5 cubic meters of discharge? For what amount of discharge would the probability of containing at least one organism be .999? Thelma calculates the exact probability of winning more than 50% of the time when she places 1000 bets on red in roulette. Louise calculates an approximate probability using the Poisson distribution. They get very different answers. What answers did they get, and why did the Poisson approximation fail in this case? "],
["poisson-process.html", "Lesson 17 Poisson Process Motivating Example Theory Essential Practice", " Lesson 17 Poisson Process Motivating Example A Geiger counter is a device used for measuring radiation in the atmosphere. Each time it detects a radioactive particle, it makes a clicking sound. In the figure below, the orange points below indicate the times at which the Geiger counter detected a radioactive particle. Figure 17.1: Radioactive Particles Reaching a Geiger Counter The radioactive particles hit the Geiger Counter at seemingly random and unpredictable times. In this lesson, we learn to make sense of the randomness. Theory Radioactive particles are a classic example of a type of random process called the Poisson process. The Poisson process is used to model random events, called “arrivals”, over time. Definition 17.1 (Poisson Process) A Poisson process of rate \\(\\lambda\\) is characterized by the following properties: The number of arrivals in any interval \\((t_0, t_1)\\) follows a Poisson distribution with \\(\\mu = \\lambda (t_1 - t_0)\\). That is, the parameter \\(\\mu\\) increases proportionally to the length of the interval. The numbers of arrivals in non-overlapping intervals are independent. These two properties allow us to calculate any probability of interest. Example 17.1 (Geiger Counter) In San Luis Obispo, radioactive particles reach a Geiger counter according to a Poisson process at a rate of \\(\\lambda = 0.8\\) particles per second. What is the probability that the Geiger counter detects 3 or more particles in the next 4 seconds? What is the probability that the Geiger counter detects (exactly) 1 particle in the next second and 3 or more in the next 4 seconds? Solution. . The number of particles arriving at the detector in the next 4 seconds, \\(X\\), follows a \\(\\text{Poisson}(\\mu = 0.8 \\cdot (4 - 0) = 3.2)\\) distribution by Property 1 (17.1). Therefore, the probability of detecting 3 or more particles is: \\[\\begin{align*} P(X \\geq 3) &amp;= 1 - P(X &lt; 3) \\\\ &amp;= 1 - f(0) - f(1) - f(2) \\\\ &amp;= 1 - e^{-3.2} \\frac{3.2^0}{0!} - e^{-3.2} \\frac{3.2^1}{1!} - e^{-3.2} \\frac{3.2^2}{2!} \\\\ &amp;\\approx .6201 \\end{align*}\\] The joint probability \\[ P(\\text{1 particle in (0, 1)} \\text{ AND } \\text{3 or more particles in (0, 4)}) \\] involves two events that are not independent. However, we can rewrite the joint probability as: \\[ P(\\text{1 particle in (0, 1)} \\text{ AND } \\text{2 or more particles in (1, 4)}). \\] Now, \\((0, 1)\\) and \\((1, 4)\\) are non-overlapping intervals, so the number of particles arriving in \\((0, 1)\\) is independent of the number of particles arriving in \\((1, 4)\\) by Property 2 (17.1). Therefore, by Theorem 7.1, we obtain their joint probability by multiplying their individual probabilities: \\[ P(\\text{1 particle in (0, 1)}) \\cdot P(\\text{2 or more particles in (1, 4)}). \\] Now, we know from Property 1 (17.1) that the number of particles in \\((0, 1)\\) follows a \\(\\text{Poisson}(\\mu = 0.8)\\) distribution, and the number of particles in \\((1, 4)\\) follows a \\(\\text{Poisson}(\\mu = 2.4)\\) distribution. If we represent the p.m.f.s of these two random variables by \\(f_1\\) and \\(f_2\\), respectively, then the probability is \\[ f_1(1) \\cdot \\left(1 - f_2(0) - f_2(1) \\right) = e^{-0.8} \\frac{0.8^1}{1!} \\cdot \\left( 1 - e^{-2.4} \\frac{2.4^0}{0!} - e^{-2.4} \\frac{2.4^1}{1!} \\right) \\approx .2486. \\] We can also calculate these probabilities with the aid of software: from symbulate import * Poisson(0.8 * (1 - 0)).pmf(1) * (1 - Poisson(0.8 * (4 - 1)).cdf(1)) ## 0.24858997647262118 Why Poisson? Why does it make sense to assume that the number of arrivals on any interval follows a Poisson distribution? If we chop time up into tiny segments of length \\(\\Delta t\\), then the probability of an arrival on any one of these segments will be small—but there will be many such intervals. Figure 17.2: Chopping Up Time in a Poisson Process If we further assume that arrivals are independent across these tiny segments, then the number of arrivals follows a binomial distribution, with large \\(n\\) (because there are many segments) and small \\(p\\) (because an arrival is unlikely to fall exactly in any given segment). We saw in Theorem 16.1 that the Poisson distribution is a good approximation to the binomial when \\(n\\) is large and \\(p\\) is small. Technical Detail: In order for the number of arrivals to be binomial, each tiny segment must contain either 1 arrival or none; there cannot be 2 or more arrivals in any segment. Usually, if \\(\\Delta t\\) is so small that it is rare to get even 1 arrival in a segment, then it is essentially impossible to get 2 arrivals. Essential Practice Packets arrive at a certain node on the university’s intranet at 10 packets per minute, on average. Assume packet arrivals meet the assumptions of a Poisson process. Calculate the probability that exactly 15 packets arrive in the next 2 minutes. Calculate the probability that more than 60 packets arrive in the next 5 minutes. Calculate the probability that the next packet will arrive in within 15 seconds. Small aircraft arrive at San Luis Obispo airport according to a Poisson process at a rate of 6 per hour. What is the probability that exactly 5 small aircraft arrive in the first hour (after opening) and exactly 7 arrive in the hour after that? What is the probability that fewer than 5 small aircraft arrive in the first hour and at least 10 arrive in the hour after that? What is the probability that exactly 5 small aircraft arrive in the first hour and exactly 12 aircraft arrive in the first two hours? "],
["joint-discrete.html", "Lesson 18 Joint Distributions Motivating Example Theory Essential Practice Additional Exercises", " Lesson 18 Joint Distributions Motivating Example Xavier and Yolanda head to the roulette table at a casino. They both place bets on red on 3 spins of the roulette wheel before Xavier has to leave. After Xavier leaves, Yolanda places bets on red on 2 more spins of the wheel. Let \\(X\\) be the number of bets that Xavier wins and \\(Y\\) be the number that Yolanda wins. We know that \\(X\\) follows a \\(\\text{Binomial}(n=3, p=\\frac{18}{38})\\) distribution so its p.m.f. is \\[ f(x) = \\binom{3}{x} \\left( \\frac{18}{38} \\right)^x \\left(1 - \\frac{18}{38} \\right)^{3-x}, \\] which we can write in tabular form as \\[ \\begin{array}{r|cccc} x &amp; 0 &amp; 1 &amp; 2 &amp; 3 \\\\ \\hline f(x) &amp; .1458 &amp; .3936 &amp; .3543 &amp; .1063 \\\\ \\end{array}. \\] We also know that \\(Y\\) follows a \\(\\text{Binomial}(n=5, p=\\frac{18}{38})\\) distribution so its p.m.f. is \\[ \\begin{array}{r|cccc} y &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5\\\\ \\hline f(y) &amp; .0404 &amp; .1817 &amp; .3271 &amp; .2944 &amp; .1325 &amp; .0238 \\end{array}. \\] But this does not tell us how \\(X\\) and \\(Y\\) are related to each other. In fact, the two random variables have a very distinctive relationship. For example, \\(Y\\) must be greater than or equal to \\(X\\), since Yolanda made the same three bets that Xavier did, plus two more. In this lesson, we will learn a way to describe the distribution of two (or more) random variables. Theory Definition 18.1 The joint distribution of two random variables \\(X\\) and \\(Y\\) is described by the joint p.m.f. \\[\\begin{equation} f(x, y) = P(X=x \\text{ and } Y=y). \\tag{18.1} \\end{equation}\\] Example 18.1 Let’s work out the joint p.m.f. of \\(X\\), the number of bets that Xavier wins, and \\(Y\\), the number of bets that Yolanda wins. To do this, we will lay out the values of \\(f(x, y)\\) in a table, like the following. \\[\\begin{equation} \\begin{array}{rr|cccc} &amp; 5 &amp; f(0, 5) &amp; f(1, 5) &amp; f(2, 5) &amp; f(3, 5) \\\\ &amp; 4 &amp; f(0, 4) &amp; f(1, 4) &amp; f(2, 4) &amp; f(3, 4) \\\\ y &amp; 3 &amp; f(0, 3) &amp; f(1, 3) &amp; f(2, 3) &amp; f(3, 3) \\\\ &amp; 2 &amp; f(0, 2) &amp; f(1, 2) &amp; f(2, 2) &amp; f(3, 2) \\\\ &amp; 1 &amp; f(0, 1) &amp; f(1, 1) &amp; f(2, 1) &amp; f(3, 1) \\\\ &amp; 0 &amp; f(0, 0) &amp; f(1, 0) &amp; f(2, 0) &amp; f(3, 0) \\\\ \\hline &amp; &amp; 0 &amp; 1 &amp; 2 &amp; 3\\\\ &amp; &amp; &amp; &amp; x \\end{array} \\tag{18.2} \\end{equation}\\] First, we observe that it is impossible for Xavier to win more bets than Yolanda—since Yolanda makes all the bets that Xavier does (plus two more). Therefore, we know that \\(f(x,y) = 0\\) if \\(x &gt; y\\). We also know that Yolanda can at most two more bets than Xavier. So \\(f(x, y) = 0\\) if \\(y &gt; x + 2\\). Therefore, we can fill in half of the entries in the table with zeroes. \\[ \\begin{array}{rr|cccc} &amp; 5 &amp; 0 &amp; 0 &amp; 0 &amp; f(3, 5) \\\\ &amp; 4 &amp; 0 &amp; 0 &amp; f(2, 4) &amp; f(3, 4) \\\\ y &amp; 3 &amp; 0 &amp; f(1, 3) &amp; f(2, 3) &amp; f(3, 3) \\\\ &amp; 2 &amp; f(0, 2) &amp; f(1, 2) &amp; f(2, 2) &amp; 0 \\\\ &amp; 1 &amp; f(0, 1) &amp; f(1, 1) &amp; 0 &amp; 0 \\\\ &amp; 0 &amp; f(0, 0) &amp; 0 &amp; 0 &amp; 0 \\\\ \\hline &amp; &amp; 0 &amp; 1 &amp; 2 &amp; 3\\\\ &amp; &amp; &amp; &amp; x \\end{array} \\] Let’s calculate one of the non-zero joint probabilities: \\[ f(2, 3) = P(X=2 \\text{ and } Y=3). \\] In order for Xavier to win twice and Yolanda to win 3 times, there must have been 2 reds in the first 3 spins and 1 red in the 2 spins after that. Because the first 3 spins and the next 2 spins are independent, we can multiply the two binomial probabilities: \\[\\begin{align*} f(2, 3) &amp;= P(\\text{2 reds in first 3 spins} \\text{ and } \\text{1 red in next 2 spins}) \\\\ &amp;= \\binom{3}{2} \\left( \\frac{18}{38} \\right)^2 \\left( 1 - \\frac{18}{38} \\right)^{1} \\cdot \\binom{2}{1} \\left( \\frac{18}{38} \\right)^1 \\left( 1 - \\frac{18}{38} \\right)^{1} \\\\ &amp;\\approx .1766 \\end{align*}\\] As one more example, let’s calculate \\[ f(1, 1) = P(X=1 \\text{ and } Y=1). \\] In order for Xavier and Yolanda to each win once, there must have been 1 red in the first 3 spins and 0 reds in the next two. Since the first 3 spins and the next 2 spins are independent, we can multiply their probabilities: \\[\\begin{align*} f(1, 1) &amp;= P(\\text{1 red in first 3 spins} \\text{ and } \\text{0 reds in next 2 spins}) \\\\ &amp;= \\binom{3}{1} \\left( \\frac{18}{38} \\right)^1 \\left( 1 - \\frac{18}{38} \\right)^2 \\cdot \\binom{2}{0} \\left( \\frac{18}{38} \\right)^0 \\left( 1 - \\frac{18}{38} \\right)^2 \\\\ &amp;\\approx .1090 \\end{align*}\\] The process for calculating the other probabilities in the table is the same. We look at what each event \\(\\{ X=x \\text{ and } Y=y\\}\\) implies about the number of reds in the first 3 spins and the number of reds in the next 2 spins; because the first 3 spins and the next 2 spins are independent, we can multiply their probabilities. The completed table looks like this: \\[ \\begin{array}{rr|cccc} &amp; 5 &amp; 0 &amp; 0 &amp; 0 &amp; .0238 \\\\ &amp; 4 &amp; 0 &amp; 0 &amp; .0795 &amp; .0530 \\\\ y &amp; 3 &amp; 0 &amp; .0883 &amp; .1766 &amp; .0294 \\\\ &amp; 2 &amp; .0327 &amp; .1963 &amp; .0981 &amp; 0 \\\\ &amp; 1 &amp; .0726 &amp; .1090 &amp; 0 &amp; 0 \\\\ &amp; 0 &amp; .0404 &amp; 0 &amp; 0 &amp; 0 \\\\ \\hline &amp; &amp; 0 &amp; 1 &amp; 2 &amp; 3\\\\ &amp; &amp; &amp; &amp; x \\end{array} \\] Notice that all of the probabilities in this table add up to \\(1.0\\) (up to rounding error). Example 18.2 (Coin Tosses) A fair coin is tossed 6 times. Let \\(X\\) be the number of heads in the first 3 tosses. Let \\(Y\\) be the number of heads in the last 3 tosses. Calculate the joint p.m.f. of \\(X\\) and \\(Y\\), and use it to calculate \\(P(X + Y \\leq 2)\\). Solution. The first 3 tosses and the next 3 tosses are independent. Therefore, we know that \\[ f(x, y) = P(X=x \\text{ and } Y=y) = P(X=x) \\cdot P(Y=y) \\] for any value \\(x\\) and \\(y\\). Since \\(X\\) and \\(Y\\) are both \\(\\text{Binomial}(n=3, N_1=1, N_0=1)\\), we have a formula for their p.m.f.s: \\[\\begin{align*} P(X=x) &amp;= \\frac{\\binom{3}{x}}{2^3} &amp; P(Y=y) &amp;= \\frac{\\binom{3}{y}}{2^3}. \\end{align*}\\] Therefore, we can write the joint p.m.f. as a formula: \\[ f(x, y) = \\frac{\\binom{3}{x}}{2^3}\\cdot \\frac{\\binom{3}{y}}{2^3}, 0 \\leq x, y \\leq 3. \\] This is equivalent to writing the probabilities in a table: \\[ \\begin{array}{rr|cccc} &amp; 3 &amp; .0156 &amp; .0469 &amp; .0469 &amp; .0156 \\\\ y &amp; 2 &amp; .0469 &amp; .1406 &amp; .1406 &amp; .0469 \\\\ &amp; 1 &amp; .0469 &amp; .1406 &amp; .1406 &amp; .0469 \\\\ &amp; 0 &amp; .0156 &amp; .0469 &amp; .0469 &amp; .0156 \\\\ \\hline &amp; &amp; 0 &amp; 1 &amp; 2 &amp; 3\\\\ &amp; &amp; &amp; &amp; x \\end{array}. \\] To use this joint p.m.f. to calculate \\(P(X + Y \\leq 2)\\), we add up \\(f(x, y)\\) for values \\(x\\) and \\(y\\) satisfying \\(x + y \\leq 2\\). As a formula, we can express this as: \\[ P(X + Y \\leq 2) = \\underset{x, y:\\ x + y \\leq 2}{\\sum\\sum} f(x, y). \\] But it is easier to see what probabilities we need to add in the table: \\[ \\begin{array}{rr|cccc} &amp; 3 &amp; .0156 &amp; .0469 &amp; .0469 &amp; .0156 \\\\ y &amp; 2 &amp; \\fbox{.0469} &amp; .1406 &amp; .1406 &amp; .0469 \\\\ &amp; 1 &amp; \\fbox{.0469} &amp; \\fbox{.1406} &amp; .1406 &amp; .0469 \\\\ &amp; 0 &amp; \\fbox{.0156} &amp; \\fbox{.0469} &amp; \\fbox{.0469} &amp; .0156 \\\\ \\hline &amp; &amp; 0 &amp; 1 &amp; 2 &amp; 3\\\\ &amp; &amp; &amp; &amp; x \\end{array}. \\] The answer is: \\[\\begin{align*} P(X + Y \\leq 2) &amp;= f(0, 0) + f(1, 0) + f(0, 1) + f(0, 2) + f(1, 1) + f(2, 0) \\\\ &amp;= .0156 + .0469 + .0469 + .0469 + .1406 + .0469 \\\\ &amp;= .3438. \\end{align*}\\] Of course, we could have obtained this answer without deriving the joint p.m.f. of \\(X\\) and \\(Y\\). The random variable \\(X + Y\\) represents the number of heads in 6 tosses of a fair coin, which we know follows a binomial distribution. Therefore, we can calculate \\(P(X + Y \\leq 2)\\) using the c.d.f. of a binomial distribution: from symbulate import * Binomial(n=6, p=0.5).cdf(2) ## 0.3437500000000001 We get the same answer. Example 18.3 (Chicken and the Egg) The number of eggs laid by a hen, \\(N\\), is a \\(\\text{Poisson}(\\mu)\\) random variable. Each egg hatches with probability \\(p\\), independently of any other egg. Let \\(X\\) be the number of eggs that hatch into baby chickens. Find the joint p.m.f. of \\(N\\) and \\(X\\). Solution. First, observe that \\(N\\) is a random variable that can take on values from \\(0\\) and \\(\\infty\\). We cannot possibly write down all of the probabilities in a table. We will try to write the joint p.m.f. as a formula. We are interested in: \\[ f(n, x) = P(N = n \\text{ and } X = x). \\] By the multiplication rule (Theorem 6.1), we have \\[ P(N = n \\text{ and } X = x) = P(N = n) P(X = x | N = n). \\] Once we know how many eggs there are, then \\(X\\) follows a binomial distribution. In other words, given \\(\\{ N = n \\}\\), \\(X\\) is a \\(\\text{Binomial}(n, p)\\) random variable. Therefore, \\[\\begin{align*} P(N = n) P(X = x | N = n) &amp;= e^{-\\mu} \\frac{\\mu^n}{n!} \\cdot \\binom{n}{x} p^x (1-p)^{n-x} \\\\ &amp;= e^{-\\mu} \\frac{(\\mu p)^x}{x!} \\frac{(\\mu (1-p))^{n-x}}{(n-x)!}. \\end{align*}\\] This formula is only valid when \\(x \\leq n\\), since we cannot have more baby chickens than eggs. So, we can specify the p.m.f. as \\[ f(n, x) = \\begin{cases} e^{-\\mu} \\frac{(\\mu p)^x}{x!} \\frac{(\\mu (1-p))^{n-x}}{(n-x)!} &amp; 0 \\leq x \\leq n &lt; \\infty \\\\ 0 &amp; \\text{otherwise} \\end{cases}. \\] Essential Practice Two tickets are drawn from a box with \\(N_1\\) \\(\\fbox{1}\\)s and \\(N_0\\) \\(\\fbox{0}\\)s. Let \\(X\\) be the number of \\(\\fbox{1}\\)s on the first draw and \\(Y\\) be the number of \\(\\fbox{1}\\)s on the second draw. (Note that \\(X\\) and \\(Y\\) can only be 0 or 1.) Find the joint p.m.f. of \\(X\\) and \\(Y\\) when the draws are made with replacement. Find the joint p.m.f. of \\(X\\) and \\(Y\\) when the draws are made without replacement. (You may specify the joint p.m.f. as a table or a formula, whichever is more convenient for you.) Two fair, six-sided dice are rolled. Let \\(S\\) be the smaller of the numbers on the two dice. Let \\(L\\) be the larger of the numbers on the two dice. (Note: If doubles are rolled, then \\(S = L\\).) Find the joint p.m.f. of \\(S\\) and \\(L\\). Use the joint p.m.f. to calculate \\(P(S + L = 2)\\). Repeat for \\(P(S + L = k)\\), \\(k = 3, 4, 5, \\ldots, 12\\). Why does the answer make sense? A fair coin is tossed 3 times. Let \\(X\\) be the number of heads in these three tosses. Let \\(Y\\) be the number of tails in these three tosses. Find the joint p.m.f. of \\(X\\) and \\(Y\\). (You may specify the joint p.m.f. as a table or a formula, whichever is more convenient for you.) At Diablo Canyon nuclear plant, radioactive particles hit a Geiger counter according to a Poisson process with a rate of 3.5 particles per second. Let \\(X\\) be the number of particles detected in the first 2 seconds. Let \\(Y\\) be the number of particles detected in the second after that (i.e., the third second). Find the joint p.m.f. of \\(X\\) and \\(Y\\). (You may specify the joint p.m.f. as a table or a formula, whichever is more convenient for you.) Additional Exercises A fair coin is tossed 4 times. Let \\(X\\) be the number of heads in the first three tosses. Let \\(Y\\) be the number of heads in the last three tosses. Find the joint p.m.f. of \\(X\\) and \\(Y\\). (Hint: There are only \\(2^4 = 16\\) equally likely outcomes when you toss 4 coins. If you are unable to calculate the probabilities using rules we have learned, just list all the possible outcomes!) At Diablo Canyon nuclear plant, radioactive particles hit a Geiger counter according to a Poisson process with a rate of 3.5 particles per second. Let \\(X\\) be the number of particles detected in the first 2 seconds. Let \\(Z\\) be the number of particles detected in the first 3 seconds. Find the joint p.m.f. of \\(X\\) and \\(Z\\). "],
["marginal-discrete.html", "Lesson 19 Marginal Distributions Motivating Example Theory Essential Practice Additional Exercises", " Lesson 19 Marginal Distributions Motivating Example In Lesson 18, we found the joint distribution of \\(X\\), the number of bets that Xavier wins, and \\(Y\\), the number of bets that Yolanda wins. If all we have is the joint distribution of \\(X\\) and \\(Y\\), can we recover the distribution of \\(X\\) alone? Theory Recall from Lesson 10 that the p.m.f. of \\(X\\) is defined to be \\(P(X = x)\\) as a function of \\(x\\). To calculate a probaebility from a joint p.m.f., we sum over the relevant outcomes. In this case, we need to sum the joint p.m.f. over all the possible values of \\(y\\) for the given \\(x\\): \\[\\begin{equation} P(X = x) = \\sum_y f(x, y). \\tag{19.1} \\end{equation}\\] If the joint p.m.f. is written out in table form, then (19.2) corresponds to the column sums of the table, as illustrated in Figure 19.1. Figure 19.1: Calculating the Marginal Distribution of \\(X\\) Notice how natural it was to write the column totals in the margins of the table in Figure 19.1. For this reason, this collection of probabilities has come to be known as the marginal distribution of \\(X\\). Definition 19.1 (Marginal Distribution) The marginal p.m.f. of \\(X\\) refers to the p.m.f. of \\(X\\) when it is calculated from the joint p.m.f. of \\(X\\) and \\(Y\\). Specifically, the marginal p.m.f. \\(f_X\\) can be calculated from the joint p.m.f. \\(f\\) as follows: \\[\\begin{equation} f_X(x) \\overset{\\text{def}}{=} P(X=x) = \\sum_y f(x, y). \\tag{19.2} \\end{equation}\\] Notice that we use subscripts in \\(f_X\\) to distinguish this function from the joint distribution \\(f\\) and, later, the marginal distribution of \\(Y\\). There is also a marginal distribution of \\(Y\\). As you might expect, the marginal p.m.f. is symbolized \\(f_Y\\) and is calculated by summing over all the possible values of \\(X\\): \\[\\begin{equation} f_Y(y) \\overset{\\text{def}}{=} P(Y=y) \\sum_x f(x, y). \\tag{19.3} \\end{equation}\\] On a table, the marginal distribution of \\(Y\\) corresponds to the row sums of the table, as illustrated in Figure 19.2. Figure 19.2: Calculating the Marginal Distribution of \\(Y\\) Remember that we know the distribution of \\(Y\\). It is \\(\\text{Binomial}(n=5, p=18/38)\\). You should verify that the marginal distribution we calculated in 19.2 matches that of a \\(\\text{Binomial}(n=5, p=18/38)\\) distribution. Theorem 19.1 (Joint Distribution of Independent Random Variables) If \\(X\\) and \\(Y\\) are independent, then \\[\\begin{equation} f(x, y) = f_X(x) \\cdot f_Y(y) \\end{equation}\\] for all values \\(x\\) and \\(y\\). But only if \\(X\\) and \\(Y\\) are independent! Proof. In Lesson 18, we saw that the joint distribution is defined to be \\[ f(x, y) = P(X = x \\text{ and } Y=y). \\] If \\(X\\) and \\(Y\\) are independent, then we can multiply the probabilities, by Theorem 7.1: \\[ P(X=x) \\cdot P(Y=y). \\] But \\(P(X=x)\\) is just the marginal distribution of \\(X\\) and \\(P(Y=y)\\) the marginal distribution of \\(Y\\). So this is equal to: \\[ f_X(x) \\cdot f_Y(y) \\] Let’s calculate another marginal distribution—this time from the formula representation of the joint p.m.f. Example 19.1 (Marginal Number of Chickens) In Example 18.3, we found that the joint distribution of the number of eggs \\(N\\) and the number of baby chickens \\(X\\) was \\[\\begin{equation} f(n, x) = \\begin{cases} e^{-\\mu} \\frac{(\\mu p)^x}{x!} \\frac{(\\mu (1-p))^{n-x}}{(n-x)!} &amp; 0 \\leq x \\leq n &lt; \\infty \\\\ 0 &amp; \\text{otherwise}. \\end{cases} \\tag{19.4} \\end{equation}\\] What is the marginal distribution of the number of baby chickens, \\(X\\)? Solution. By (19.2), we need to sum the joint p.m.f. \\(f(n, x)\\) over all the possible values of \\(N\\). In (19.4), we see that the joint p.m.f. is \\(0\\) unless \\(n \\geq x\\). So we sum the complicated expression in (19.4) for all \\(n\\) from \\(x\\) to \\(\\infty\\). \\[\\begin{align*} f_X(x) &amp;= \\sum_n f(n, x) \\\\ &amp;= \\sum_{n=x}^\\infty e^{-\\mu} \\frac{(\\mu p)^x}{x!} \\frac{(\\mu (1-p))^{n-x}}{(n-x)!} \\\\ &amp;= e^{-\\mu} \\frac{(\\mu p)^x}{x!} \\sum_{n=x}^\\infty \\frac{(\\mu (1-p))^{n-x}}{(n-x)!} &amp; \\text{(pull out terms not depending on $n$)} \\\\ &amp;= e^{-\\mu} \\frac{(\\mu p)^x}{x!} \\sum_{m=0}^\\infty \\frac{\\nu^m}{m!} &amp; (m=n-x, \\nu=\\mu(1-p)) \\\\ &amp;= e^{-\\mu} \\frac{(\\mu p)^x}{x!} e^{\\nu} \\underbrace{\\sum_{m=0}^\\infty e^{-\\nu} \\frac{\\nu^m}{m!}}_{\\text{sum of Poisson$(\\nu)$ p.m.f.} = 1} &amp; \\text{(multiply by $e^{\\nu} e^{-\\nu} = 1$)} \\\\ &amp;= e^{-\\mu + \\mu(1-p)} \\frac{(\\mu p)^x}{x!} &amp; (e^{-\\mu + \\nu}, \\nu=\\mu(1-p)) \\\\ &amp;= e^{-\\mu p} \\frac{(\\mu p)^x}{x!}. \\end{align*}\\] This formula is valid for \\(x=0, 1, 2, \\ldots\\). We recognize this as the p.m.f. of a \\(\\text{Poisson}(\\mu p)\\) distribution. Essential Practice Let \\(X\\) be the number of times a certain numerical control machine will malfunction on a given day. Let \\(Y\\) be the number of times a technician is called on an emergency call. Their joint p.m.f. is given by \\[ \\begin{array}{rr|cccc} &amp; 5 &amp; 0 &amp; .20 &amp; .10 \\\\ y &amp; 3 &amp; .05 &amp; .10 &amp; .35 \\\\ &amp; 1 &amp; .05 &amp; .05 &amp; .10 \\\\ \\hline &amp; &amp; 1 &amp; 2 &amp; 3\\\\ &amp; &amp; &amp; x \\end{array}. \\] Calculate the marginal distribution of \\(X\\). Calculate the marginal distribution of \\(Y\\). Are \\(X\\) and \\(Y\\) independent? How do you know? Use the joint p.m.f. of the smaller and the larger of two dice rolls that you calculated in Lesson 18 to find the p.m.f. of the larger number. Use this p.m.f. to solve the “last banana” problem from Lesson 7. Suppose two random variables \\(X\\) and \\(Y\\) both have marginal \\(\\text{Binomial}(n=3, p=0.5)\\) distributions. In this exercise, you will see that there are many joint distributions that could have those marginal distributions. What is the joint p.m.f. if \\(X\\) and \\(Y\\) are independent? Can you find at least 2 more joint p.m.f.s with the same marginal distributions? (Hint: What happens if you define \\(X\\) and \\(Y\\) based on just 3 tosses of a coin? What about 4 tosses of a coin?) Additional Exercises Two tickets are drawn without replacement from a box with \\(N_1\\) \\(\\fbox{1}\\)s and \\(N_0\\) \\(\\fbox{0}\\)s. Let \\(X\\) be the number of \\(\\fbox{1}\\)s on the first draw and \\(Y\\) be the number of \\(\\fbox{1}\\)s on the second draw. It is clear that the first draw has a \\(\\frac{N_1}{N}\\) probability of being a \\(\\fbox{1}\\). But what about the second draw? In Lesson 18, you found the joint distribution of \\(X\\) and \\(Y\\). Use this joint p.m.f. to show that the probability that the second draw is a \\(\\fbox{1}\\) is \\(\\frac{N_1}{N}\\). "],
["conditional-discrete.html", "Lesson 20 Conditional Distributions Motivating Example Theory Essential Practice Additional Exercises", " Lesson 20 Conditional Distributions Motivating Example Continuing with the example from Lessons 18 and 19, suppose Xavier and Yolanda meet up later for coffee. Xavier has forgotten how many bets he won at roulette, but Yolanda clearly remembers that she won 3 bets. What information does this give Xavier about how many bets he won? First, if Yolanda won 3 bets, Xavier knows that he had to have won at least once, since Yolanda only made two more bets than he did. But he cannot be sure whether he won 1, 2, or 3 bets. All he can do is assign probabilities to these possible values based on the information he has been given. Theory Xavier wants to know the distribution of the random variable \\(X\\), given the information in another random variable \\(Y\\). This is called the conditional distribution of \\(X\\) given \\(Y\\). Definition 20.1 (Conditional Distribution) The conditional p.m.f. of \\(X\\) given \\(Y\\) is defined as \\[\\begin{equation} f_{X|Y}(x|y) \\overset{\\text{def}}{=} P(X = x | Y = y) = \\frac{f(x, y)}{f_Y(y)}. \\tag{20.1} \\end{equation}\\] Visually, we are taking a row of the joint p.m.f. table and dividing the values by the total of that row. The process is illustrated in Figure 20.1. Figure 20.1: Calculating the Conditional Distribution of \\(Y\\) Notice that the probabilities add up to \\(1.0\\). This makes sense, since we have exhausted all the possible values that \\(X\\) could be. Figure 20.2 provides another view of what is going on when we divide by the marginal p.m.f. of \\(Y\\). The probabilities in the joint p.m.f. \\(f(x, y)\\) are correct relative to each other; the marginal p.m.f. \\(f_{Y}(y)\\) is just a scaling factor to make the probabilities add up to \\(1.0\\). Figure 20.2: The joint distribution \\(f(x, 3)\\) in red vs. the conditional distribution \\(f_{X|Y}(x|3)\\) in black Let’s calculate another conditional distribution—this time using formulas, rather than tables. Example 20.1 (Conditional Distributions of a Poisson Process) In San Luis Obispo, radioactive particles hit a Geiger counter according to a Poisson process at a rate of \\(\\lambda = 0.8\\) particles per second. Suppose that 7 particles are detected in the first 5 seconds. What is the distribution of the number of particles that are detected in the first 3 seconds? Solution. If we let \\(X\\) be the number of particles in the first 3 seconds and \\(Y\\) be the number of particles in the first 5 seconds, then we are interested in the conditional distribution \\[ f_{X|Y}(x | 7). \\] From (20.1), we know that this is \\[ f_{X|Y}(x | 7) = \\frac{f(x, 7)}{f_Y(7)}. \\] The marginal probability \\(f_Y(7)\\) is easy to calculate. \\(Y\\) is the number of arrivals on a \\(5\\)-second interval, which we know follows a \\(\\text{Poisson}(\\mu=5 \\cdot 0.8)\\) distribution, by Property 1 of a Poisson Process (see Lesson 17). Therefore: \\[ f_Y(7) = e^{-5 \\cdot 0.8} \\frac{(5 \\cdot 0.8)^7}{7!}. \\] To calculate the joint probability \\(f(x, 7)\\), we first break the time interval \\((0, 5)\\) into two non-overlapping intervals, \\((0, 3)\\) and \\((3, 5)\\), as shown in Figure 20.3. We know from Property 2 of a Poisson Process (see Lesson 17) that the numbers of arrivals on non-overlapping intervals are independent. Let’s represent the number of arrivals on \\((3, 5)\\) by \\(Z \\overset{\\text{def}}{=} Y - X\\) so that \\(Z\\) is independent of \\(X\\). Figure 20.3: Breaking up a Poisson Process Now, we calculate the joint probability: \\[\\begin{align*} f(x, 7) &amp;= P(X=x \\text{ and } Y=7) \\\\ &amp;= P(X=x \\text{ and } Z=7-x) \\\\ &amp;= P(X=x) \\cdot P(Z=7-x) &amp; \\text{(since $X$ and $Z$ are independent)} \\\\ &amp;= e^{-(3 \\cdot 0.8)} \\frac{(3 \\cdot 0.8)^x}{x!} \\cdot e^{-(2 \\cdot 0.8)} \\frac{(2 \\cdot 0.8)^{7-x}}{(7-x)!} \\end{align*}\\] Putting everything together, we find that the conditional distribution is: \\[\\begin{align*} f_{X|Y}(x | 7) &amp;= \\frac{f(x, 7)}{f_Y(7)} \\\\ &amp;= \\frac{e^{-(3 \\cdot 0.8)} \\frac{(3 \\cdot 0.8)^x}{x!} \\cdot e^{-(2 \\cdot 0.8)} \\frac{(2 \\cdot 0.8)^{7-x}}{(7-x)!}}{e^{-5 \\cdot 0.8} \\frac{(5 \\cdot 0.8)^7}{7!}} \\\\ &amp;= \\frac{7!}{x! (7-x)!} \\frac{(3 \\cdot 0.8)^x \\cdot (2 \\cdot 0.8)^{7-x}}{(5 \\cdot 0.8)^7} \\\\ &amp;= \\frac{\\binom{7}{x} 3^x \\cdot 2^{7-x}}{5^7} \\end{align*}\\] This is just the p.m.f. of a \\(\\text{Binomial}(n=7, N_1=3, N_0=2)\\) distribution. The interpretation is this: given that there were 7 arrivals on the interval \\((0, 5)\\), each arrival has a \\(p=3/5\\) chance of falling in the first 3 seconds, independently of the other arrivals. Essential Practice Let \\(X\\) be the number of times a certain numerical control machine will malfunction on a given day. Let \\(Y\\) be the number of times a technician is called on an emergency call. Their joint p.m.f. is given by \\[ \\begin{array}{rr|cccc} &amp; 5 &amp; 0 &amp; .20 &amp; .10 \\\\ y &amp; 3 &amp; .05 &amp; .10 &amp; .35 \\\\ &amp; 1 &amp; .05 &amp; .05 &amp; .10 \\\\ \\hline &amp; &amp; 1 &amp; 2 &amp; 3\\\\ &amp; &amp; &amp; x \\end{array}. \\] Calculate the conditional distribution of \\(X\\) given \\(Y=3\\). Calculate the conditional distribution of \\(Y\\) given \\(X=2\\). Is \\(P(Y=3 | X=2)\\) the same as \\(P(X=2 | Y=3)\\)? Small aircraft arrive at San Luis Obispo airport according to a Poisson process at a rate of 6 per hour. What is the probability that (exactly) 5 small aircraft arrived in the first hour, given that (exactly) 12 aircraft arrived in the first two hours? First calculate an appropriate conditional distribution; then, use this conditional distribution to answer the question. A fair coin is tossed 10 times. Let \\(X\\) be the total number of heads in the 10 tosses. Let \\(Y\\) be the number of heads in the first 6 tosses. Find the conditional distribution of \\(Y\\), given \\(X = 7\\). This is a named distribution we have learned. Which is it? Specify all parameters of this distribution. (Hint: In order to identify the named distribution, it is easier to work with formulas rather than tables.) Additional Exercises Use the joint p.m.f. of the smaller and the larger of two dice rolls that you calculated in Lesson 18 to find the conditional distribution of the smaller number, given that the larger number was \\(4\\). "]
]
